# 0101. 信息度量：世界上有稳赚不赔的生意吗？
> 吴军·信息论40讲
2019-05-30

在前几节课里，我们介绍了信息论的大致内容，信息的作用，它作为一门交叉科学，是如何成为今天信息时代做事情所采用的方法论的。

我们课程的第一模块围绕着信息的产生，也就是信息的源泉（香农称之为信息源，information sources）展开。第二模块围绕着信息传播，也就是我们今天所说的广义上的通信和传播学展开。信息的应用放到了第三个模块中。

从这一讲开始，我们就沿着香农当年提出信息论的思路一点点抽丝剥茧，讲解信息理论。

我们先来讲讲信息的量化度量。我在第一讲问过你，佐尔格给斯大林的信息作用很大，但是信息量其实不到 1 比特，那到底怎么去衡量信息量的大小呢？在香农之前，人们并不认为信息还能像重量、体积、电流一样可以用什么单位去衡量。

人们过去绞尽脑汁试图从信息的内容出发，通过对比重要性，度量信息。香农说，这条路其实走错了。对于一条信息，重要的是找出其中有多少信息量，要搞清楚「信息量」，就要对信息进行量化的度量。但人们始终没找到量化度量信息的桥梁，也就是缺少一个合适的「衡量单位」，比如你用天平称重，需要在另一边摆放相应重量的砝码，那衡量信息的砝码是什么呢？

香农最大的贡献在于找到了这个「砝码」，也就是将信息的量化度量和不确定性联系起来。他给出一个度量信息量的基本单位，就是我们第一讲所讲的「比特」。

「比特」是这样定义的：如果一个黑盒子中有 A 和 B 两种可能性，它们出现的概率相同，那么要搞清楚到底是 A 还是 B，所需要的信息量就是一比特。如果我们对这个黑盒子有一点知识，知道 A 的概率比 B 大，那么解密它们所需要的信息就不到一比特。

那么如果是多于 A、B 这两种可能性，更复杂的黑盒子，要消除它的不确定性需要多少信息呢？

比如我们做选择题四选一，或者猜世界杯足球赛的冠军是谁，他们想知道结果需要多少信息呢？有人说四选一需要四比特，猜出 32 个足球队参加的世界杯的冠军需要 32 比特。

这其实是不对的。如果我们对选择题的答案一无所知，去向一个知道答案的预言家请教，他每给你一个是非的答案，收取你一块钱。

对我们来讲，有效的提问方式不是问他「是否答案是 A，或者是否答案是 B」，而应该先问他，「是否答案在 A、B 中」。如果他回答「是」，我们就圈定答案的范围是 A 或者 B，与 C、D 无关。

接下来，再问一个问题就能确定是 A 还是 B 了。反之，当我们知道答案不在 A、B 中，我们也可以用第二个问题确定是 C 还是 D。这样我们一共付 2 块钱就可以了。

类似地，对于世界杯足球赛的问题，我们问五个问题，付 5 块钱就可以了。你可以自己在心里算一下。

当然，在信息论中不用钱来当信息的单位，而采用了比特。也就是说，要确定四选一问题的答案需要 2 比特信息，确定世界杯冠军的问题需要 5 比特信息。

我们把这样充满不确定性的黑盒子就叫做「信息源」，它里面的不确定性叫做「信息熵」，而「信息」就是用来消除这些不确定性的（信息熵），所以搞清楚黑盒子里是怎么一回事，需要的「信息量」就等于黑盒子里的「信息熵」。

我们知道，熵其实是一个热力学的概念，表示一个系统的无序状态，或者说随机性。比如把冰水倒进一杯开水中，它们会彼此融合，杯子里的「熵」，也就是混乱程度会增加；在信息系统中也是如此，信息熵则表示一个系统内部的不确定性。

我们都知道，一个系统中的状态数量，也就是可能性，越多，不确定性就越大；在状态数量保持不变时，如果各个状态的可能性相同，不确定性就很大；相反，如果个别状态容易发生，大部分状态都不可能发生，不确定性就小。这段原理其实很简单，你先记住它，接下来我给你详细讲解。

香农把这个原理呢，用公式表示出来了，从此信息不仅可以度量了，信息熵也可以计算了。信息熵的公式：

![](./res/2019033.jpg)

我们大家不用搞懂公式，但要明白这个公式的原理。我先解释什么叫「一个系统中的状态数量（即可能性）越多，不确定性就越大」。

比如，你买彩票，只有两个号，其中一个必中彩，不确定性就小，那么这个问题的信息熵就小。如果有 10000 个号，也是其中有一个必中彩，那不确定性就大了。

接下来，我再解释这半句：「在状态数量保持不变时，如果各个状态的可能性相同，不确定性就很大……」我们现在假定可能性的数量是固定的，比如在只有两种情况时，也就是非 A 即 B 的情况，信息熵的变化图类似一个抛物线：

![](./res/2019034.jpg)

图中的横轴是 A 发生的概率，它从 0 到 1 分布，纵轴就是熵，也就是确定它发生，你需要的信息量。你会发现，当 A 发生的概率正好是 1/2 时需要的信息熵达到顶峰，是一比特。

这就类似抛一枚均质的硬币，谁也猜不好结果，因为正反两种结果发生的概率一样，都是 1/2。但是，如果这枚硬币没造好，一面重，一面轻，那就大概率是重的那面朝下，需要确定它哪面朝下的信息量就小。

这告诉我们，永远不要听那些正确率总是 50% 的专家的建议，因为那相当于什么都没说，没有提供能够减少「信息熵」的「信息量」。这是今天的第一个知识点。

最后半句：「相反，如果个别状态容易发生，大部分状态都不可能发生，不确定性就小。」其实是这个意思：如果你买彩票要从 10000 个号里选出一个中奖的，不确定性就大多了。不过，如果其中一个号中彩的可能性是 99%，剩下所有的号加起来的可能性只有 1%，这个问题就比较确定，熵就小。

现在，你明白什么叫「一个系统中的状态数量，也就是可能性越多，不确定性就越大；在状态数量保持不变时，如果各个状态的可能性相同，不确定性就很大；相反，如果个别状态容易发生，大部分状态都不可能发生，不确定性就小。」这个原理了吧？

好，你知道了信息有单位，还可以通过公式计算，那又有什么用呢？

大家都知道赌球的庄家总是稳赚不赔，就觉得里面猫腻很多，这次我带你从信息论的角度来看清这个问题。你会发现其实很多类似的复杂难题都是信息熵的计算问题。

假如，我们能提前确定各个球队获得世界杯冠军的概率，设定它们分别是 P1，P2，……，P32。那么我们套用上面的公式，就可以算出这件事需要多少信息，或者说这个问题的信息熵。

我们假定为 3.4 比特，或者说对应于 3.4 块钱。如果有一个人提一次问题支付一块钱，从理论上讲，所有参加赌局的人只要平均支付 3.4 块钱就能得到谁是冠军这个信息。

但是如果设定赌局的人将收费标准略微提高，提高到一个人平均 4 元。这里面的盈余就被设赌局的人拿走了。

那你会说，我们不可能提前知道概率，那每个球队得冠军的概率是如何预估的？其实这是我们这些下注的人告诉设赌局的人的。

如果大家都往德国队身上下注，结果预测德国获冠军的概率就很高，所以押注的多少其实就是大家给出的概率。

而开赌局的，只要收费比信息实际的价值高，都是稳赚不赔的。这里面的细节大家不用太在意，总之记住一点，就是开赌局的从来不是拿自家的钱和你对赌，而是让你们彼此互相赌，他通过变相多收费盈利。

很多人会讲，我不参加赌局，不会被开赌局的人赚走钱。其实上述这类赌局在金融市场更多。

你可能听说过「结构化的投资证券」（Structured Notes），比如说石油的价格上涨到 100 美元以上，每 1 美元高盛就付给你 1.5 美元。但是，如果没有到 100 美元，你需要每个月付给高盛 1 美元。这种投资工具，就被做成一种结构化的投资证券。

像航空公司或者运输公司因为害怕油价浮动太高，会购买这样的投资产品。那么你以为是高盛在和石油公司，或者其他人对赌么？不是的，因为高盛转手就将和它完全相反的投资产品，卖给了希望油价波动的人。当然，高盛会包装得很好，让两边都感谢它，其实它才是真正挣钱的一方。

你可能听说过金融数学这个专业，那里面的人天天做的事情就是设计这种不容易为人所看懂的，自己永远不赔钱的金融产品。而所谓的基金经理，很多就是把这样的产品卖给你的人。

因此，多了解信息论和基本的数学常识，可以在生活中省下不少冤枉钱。这是今天我想告诉你的第二个知识点，希望你知道，很多交易和产品都是利用了信息的可度量性，知道了这点，就可以看清很多复杂交易背后的原理。

掌握了信息量化度量的原理，你还可以用它来对付当今「信息过载」的问题，比如如何判断一篇报道里到底有多少信息量。

信息说到底是用于消除不确定性的。如果讲的事情大部分大家都知道，信息量就很少。这也是为什么那些心灵鸡汤的文章大家不愿意读，并非是它们说的不对，而是没有信息量。

和它们相反的是，我前面介绍的三篇改变世界的论文，都非常短，特别是沃森和克里克的那一篇，一页纸多一点，但是把我们过去不知道的 DNA 的结构讲清楚了。这个信息量就很大。

## 要点总结

香农告诉大家，信息可以衡量，但不是用重要性，而是用信息量，单位是「比特」。

你可以把一个充满可能性的系统视为一个「信息源」，它里面的不确定性叫做「信息熵」，而「信息」就是用来消除这些不确定性的，所以搞清楚黑盒子里是怎么一回事，需要的「信息量」就等于黑盒子里的「信息熵」。

很多复杂交易背后其实都用到了信息的可度量性。

信息量的大小不在于长短，而在于开创多少新知。

这一讲我留给你的思考题是：如果你和一个特别会玩锤子、剪子、布游戏的人玩这个游戏，你最好的策略是什么呢？

预告：

有了信息的量化度量，我们就知道了信息的多少，但是如果我们还想知道具体的信息是什么，就需要对它们进行编码了。这是我们下一讲要讲的内容。

## 黑板墙

## 01

#### 1. 金勇笔记

前面三条笔记经过了一天的「洗礼」之后， 大家给了我很多的反馈， 我很激动，也很感谢大家。 

格式和长度在今后会做些调整，个人经历及延伸阅读部分将会减小篇幅。

今天给大家分享一段我和小宁主编昨晚的对话：

小宁：啥叫比特啊？

金勇：比特就是当你面临二选一的时候，两个可能性都一样的时候，你的选择成本呀。 二选一要用一比特，四选一就要两比特呀。

小宁：四选一我知道了，吴老师说的 32 选一，我在心里算了下，确实需要问 5 次。但是有没有办法只问 4 次就得出答案？

金勇：没有办法的。 这可以用归纳法或者二叉树去证明，就是 5 次询问，5 比特信息。

小宁：你这个树形结构、归纳法啥的，我看不懂，但我知道你的意思是说至少也要问 5 次从数学上可以证明。那这个简单的 32 选一的问题怎么套用吴老师给出的公式呢？

金勇：恩， 如果说 N 种事情等可能，所要用的比特数就是 log 以 2 为底的 N。 

小宁：哇，那这么算来，log 以 2 为底 32=5，也就是 5 比特，这是巧合吗？信息论可以直接告诉我们最简单的答案啊？

金勇：这不是巧合，你先记住今天吴老师给出的抛物线图，知道 0.5，也就是一半对一半是错，所带来的不确定性是最大的，结合下一讲的内容，我会告诉你为什么不是巧合了。

其实这段对话既有故意的设计，也有我的深意。  

1. 如果这件事情我真的懂了，我给小宁解释起来是应该是比较轻松的。

2. 你可以时刻给自己找一个「小宁主编」，经常问自己为什么、怎么来的，你会发现自己对某些知识的掌握程度是否扎实。

#### 2. 知识解读

结构化数据 （Structured Notes ， Structured Product）。

这是一个我今天才知道的金融学术语， 对我来说非常陌生。 但我发现它的组成部分我能看明白，通常由两部分组成：

- 第一部分是固定收益产品， 比如债券（Debt）；

- 另一部分是金融衍生品，比如期权（Call&Put）；

所以这个产品也是一种投资组合的设计， 而且据我看到的文章显示，这种金融产品其实就是「过度设计」的金融产物。 我希望你在投资的时候不要盲从，像芒格一样——做个笨人，不投自己不懂的领域。不知道你对「上帝喜欢笨人」这个标题还有没有印象，如果没有印象，去搜索看看？

这里再提个小建议，我们组的算法同事其实为了让大家更准确的搜索到感兴趣、全信息的搜索，做了大量的无名工作。 得到 app 其实今年是个转型之年，除了作为大家的课堂，她还可以是一处「知识引擎」，请你善加利用。

#### 3. 延伸阅读

延伸一， 关于单位公制

我对世界上通用的物理量公制有些好奇，有个网站介绍： http://www.us-metric.org/commonly-used-metric-system-units-symbols-and-prefixes/      

我想到一个有意思的问题，除了比特这个单位，还有哪些物理量的计算涉及到对数运算？

延伸二， 有同学和我要香农论文《通讯中的数学原理》的地址

http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf

#### 4. 前期回顾

我很担心同学把问题藏着掖着，耽误之后的理解。于是我跟小宁决定保留一个环节是答疑之前模块的部分：

问题：有同学问第一讲中的「三比特信息」是什么意思？

回答： 三个故事，每个故事都用归到一比特的信息，所以最后是三个故事三比特。

问题： 请解释「如果一种情况发生的可能性大，另一种发生的可能性小，所需要的信息就不到 1 比特」。

回答： 如果一种情况发生的概率是 p，那么另一种情况发生的概率是 1-p， 此时所要消耗的比特大小是：

-p * Log p - (1-p) * Log (1-p)

(空一行便于查看）

这个函数中 p 的范围是 0 至 1， 它的最高点就是对应于 p=0.5， 如果 p 取 0.01， 结果就是 0.08 比特。

问题：此时面对着一种情况 0.01 的概率，而另一种情况是 0.99，那我消除了多少不确定性？

回答： 在信息论的后期会提到熵的计算公式， 还有熵增（entropy gain）的概念。 所谓的消除不确定性，是指当我获取了这个新知后给整个系统的熵是否带来了更大的熵增。

在这里， 一种情况特别极端（99%）另一种 1%，如果这种现象为真，说明我接下来要考虑的很大概率上就是要去分析这 99% 了， 它给我带来的有「新知」的收获是很小的。

打个比方，你在上高中时来了一个同桌，他和你的所有知识体系有 99% 是高重合的，只有 1% 不一样。那这个知道你要从他身上学习到的新知+他从你身上学习就不会太多。 如果他有 50% 是你不知道的， 这种「你学习他的知识+他学习你的知识」所产生的新系统变化是最大的。

### 02

知道了一件事用信息量如何度量，再知道制造这些信息最小需要多少焦耳，我们就能在处理和传输信息时标定一个极值，在工程设计时尽量靠近它，我想优势肯定很大。对实体来说，不同介质里这个最小能量是不同的，不知道有没有和介质无关的，改变 1bit 信息对应的最小能量呢？

### 03

真随机，才是「诡道」。

如果和一个特别会玩锤子剪子布游戏的人玩，最好的策略为何？

万维钢老师提过「最小最大值定理」（Minimax theorem），冯·诺依曼证明，这是最有利的混合策略。推荐参考精英日课第三季博弈论 11 讲。

这个博弈论的精神是：

1) 按照一定的概率，混合自己的打法。

2) 混合的规律，必须让对手无法利用。

也就是设法让出拳的信息熵最大化，使对手要以更大的信息量来消除不确定性。通常深谙此游戏的高手，大多是掌握了概率论和心理学，若无法熟稔混合自己出拳策略，做到真正的随机也是增加信息熵的方法。

金融市场以信息熵来挣钱，了解我们为熵多付了多少钱，就能比其他人更看透庄家和玩家的本质。

### 04

最好的策略是提供不确定性。

会玩石头剪刀布的人一般会掌握大多数人出什么的概率，比如正常人会沿着「石头剪刀布」的顺序出，第一次出石头，第二次会出剪刀等。通过以上经验，他等于掌握了比你更多的信息。

此时应该提供更多干扰信息，一种是主动提供，一种是主动索取。

1. 比如出之前说一句「我这次出剪刀」，这样就打乱了对方的节奏，对方大概率上会出剪刀，那你可以考虑出石头。

2. 询问对方「这次你要出什么」，对方会直接陷入告诉你的和实际究竟应该有什么样区别的思考中。

### 05

对于这个特别会玩猜拳的人来说，我就是一个充满可能性的「信息源」，我出剪刀、石头、布的不确定性就是「信息熵」，对方特别会玩这个游戏，意思就是对方很容易猜我出拳的规律，用将这个规律作为「信息」来消除不确定性。

我的策略：因为强调对方更会玩，所以我的最佳策略不是以卵击石，也去猜对方的规律，而是打乱自己出拳的规律，加大随机性，让对方不容易获得「信息」。