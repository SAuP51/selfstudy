## 20231021. 方军 AI 个人生产力提升

狗霸：

今天我们讲座的分享者是方军老师，他是许多开智社区的同学们所熟知的一位。之所以如此，是因为在我们的「玩转 GPT 星球」活动中，你常常可以见到方军老师在星球中所做的那些分享。实际上，方军老师是一位行动力极强的技术专家。今天晚上，你们在他的讲座分享中，将听到非常丰富的关于生产工具以及他对 AI 的见解。

在今晚的讲座正式开始之前，让我们先简要地介绍一下讲座将会进行的流程。首先，我们会邀请阳老师 —— 作为生产力计划这个项目的主导老师 —— 来发表致辞。然后，阳老师会给大家简要介绍一下方军老师即将做的演讲。接下来，就是我们今晚的重头戏 —— 方军老师将会给大家分享大量的干货。在此，也请大家准备好水和零食，以便在吸收丰富的信息和知识的同时，享受这场知识的盛宴。在方军老师的分享结束后，我们会安排大约十到十五分钟，用于三到五个小问题的互动答疑。请大家在听讲座的过程中，如果有任何的问题，可以先在聊天区里面提出。在老师分享完之后，我们会从聊天区挑选一些问题进行解答。这就是我们今天晚上的讲座流程。

接下来，我们邀请到阳老师来给大家简短的致辞。

阳志平：

各位同学，今晚我非常高兴邀请到方军老师，为大家进行 AI 生产力跃迁计划的第一期增加直播讲座。

自 2023 年 3 月 15 日以来，GPT14 已经过去半年时间。当初有不少人对 AI 产生兴趣，但现在我们仍能找到这些人。有些人已经失去了新鲜感，没有继续投入 AI 研究。对于这批人来说，生活依然原地踏步，工作依然使用 AI 前时代的方式。

然而，与这批人相对的是，有一批人已经成为了 AI 时代遥遥领先的专家。他们在过去的半年中快速学习，不断调试，用作品说话，剧中发布了一个又一个产品，撰写了一本又一本书。

在这一批人中，我将其总结为两类：一类是 AI 生产力专家，典型代表方军老师。另一类是在各个先进的大模型团队从事实际研发，尤其是日常生活中接触不到的那些任务，例如大量的 GPU 和算力调试的人，称为 AI 工程师。我们发现，这两类人在 AI 时代已经相较于其他人领先更多。AI 生产力专家方军老师无疑是其中优秀的一位。

方军老师在 AI 时代之前，已经是在业界非常知名的技术作家。他曾荣获过中国好书记奖，并在 2017 年到 2018 年，由腾讯邀请出版了《平台时代》。他还担任过创业邦执行总裁和现代传播集团的 CTO。

许多人因了解区块链而了解方军老师。当时方军老师在 AI 诞生后，他的行动力和学习力比一般人强得多。今年他出版了两本与 AI 相关的书，一本是翻译的书《Chagpt 超入门》，还有一本是由方军老师撰写的书《成为提问工程师》。

未来方军老师开设的讲座可能会整理成相应内容。而且，这里面比光出书更重要的是，方军老师实际投入了一些产品研发。例如，在 5 月份，方军老师与我进行面对面沟通时提及，那时他从事了区块链和微博三部分的数据研究，并将其与大模型进行微调，最终形成了一个可回答区块链和微博领域的产品。

大家会发现在这个时代，社会分散问题越来越严重。一些生产力较强的专家和工程师掌握了更独特的生产力，并且适应这个时代的速度更快。我希望各位同学能成为像方军老师这样的人。

更具体的干货内容。方军老师已经准备了整整 78 页 PPT，非常精彩，我不忍心占用大家太多时间。我们把时间交给方老师。

狗霸：

好的，各位好，感谢阳老师的致辞。接下来的话，我将把最重要的时间交给我们今天晚上的主角嘉宾，方军老师。今天晚上，方军建师给大家带来的讲座的题目是「人工智能作为个人生产工具」。接下来，我们将在讲座的过程中一一揭晓。在讲座的过程中，如果有任何问题，希望大家能在聊天区提前提出来。

在我们的讲座结束后，我们也请方军老师与在座的同学们进行一定的互动和交流。接下来，让我们将时间交给方军老师。

方军：

感谢阳老师的邀请，我非常荣幸能够和大家进行交流。我在这个领域的工作经历并不长。事实上，我是在去年才开始接触一些 AI 编程和绘图工作，直到去年年底才较深入地开始研究现在的大语言预测模型 GPT。我后来发现，阳老师之前的产品 AI 写匠等，都是采用的旧版本的 GPT 模型。

然而，自从今年我们开始进入这个额域后，我逐渐认识到，我们这个行业可能有机会投入到大型模型的开发与研究中。于是，我们开始考虑利用现有的模型，无论是公司自有的，还是某些开源的模型，进行进一步的微调。我认为，尽管一些开源模型可以进行一些小的微调，但像 GPT-4 这样的最先进模型可能是我们真正需要的。

因此，我个人的工作经历基本上集中在这一个方向。今天，我想分享的内容可能会更窄一些。我想讲述的是，在我看来，当我们把 AI 视作生产工具时，我们应该如何去使用它。我之前曾和一些人简单地讨论过这个问题。我特别希望说清楚，当我说 AI 是生产工具时，我不是把它当作野外伐木工人背包里的瑞士军刀，而是当作电锯 —— 我真正去砍倒树的那个工具。如果把 AI 只当作辅助工具看待，会影响你对 AI 的理解和运用。







阳老师已经说过，今天我们不必太担心时间，因此我没有删减我预先准备的内容。我们可以顺着这个节奏，慢慢来分享我对这个话题的思考。今天我准备的 PPT 并非常规意义上的 PPT，因为在常规的 PPT 中，我会尽量减少文字内容。

本篇文稿实际上是一个介于讲稿和精简的 PPT 之间的文件。我的目标是尽可能以文字的形式将我的思绪明确整理出来，这样既能帮助我更好地思考，也可以详尽地展示给大家关于某个主题的具体内容。我想请我的同事们在讲座之后将此文稿分享给大家，你们可以在其中找到我所分享的详细内容。

首先，我今天的演讲需要预设一些前提假设。首先，我假设你已经听过人工智能专家阳老师的课程。自此，我可以预设你已经对生成式人工智能，也就是大语言模型和图像生成模型的基本原理有所理解。因此，我们就可以跳过它们的基础知识部分。其次，我假设你已经使用过一些语言模型的工具，无论是通过 API，用户界面，还是其他方式，不论是国内还是国外的工具。实际上，国内最近也开始出现一些杰出的模型，使用的感觉相当不错，特别是在处理长文本的上下文方面。

同时，我也假设你现在主要是以个人身份来使用语言模型，而不是在企业环境中工作。因为我的最近的工作经历主要是与自己的相关企业或一些合作的企业打交道，这与以个人身份使用模型的视角是截然不同的。

基于阳老师的定位，现在的听众中，一部分人可能是大模型的研发工程师，另一部分人可能在模型技术上进行进一步的应用。今天，我希望你能够根据你的实际情况去转换角色。如果你主要是做模型应用的，那么就把自己视为一个模型应用者，而不是模型开发者。

此外，我希望强调一点，那就是对于今天的主题 —— 大模型在工作中的辅助功能，编程实际上是最好的应用场景。虽然在这次演讲中，我避免举编程的例子，因为只有会编程的人才能理解，而其他人可能会觉得难以理解。但我始终认为，当我们使用大模型来辅助工作时，编程是最佳的场景。为什么呢？当我们写一篇文章或进行修改时，我们无法确定对方所修改的部分是否正确。然而，当我们请求模型帮助我们编写一段程序，修改一段代码，或者编写单元测试时，我们可以通过运行测试来迅速知道对方写的是否正确。相比其他场景，这是我们当前的模型能力最容易处理的场景。

现在我们来正式开始今天的讲座主题。我认为，当我们考虑一个 AI 相关的业务时，实际上可以从三个层次来理解。第一个层次是模型本身，带来的问题有：模型的基础原理是什么？其训练方式如何？以及训练过的模型有何特点，或者经微调过的模型有何特性。第二个层次是我们在日常工作中的应用开发。

当前的情况是，我们可能直接在某些 API 上加一层封装，可能是在语言模型或图像模型上加一层封装，或者将它与我们的具体业务数据做一定的融合，进行所谓的检索和增强生成。此外，另一个应用场景是我们可以将模型的能力与我们企业的业务流程或我们个人的工作流程相结合。今天我们要聚焦的话题便是：如何将大型模型，尤其是大型语言模型的相关能力，与我们作为一个知识生产者的工作流程相结合。

在这个过程中，我提到一个概念，即「个人知识产出」。实际上，无论你是一个独立的程序员、作家、研究员，或者是一名学生，你都需要产生个人的知识产品。在公司内部，你也可能有大量的工作，同样需要形成一份产出。这些都需要进行所谓的个人生产。

当我们从个人生产的角度来观察 AI 模型时，首先我们对 AI 模型有一个基本的认识：它已经将各种已知的、文本化的知识和能力压缩成了模型参数。然后，我们通过文本提示（prompt）或图像提示（mpt），将模型本身的知识和能力调出来。此时，我们会发现，以往的 AI 模型主要是基于判别式学习，而近两年兴起的模型实际上主要是基于生成式学习。

生成模型可以进一步分为两类：一种是使用文本生成图像，另一种是使用文本生成文本。当然，我们也可以进一步扩展，可能是使用文本来生成语音，或者是使用文本来生成视频，生成动态图像，或者是将文本转换成网页界面，或者是将文本转换成应用设计的用户界面。还有使用文本来生成 3D 模型等等。

但是，今天我们要聚焦的是大语言模型，因为刚才我们提到的所有模型，其核心都是从文本生成文本。然后思考，我们在训练大语言模型之后，实际上可以用来做什么呢？

在个人生态环境之中，我们可以用它进行外文的翻译，可以用 GPT 这样的模型来做问答助手，也可以用它来作为编程助手，比如 Curcuror，或者是 GitHub Co-Pilot。我们也可以使用它来编写和整理文本，比如在 Notion 里面就可以使用。如果我们正在写书，我们可以利用它来进行文字编辑。

但是，我们需要注意的是，这其中包含的图像生成的能力。

尽管本身并非专注于图像相关工作，但作为一个作家，我经常希望能在自己的书中插入一些精美的插图。在过去，这通常需要寻找专业设计师进行合作，由他们完成绘图工作。但在现代，我们可以利用 "me journey"、"SD" 模型或最近的 "TTB's LE" 模型来生成所需的插图。

今天我们所处的场景中，有一部分角色是教学。我最近也在与一些中小学教育机构进行讨论，也阅读了关于中小学教学的大量资料。我们发现，AI 也能够被用于教学辅助，这个角色有许多相关讨论。

我一直在思考一个问题，即在个人生产过程中，AI 扮演了什么角色。我对此有一个自己的定义，我认为 AI 是一个「十倍的生产工具」。有些人将它定义为生产力工具，我认为将它定义为生产工具更为贴切。是什么让我这样认为呢？

生产力工具，我们可能会用来记笔记、查阅信息，它的便捷帮助我们提效。当我们有一系列工具在手，这个工具可能只是其中的一个小环节，我们可以把它当成生产工具，就像在某些工作中，我们可以把 AI 当成一个主力的工具。

当我说 AI 是一个十倍生产工具时，实际上有两个不同于普通认识的地方。首先，我尝试把它量化为 "十倍"，试图揭示 AI 的具体力量。它可能是的效率提升了十倍。事实上，我们已经经历了许多 "十倍"。比如，如果我要制作表格，用电脑和手工制作的差距绝对是 "十倍"。用表格里面的公式，自动的图表等，可能又是一个十倍的差距。如果用上一些更特殊的，如 Python 脚本等工具，或者让 Python 去抓取数据再进一步处理，那又是能够提升十倍的效率。而现在，AI 或许可以在这个背景下，再次使我们的整个效率提升十倍。

再来回顾一下我们的历程：从手写到电子表格的工作效率提升了十倍，从普通电子表格到装配了复杂公式的电子表格又提升了十倍。当引入脚本，进行更复杂的分析，借助 Python 程序进行辅助，又可以提升十倍。现在，有了 AI 的帮助，我们又看到了一次十倍效率提升的可能性。

我相信，对于经历过 Excel 表格处理的人，都能理解我这番话的真谛。近期，无论我们是使用 AI 进行写作辅助，还是进行资料整理，同样会有类似的体验。但真正的感受，是在编程这方面。编程的特殊性在于，以往我们遇到一个问题，往往会觉得处理起来复杂且耗时。可能需要编写基础的程序代码，进行单元测试，并进行众多的测试运行，最后才能真正启动。再者，如果我们对相关的程序代码或语言工具不熟悉，就需要花费大量时间去学习和熟悉。因此，我们对于任何改动，尤其是对工程系统的细小改动，都会持严肃的态度，尽管这和我们的内心感受可能完全不同。

然而，如今我们可以将 AI 和我们的代码库结合在一起。我们可以在原有的代码库中轻松找到所需的代码。我们也可以让 AI 在现有的环境中工作，即使我们之前的单元测试没有做得很充分，我们现在也可以先补充完整的单元测试，然后再增加新的小功能，并进行测试运行，看看我们是否破坏了原有的结构，看看程序功能是否得到了改进。在这样的场景下，我们能够明显感觉到，运用 AI 能够带来十倍的效率提升。

第二个观点，我认为可以把 AI 定义为一种生产工具。与一种普通的中间流程中的工具不同，生产工具是与最终产品息息相关的。当我们把 AI 视作生产工具的时候，我们会发现它有其独特的特性。首先，我们必须完成一个创造性的任务，要达到一个目标，如创造出一个产品，或其他某种成果。此时，我们的关注点便会有所不同。我们将不再只关注于提高自己的工作效率，如工作 8 小时改为高效工作 10 小时。而当我们把 AI 视为生产工具时，我们关心的是，如何在短短几小时，或者在老板工作的一小时里，完成好工作，关注点发生了转变。

一般而言，我们要么被客户雇佣去完成某项任务，要么被老板雇佣去完成某项任务。又或者我们自己雇佣一个工具去帮我们完成某项工作。我们其实都处在被雇佣的状态中，去完成某项任务。这就是我们现在所处的社会环境。

在将人工智能视为一种生产工具时，我们首先需要思考的问题是，这项工具被雇佣来完成什么样的工作，即我们能否通过利用这项工具，将工作完成得更好。对此，我想引用一种源于产品创新领域的重要理论以加以阐释，这就是所谓的 "颠覆式创新" 理论。

"颠覆式创新" 理论由哈佛商学院的知名教授 -- 克里斯坦森提出。他在数年前因病去世，但其留下的这个理论对我们仍具有深远的影响。他提出，对于任何一个产品，你都需要清楚地明白，「你被消费者雇佣来干什么」。克里斯坦森曾给出过一个相关的例子，他发现在美国一家知名的早餐馆，顾客们特别喜欢购买奶昔作为早餐。

这个现象引发了克里斯坦森的兴趣，并进一步推动他进行深入的研究。他发现，虽然顾客们有许多早餐的选择，比如香蕉、甜甜圈、巧克力棒等，但他们依然倾向于选择奶昔。原因在于，对于那些需要驾车上班的顾客来说，一根香蕉或一块巧克力棒并不能长久地抑制饥饿感，而甜甜圈在食用过程中又会带来吃相不雅的问题。相较于这些选项，奶昔显得更能满足他们的需求。奶昔浓郁的口感可以给他们带来饱腹感，同时，便携的设计也让他们可以边驾车边品尝早餐。此外，奶昔中的果汁成分又让奶昔看起来更健康，不会像巧克力棒那样让人产生罪恶感。

因此，早餐馆就发现其实他们的奶昔是被顾客们雇佣来解决他们早餐需求的问题。由此，他们在奶昔中添入水果，使奶昔口感更稠，以此进一步满足客户需求。

同样的道理，当我们试图雇佣人工智能 (AI) 来完成一项工作任务时，我们也需要清晰地明白，我们需要 AI 完成什么样的任务。我一直在思考，如何更好地传达这个观点。此时，我想到了瑞达利欧，这位前乔瑞基金的创始人在他的著作《原则》中提出了「机器图解」概念。

瑞达利欧提到，我们可以将自己看做是大机器中的一个小机器，然后用这个机器来实现一个目标，形成一个结果。在实现目标的过程中，我们可以不断对比和调试我们的机器，以期进一步优化我们的效果。

在这个基础上，我也对这个观念进行了一定的扩展。那就是：当我们有一个目标时，我们可以利用这样的一个机器（本例中可以喻指 AI）来帮助我们实现我们的目标。就如同早餐馆对奶昔的改良一般，我们也可以针对 AI 的特性和能力，提出问题，并逐步找到解决问题的策略和路径。这样，不仅可以发挥 AI 的作用，还可以最大限度地满足我们的需求。

在讲述这一次的内容之前，我想先对我们的思维方式做一些说明。在我们应对复杂问题时，我们需要反复的审查和调试我们的机器，而这里的「机器」，并非是传统意义上的硬件设备，而是将我们自身看作是一种生产工具，从而洞察到其有哪些重要的组成部分。

首先，生产工具无疑需要人的力量，是人的创新和努力推动了事物的发展，而这正是我们在这个机器 —— 也就是生产工具 —— 中所扮演的角色。

其次，无论我们做什么事情，都应有一个标准的流程，或者说，一个标准化操作流程，即 SOP。比如，我们若要写一本书，首先需要构建一个想法的提纲，然后交流与不同的人，聆听他们的建议。随后，我们需要与出版社的编辑进行商讨，他们会再度进行市场调研。然后，我们就可以开始撰写、修改，最后按流程交付成稿。这是一个恰当的工作流。有了标准化的流程规范后，我们能够更高效地完成这样的任务。

再次，我们在完成任务时，会使用到各种工具。当今，人工智能（AI）作为一种工具，开始在各个领域发挥巨大的作用。不仅如此，它也会影响我们的工作流，甚至还会对我们的角色以及我们应该做什么产生深远影响。比如，有些事情中，AI 已经做得相当出色，我们不必去与 AI 争抢工作，反而可以把这些工作交由 AI 来处理。有些事情中，我们明知 AI 暂时无法做得很好，或至少在未来三到五年内无法完成。这时，我们应该将重心放在 AI 无法做到的事情上，这也会因此改变我们的角色。

因此，我想说的是，若我们将人的创新精神、标准化工作流以及 AI 工具等多重元素组合起来，我们就能构建出一个高效的个人生产机器。在这个整个流程中，人的作用至关重要。因为只有人才能设定目标，也只有人才能优化这样一个由人、流程和工具组成的生产机器。

至此，问题就变得相对简单了：我们该如何运用 AI 等新型技术工具，让我们的个人生产机器变得更高效？

接下来，我们就将深度探讨这个问题。在详细讨论之前，让我们先看一个 AI 翻译的例子。我并非专门从事翻译工作，但我在两个方面用到了翻译工具。一方面，我们在阅读大量的材料时，曾经在三五年前我们都是一字不漏的阅读所有内容，后来我发现利用诸如 DeepL 和彩云小译这样的翻译工具，我们可以通过查看中英文对照版本来理解文章内容。

首先，深度理解英文是至关重要的。这是因为我们可以通过阅读中英文对照版本来迅速提高自己的效率。诸多书籍尚未翻译，还有许多资料和文档可能永远不会被翻译。我们可以通过阅读中英文对照版来迅速掌握这些内容。

有了像 GPT 这样的译码器和 API，我们可以大量使用这种工具来进行翻译。例如，我们可以使用一个沉浸式翻译插件来翻译各种各样的内容，还可以使用 API 和文档处理工具来翻译 PDF 等文件。

完成翻译后，我们就可以看看翻译的成果。我可以分享一个我在三月份的个人经历。当时，因为对 GPT 的能力有所过高估计，我认为它的翻译效果非常好。然而，当一家出版社邀请我翻译一本书时，我婉言谢绝，因为我每年都会写自己的书。当他们坚持要找一位懂得相关行业知识的专业人士，也特别明白具体知识的人来完成这个翻译工作时，我只好同意了。

尽管我预计会使用 GPT 进行翻译，然后对其进行微调，但我依然低估了整个过程的复杂性。在开始翻译并将之出版时，我发现 GPT 的翻译质量并不能达到我期望的标准。在制作样稿时，我就发现这是一个问题。因此，最后真正的样稿还是我人工翻译的，我完全没有使用 GPT。

当我开始正式翻译时，我意识到如果完全依赖人工翻译，我将成为一个专业的译者，这是我无法接受的，因为我并没有那么多的时间。于是，我开始寻求机器的帮助，希望通过机器辅助完成翻译工作。

在这个过程中，我使用了三两种不同的工具：DB2、GPT-3.5 和 GPT-4。三种工具都进行了翻译。我选择了 GPT-3.5 是因为我发现，尽管我们通常认为 GPT-4 提供的翻译质量更好，但 GPT-3.5 的译文更像人类的语言。我也没有明白，为什么 GPT-3.5 的翻译结果更像人说话，至今仍然是一个谜。

最后，我在阅读英文原文、参考 GPT-3.5 和 GPT-4 提供的中文翻译版本后，再次人工完成了翻译。尽管过程繁琐且耗时，但我确信这是确保翻译质量的必要步骤。

在整个翻译及修订过程中，我们不可避免地会面临一些难题，而我们会选择使用大语言模型 GPT 来解答这些问题。因为这些问题全都与 AI 相关，我们在明了这些后，会进入具体的校对和润色环节。到了这个阶段，你会发现 GPT 的能力被充分发挥出来。

他会给出校对建议，如在一页纸的篇幅里，可能会提供三四个建议。在这三四个建议中，你会发现其中可能有三个满足需求，其余的可能就不太合适。有时他会指出一些难以理解的地方并能提供明确的修正意见。而在我们逐一校对的过程中，我们要求他找出那些不太符合中文习惯的表达，他给出的建议也让人相当满意。

所以在整个过程中，我们发现 GPT 在文稿翻译的开始阶段，只是充当一个辅助角色。然而，到了校对和润色的环节，他的能力就开始真正展现出来。在这个阶段有一个启示，当他处理一个较小的片段时，他可能会给出许多有价值的建议。如果有专业的人根据他的建议进行相关处理，就可能得出有价值的讨论。

还有一个事情值得一提的是，尽管我没有把整个过程记录下来，只能口述阐述我对这个过程的感受，我发现我们行业里有一位好朋友，宝玉，之前是微软 MPAP 的专家，后来获得了美国的工作签证，移居美国工作。今年他也发现了 GPT 的优秀之处，他使用 GPT 翻译了很多关于 AI 和 GPT 的课程，比如吴恩达的课程。在这个过程中，他完成了翻译，同时也将他在翻译过程中获得的经验和启示，写成了诸多出色的博客文章，并在推特上做了分享。接下来，我们要看的就是他分享的一些经验教训。

在他的分享中，我们可以看到宝玉老师在翻译的经验中，提出了如何设置 prompt 的问题，如何为我们的文本创建上下文，如何提出问题等等。我们要做的就是按照他的经验，来看看如何设置 prompt。这个 prompt 与我们今天看到的 prompt 已经十分相近 —— 首先设定一个角色，你是写作人、计算机专家、还是认知科学家？你的风格是什么样的？然后给出任务，你需要将某个英文文字翻译成中文。在给出任务的同时，也会设定规则和输出要求。关于这个部分，我们也在别人的基础上汇总了一个模板，这将在后面展示给大家。

在第二部分，宝宝玉教授在进行翻译工作时，采用了一种独特的上下文翻译法。我们通常在翻译时，采用片段式的方式，即输入一段文字进行翻译，得出结果后再输入下一段。然而，宝宝玉教授的方法却不同。由于字幕的长度通常并不长，一个 10 分钟的视频的字幕，可能也就只有一千到两千个单词。因此，他在翻译时，会将整个上下文，也就是全部的字幕，输入到翻译系统，然后只让系统翻译其中的某一块。

这种方式带来的好处是，鉴于目前的 GBT（Generative Pre-training Transformer）模型可以理解大约四千个 token 的上下文，它可以让 GBT 理解整个上下文，并集中精力对当前需要翻译的部分进行翻译，这样往往能够得出比较理想的结果。然而，之后宝宝玉教授也对这个方法进行了反思。在其博客发布后，他在推特上表示，将整个文本放入模型进行翻译带来的效果改进似乎并不如他所预期的那样显著。他认为，可能只需要输入前后几句就足够了。因此，我们在进行长段落的翻译时，可能只需要把前面和后面的部分输入到模型，让模型进行中间部分的翻译即可。

宝宝玉教授进一步指出，实际上在进行翻译时，有一种值得探索的技巧。这是他在之前使用 GBT 进行文本润色时所使用过的方法：当我们对某个表达方式有疑虑，不知道该如何修正时，我们可以让模型生成多种可能的翻译方案，然后我们可以从这些方案中选择一个，或者结合这些方案来生成新的翻译。这种方式可以有效改善翻译的效果。

另外，对于像字幕这样的翻译，我们要逐行逐一进行核对和翻译。在这个过程中，我们可以为每一个页面生成几个不同的翻译方案，并通过人工智能和人的协作，最终得出尽可能贴切和准确的翻译结果。

第三个技巧是，人的参与在翻译过程中是非常重要的。因为在翻译过程中，总会遇到一些我们不太理解或者理解得不够清晰的内容，此时我们就需要去寻求更深层次的理解，追问是其中的一种方法。与 AI 互动是这个过程的重要组成部分，特别是当 AI 能起到独特的帮助作用。我曾经一度倾向使用所谓的「批量处理」方式，因为程序员的思维倾向于一次性解决问题。今天我们有 API，我们可以进行批量处理，一次性得到结果，这看上去是多么的高效。然而，我后来发现，在我们使用大语言模型时，模型的交互状态可能正是我们所需要的。同样的，翻译过程也是如此。当我们在进行翻译时，一旦发现有问题，我们就需要与模型进行交互，以解决问题。

在探讨新词的准确含义时，我们可能从 AI 那里得到更准确的答案。我记得有个例子，它来自一次 Open AI 的 CEO 的演讲，中间提到了一个词，叫「training wheels」。然而，在首次翻译这个词时，AI 模型把它简单地翻译成了「训练轮」，这在走马观花的听读中可能并没有什么问题。但实际上，这并不是其准确的解释。

当我们进一步询问这个词究竟什么意思时，AI 模型提供了一大段解释。我们赞同其中的一个解释，并要求 AI 重新翻译该句话，这次得到的结果更为精确。AI 这次的翻译表明，「我们需要像调整孩子自行车上的辅助轮那样，调整 AI 的训练方式。」这样，我们明白了「training wheels」其实是指孩子自行车两侧的辅助轮。

一个有意思的副产品是，我自己也了解到这个词的真实含义。几个月前，我就为孩子装备了一辆有辅助轮的儿童自行车，但在那个时候由于忙碌，我并未意识到这个词的真正含义。然而，当 AI 给出答案后，我突然恍然大悟。

虽然今天，因为程序员可以直接使用 API 批量处理信息，但我们依然要享受与大语言模型 GPT 模型交互的乐趣。因为这种方式可以最大限度地利用 AI 的优势。在这个过程中，我们也在学习和理解所谓的 "提示语"(prompt) 应如何使用。

比如，我们发现使用中文的提示语，在大多数情况下，GPT 模型也能够做出相应的反应，甚至理解的很好。但如果使用英文的提示语，效果往往会更好。我认为，这一方面是因为 AI 对英语的理解更为准确；另一方面，也与我们中国人的英语水平有关。我们讲中文时，可能会比较模糊、含糊，因为我们总是预设对方会理解。但当我们讲英文时，我们往往会退回到基础水平，耐心地解释我们要表达的东西。这样做的结果就是，我们写出的英文提示语的效果更好。

之所以有这样的体会，是因为我们在使用中文提示语时，经常需要进行修改，然后对比原来的中文提示语，发现我们用英文写出的提示语更为直接、基础，最终能够得到更好的结果。这也提醒了我们，尽管我们很可能会遇到理解错误的情况，但是通过在交互过程中深入探询，我们可以最大化 AI 的理解能力和其提供的价值。

因此，当你在工作中需要反复使用某一提示语时，我建议你考虑用英文来撰写这个提示语。当然，你也可以先使用中文，再将其修改为英文。关于这点，宝玉对此有一些补充的建议。他提出，因为机器翻译难免会让人感觉到一种生硬机械的翻译感，如何改善这种情况呢？

他提出了一个由两步构成的方案。首先，他设想有一位英语老师，你先让他将这个英文翻译成中文。其次，又设想有一位理解英文的中文老师，由他来将这个翻译版本的中文再改写成符合中文表达习惯的平易近人的语言。通过这种方式，尽可能地消除那种机械式翻译产生的冗余和生硬感。我们当然可以做的更多，比如，我们可以提供一份特定风格的语料给这位中文老师，让他参照这份语料的风格进行改写，这样就可以得到更好的结果。

实际上，这个方案背后使用的是所谓的 "思维链" 的方法。关于思维链，我们有许多不同的讨论。有时，思维链就是将任务分解，然后让模型在推理时集中注意力于当前的任务。这样，模型可以更加聚焦，从而得到更好的效果。因此，一个英语老师负责将英文翻译成中文，然后又有一个中文老师将这个中文稿子进行改写和优化，这样所得到的文本就更为通俗易懂。

至于思维链的技巧，我相当喜欢的一种方法就是将问题自行分解。我在 OpenAI 发布的使用指南中，也看到类似的建议。该指南建议，作为程序员，在使用 AI 模型时，你可以让它进行内心独白。这种 "内心独白" 并不是源自心理学的术语，其表示的是将 AI 在思考过程中的所有步骤都写下来，指导其按照某种特定的逻辑进行推理。然后，在将结果呈现给最终用户的时候，将这个 "内心独白" 部分隐藏，仅展示最终的结果。这个过程，实际上是在进行一种内心独白的方式应用。你会发现，当你将这个过程打印出来后，得到的结果通常会更好。

当然了，这种方法可能会消耗你大量的 tokens，甚至耗费你额外的 API 费用。但这也是符合原理的，因为如果模型在思考过程中没有进行完整的内心独白，而是直接跳跃性地推理，快速得出一个结论，那么它可能会忽略掉一些重要的信息。

在您请求 AI 一步一步地详细记录其思考过程时，它会进行更深入的思考，因此最后产出的答案更符合需求。然而，我们必须问自己，如何让计算机对 PPT 进行翻译以更精确地满足我们的要求呢？

教授宝玉进行了一项新的尝试。他引入了一个新角色 —— 一位校长，来进行翻译结果的校验。这位校长将用宝玉教授翻译的原始英文以及中文翻译版本来进行对比和校对。然后，杂校长将提出他认为该如何改进翻译，以及哪些地方可能存在问题。

打造这样一个流程，铅笔 PPT 的翻译过程会随着复杂的提示语出现而变得清晰。让我为大家简单概括一下这个过程，以便大家可以更详细地理解这个提示语。首先，英语老师开始执行任务。接下来，中文老师根据原文进行翻译。然后，校长会使用 GBT 模型的能力，将中文再次翻译回英文。

在中文被翻译回英文后，校长就能更方便地校验翻译结果。他会对照原始的英文，将其与翻译后的英文进行比较。这使得校长能以不借助中文的方式，直接对翻译结果进行校验。

校验完成后，校长会提出相关建议。然后这些建议会回馈给中文老师，中文老师在收到建议后，会根据这些建议进行相应的修改，以得出最终的翻译。

让我们实事求是，这个过程虽然在中间阶段会消耗大量的 token，但通过几轮此类处理后，您得到的翻译结果确实会比单一请求 "将以下英文翻译成中文" 的精简方法得出的翻译结果更为优秀。这就是我们希望通过更深入、更精细的流程来提高翻译质量的原因。

首先，无疑对于翻译结果，大家会有各自的观点。你可以自行携带这一套指导方案，尝试用你专业领域的语料进行翻译以便校正其中的部分内容，看看如何将其调整以满足你的需求。让我更正一下一个偏差。同时，宝玉老师后来提出了一项新的修改建议。他指出我们前面执行了五步，虽然看起来逻辑很顺，但实际效果却似乎并非如此明显。那是否有可能进行进一步的简化呢？

他后来发现了一个简化的方法。这个方法就是先让一个英文老师进行直译，然后有两个中文老师进行不同风格的意译。最后，校长将英文的直译和两位中文老师的意译做一个整合，三者结合起来得出一个结果。最后得到的结果与之前的那个含有回忆过程的效果看起来差不多。

对于这个方法我进行了简单地测试，实际上，从我现有的英语和中文水平来看，我认为这两者的效果都相当不错。然而，我只进行了几次试验，并未进行完整严谨的测试，这只是我个人的感受，它的结果符合我们当前的感知。

在这个过程中，实际上我们只是做了简单的翻译工作，但我们发现了涉及到许多不同的技巧。例如，我们将全文作为上下文，仅将一部分直接转译。然后，我们用 UGB 进行了多重翻译，并由人进行选择。在翻译的过程中，我们进行了追问。可能会有客户满意度跟踪这样的方式进行二步翻译，期间也产生了多步操作，引入了新的角色。最后，我们通过回忆进行校验，等等。当我们在一个具体的细分领域里，如果我们想通过提示语，模型，和提示来更好地调用模型的能力，实际上会出现许多独特的技巧。

但是这些技巧并不是说，你只要掬一把浑水泼上去，模型就能得到好的结果。因为漫天飞舞的都是类似的说法，像是你只要按照一定的方式提问，就能得到结果。实际上，你只有将模型与专业领域做出精准的融合，你才能得到一个好的结果。而且只有在这个融合的过程中，我们才能依赖我们自己的专业能力去作出相应的判断，进一步调整这项技术。最后，我们就能得到一个效果好，成本合理的提示方案。

我曾深思过，如果 AI 能全程管理图书的翻译流程，可能会呈现出怎样的景象？根据我个人现阶段的理解，最初步和基础的辅助工作，如 AI 生成不同的译稿，然后由人工基于这些译稿进行翻译修订，这种方法完全可行。这其实与我以及宝玉老师所采用的方法有许多共通之处。我们在尝试这种方法的过程中，会发现当我们的中文表达不足的时候，我们会主动参与修正错误或者做些必要的补充。

对于那些我们人工操作的部分，我把它们标为蓝色；而对于 AI 可以进行的工作，我则用黄色来标注。然后，在这一系列过程中，当我们进行到编辑老师的校对环节时，你会发现，在某些环节上，AI 可以更好地发挥其功能。

总的来说，我认为，当前在一个完整的业务流程中引入 AI 作为生产工具时，我们实际上需要引入一种流程思维。我们需要将整个业务流程分解为许多部分，并确定哪些部分适合 AI 处理，哪些部分需要人为深度介入。然后，在使用过程中，我们逐步引入相关的 AI 能力。

当我们提到 AI 时，我们并不只是局限于一个特定的 AI。就算是基于 GBG 的模型，我们也认为 AI 具有许多不同的能力。我们通过设定一些提示语来把 AI 的能力局限下来，使其能适配到我们特殊的流程中。

所以，我想分享一个看法，即在将 AI 作为生产工具使用时，它需要与实际的工作流程充分融合，而并不是追求「端到端」的自动化过程。比如，有人会说：「我让 AI 直接为我写一个脚本，或者我指定一些设定，然后让 AI 为我写一个穿越时空的故事。」但实际上，这并不可能实现，因为这个过程中需要很多人为的介入。

关于这个论点，有一个著名的设计理论，即在迭代的过程中，人应该主导这个迭代过程。我这里画了一个形象的图说明，我们将一个业务分为多个流程，有的流程中 AI 的参与较少，有的流程中 AI 的参与就相对较多。像翻译这个业务流程，最后一步是人工进行的校对环节。其实在现今，AI 可以为此环节贡献 80% 的工作量。

但是也有一些环节，比如最后的定稿环节，AI 可能不能百分百靠谱，最多可以帮你快速预览一遍，但定稿还是需要你的主编，甚至作者本人来完成。所以，这是我对在将 AI 作为生产工具使用时的首要启示。接下来，我们将继续讨论如何使用 AI 来改造我们的工作机器。

在刚开始的讲座中，我首先提到了在基于深度学习的逻辑框架上，我们应如何去理解和利用机器 AI。我们需要将整个过程定下一个明确的目标，然后用这个目标来指导深度学习机器的行为，并由此得到一个结果。在得到这个结果之后，我们将其与设定的目标进行对比，这可以使我们清楚地看到应该如何优化我们的机器 AI。

在实现这个过程的时候，我们主要依赖三个部分：其一是我们自身，因为人是机器 AI 的最主要用户和调试者；其二是我们执行的工作流程，也就是常说的标准作业程序（或简称为 SOP）；其三是我们正在使用的各种各样的相关技术工具。如果我们想用人工智能（AI）来改造自己的机器，我们应该怎么做呢？

我通常认为，无论我们是在使用任何一种技术工具，还是作为程序员引入新的库，或者引入一个新的云服务，这些操作都可以分为四个步骤。但在众多的技术书籍中，一本本的「从入门到精通」似乎变成了「从入门到放弃」，我们会发现，实际上想要真正精通一项技术，往往非常困难，我们可能在操作过程中就会选择放弃。

那么问题来了，我们如何有效的使用这个技术工具呢？最有效的方法，我认为是先去理解它的基本原理和工作方式。这点实现其实并不难，因为这个技术工具毕竟是有人创造出来的，我们这些灵活的用户总是能够理解并挖掘出它的潜力。然后，我们需要评估这个工具的优点与不足，以及确定它是否适用于我们的具体环境。

而，什么时候我们最容易放弃一个工具呢？通常是在我们实际并不需要它，或者说用不用这个工具对我们来说没有明显区别的时候。但是，如果这个工具的某个功能我们是必须要用的，那么我们很可能会坚持下来，甚至可能会熟能生巧，然后在熟练和精通之间进步。在这种情况下，我们就不太可能会从入门到放弃，只有当我们必须使用某个工具的某个功能时，我们才可能不会放弃它。

因此，我认为在引入新的技术工具时，我们需要找到该工具上的一个「单点」—— 即那个能让我们真正产生效果的点。一旦我们发现这个「单点」的效果非常好，我们就可以尝试着把这个「单点」的规模大大放大，这样我们最终就可以获得更多的效果。

在实际操作中，如果一个公司内部的员工发现了这样一个「单点」，并且这个「单点」带来的效果非常好，那么公司其他的员工也有可能会用上这个方法，这对于整个公司来说都会带来很大的效益。因此，无论我们过去的几年中如何使用技术工具，我都认为这四个步骤是非常关键的。

那么，当 AI 大语言模型出现之后，我们也同样需要遵循这四个步骤。无论是在调试机器 AI，还是在引入新的技术工具，这四个步骤都会始终如一的指导我们前行。

今年上半年，许多人踏出了对于人工智能技术学习与理解的第一步，旨在探寻其中的奥秘原理。有一种观点，短时间内，无论是专业人士还是公众，似乎都已经基本了解了这个技术。其中，有一个重要的原理就是转化器（Transformer）模型的运作方式，它是很多人学习理解过程中的重要步骤。部分人会进一步了解每一层层次的功能与工作原理，还有的人则会扩展深入到各种不同的模型，如语言模型、图像模型，以及各种先进的技术如 CTRLT 等。

我们经历了理论的了解后，自然就会实际应用测试。在这个过程，拥有交互界面的 API 接口为我们提供了巨大的便利。我们可以借助它进行各种图像生成的试用，对自己设计的模型进行训练。而当我们遇到困难或者问题时，我们会搜索相关的技巧或者指导，这些都会大大提升我们的研究进度。

我们作为技术人员，日常工作中需要使用更高级、更复杂的工具。不过，我自己曾进入了一个陷阱，那就是对开源模型的微调。我试图通过微调来提升模型的效果，但是最后发现，相比于闭源模型，开源模型的效果反而不如人意。于是我又回到闭源模型的研究之中。

在使用这些模型的过程中，我们发现了一个问题，那就是这些模型并不能理解我们的专业知识和新兴知识。特别是我们这些专业领域的知识，于是我们采取了解索增强生成的方式。我们输入大量的资料库，研究如何最有效的处理这些资料库，尽快准确地提取我们想要的内容。这是一个充满挑战的过程，我们也曾经走过许多弯路。

然而，当我们在对模型进行某种程度的更改之后，我们需要进行测试，验证我们的改变是否提升了模型的性能，是否达到了我们的期待。这个过程需要我们投入大量的时间去了解模型性能的评估方法，无论对于我们改进后的模型，还是如 IAG 和 n untime 之后的模型。仅有在评估后，我们才能安全地在生产环节中使用这些模型。

总的来说，这些都是一种理解的过程。在这之后，我们还需要对技术本身进行全面地评估，这是一个很多人容易忽视，但非常重要的阶段。我们需要对技术决策进行远瞻预判，例如，我们预判 GPT-5 将要到来，或者预计不久的将来会有很多与 GPT-4 相近的中国本土模型落地应用。

值得注意的是，当我们在进行应用开发时，如 GBG 在中国的应用实践中，我们已经遇到了一定的困难。如果我们想要开发一些更具野心的应用，我们可能需要放弃已经不能满足需求的 GBT-4 模型，而转向国内经过验证的模型。这就需要我们评估与跟踪这些国内模型的发展，以预判它们何时能够达到相对理想的性能水准。

自然语言处理中的技巧实在是琳琅满目。举例来说，我们或许无法直接采用 GPT-4 模型来得出最终的结果，但是我们完全可以将微调过的模型，或者是国内某模型经过微调后，和 GPT-4 进行混合使用，这样便能够优化出期望的效果。然后在通过 GPT-4 对这个混合模型进行校准，校准完之后再正式投入使用。

当然，在此过程中，我们需要对当前深度学习模型的发展态势有较好的认识，尤其是需要了解这些大语言模型的局限性，以及可能潜藏的风险。例如，我在今年四月所参与的一个项目，在上线前的最后几天，我们发现其在安全问题上处理得并不理想，安全异常不是只有那些违背广义价值观的问题，因为这样的问题，GPT-4 已经为我们预设好了一套处理方案。然而我们那时所碰到的问题，主要是与中国特有的社会环境有关的问题，这些问题的解决缺乏成熟的措施或者解决方案。

这些问题必须解决，否则产品无法投入使用。如果你在自己的企业内部使用，可能只涉及到几十个人，或几百个人，问题可以尽量被控制。但是一旦你打算将其推广给不特定的公众，这些问题必须得到妥善的处理。在这个项目进行过程中，我们感到深深的压力和风险，这个所谓的风险就像一场意想不到的惊吓。

当然，既然有了对风险的觉知，便能够找到解决的办法。事实上，只要你意识到且面对风险，找到解决方案并非难事。我们也需要从更广的视角来看待这个问题，比如这个模型可能会对社会或者产品带来何种影响。我们必须时刻提防，避免我们的产品被那些有意使用这些模型恶意使用的人所利用。

在这个 использовGPT 模型来模型来解决实际问题的过程当中，我开始感觉到我们需要深入了解和评估这个模型。回顾了一下我自己和别人向 GPT 模型提问的方式，我认为在使用这种大型语言模型的时候，我们需要遵循一些基本原则。这些原则应当以个人的视角为出发点。

我们必须明白，尽管看起来 GPT 模型可以理解和生成语言，并且具有一定的推理能力。但是如果我们从更基础的层次来理解，这个模型的基本运作原理，是通过大量的语料学习和调整参数，然后在运行时通过预测下一个词，以构建出连贯的回答。这一过程中，模型的能力得到了泛化，表现出来的结果看起来很像人的智能。然而，如果我们回归到根本，实际上模型在做的还是预测下一个词。

当我们从这个角度理解和对待模型时，我们就能够解决很多我们在长期使用模型过程中遇到的问题。比如一开始我们往往会忽视模型的错误，认为模型只不过是在做预测而已，可能会出错，我们需要人来做判断。然而当我们抛弃这种轻视的态度，我们真正地理解并用心对待模型时，我们就可能在对人工智能这个领域有更深的把握和理解。

在他的讲解过程中，语言显得非常专业，并且非常具有权威性。对于一些高深且复杂的知识，他常常能深入地讲解，十分冗长。并不是专业人士可能无法理解，而他却能如数家珍地说出这些知识，让你感觉他随口一吐就是一篇论文。在这样的情况下，普通人很有可能会毫无保留地相信他。然而，当我们向他们揭示，他们正在使用的实际上只是一个大语言模型，它其实并没有他们想象的那么智慧，而只是根据已有的数据信息来预测下一个词语的产出，他们对大语言模型的过度信任就会得到一定程度的修正。因此，在推广这类 AI 产品的时候，有必要向普通用户解释，他们不能过于轻信大语言模型所给出的答案。另外，大语言模型会创造许多的幻觉，而这些幻觉并不一定是模型本身的问题。

如果你深入理解大语言模型的工作原理，你会明白它是如何通过大规模的数据学习，根据给定的一段文本进行延续性的生成。如今，我们将这个概念扩展至问答系统中，你只需输入一个问题，它便能根据学习的知识给出一个合适的回答，这其实也是一种反向的延续性生成。然而，问题的提出者可能会无意间将大语言模型的回答引导至错误的路径，这并不是模型的错，也许是我们自己的问题。虽然我会从常规的角度去解释这个问题，但实际上我更注重我们作为一个提问者对问题的思考。

以一次实验为例，我曾经问过大语言模型一个问题：「请您解释一下杜甫的窗前明月光是什么？」这其中包含了两个误导性的陷阱，首先，并没有一首叫「窗前明月光」的诗，其次，「窗前明月光」其实是「床前明月光」误写。然而，当这样的问题出现后，大语言模型会继续按照我们的问题进行解答并即兴创作，比如说，「这首诗表达了诗人的某种心情。」在某些情况下，模型无法识别问题中的误导，但如果模型具有高级的理解和判断能力，它就可以发现我们提出的问题存在错误，并纠正这些错误。因此，我们经常会使用这样带有误导性的问题去测试大语言模型的表现。

我还会使用类似的方法进行另一项实验。我曾经问过一个问题：「为什么鲁迅和周树人不能够互相争吵？」一款国内的大语言模型立刻回答说：「他们都是民国时期的知名知识分子，为什么他们不能和平相处？」这让我们对模型的智能程度感到困惑。然而，随着时间的推移，到了七八月份，我们发现许多模型对于这样经常被用来测试的问题，已经有了比较好的改进并给出了正确的回答。因此，向大语言模型提问时，我们需要了解它存在的幻觉问题。

第三，当我们向 AI 提问时，包括宝玉老师早些时候的提问，我们实际上都是采用一种结构化的提示语。

该讲座主要内容是介绍了一种由海外工程师编写的技术教程中使用的解决问题的框架，该框架将问题解决的过程分为四个步骤：指令（Instruction）、上下文（Context）、数据（Data）和输出（Output），以此形成了 ICDO 模型。更具体地说，当我们用这个模型来和聊天机器人交流，例如让其执行某项任务时，我们就按照这个顺序给出指示。例如，「你帮我做......」，然后机器人就会理解我们的意图，按照指示去执行操作。接下来的讲座会进一步详细解析这个模型。

另一个值得注意的模型是 GBG 三模型，它从对应的学术论文中提炼而来。此模型把语言模型视作一种学习器，能够从我们的指导和提示中学习，并在处理大量新的信息时对这些指导产生反应。比如，我们可以在提示中添加足够多的信息给聊天机器人，让它学习并理解这些信息，在接下来立即对我们提出的问题作出回答。这样的回答通常能够达到我们的期望，因为聊天机器人的回答主要是依靠理解和推理，而不是去其庞大的信息库中寻找答案。这样的方法也克服了由于同一问题可能有不同的答案，机器人无法确定哪个答案更适合的问题。在我们提供了信息后，聊天机器人可以针对当前给定的信息更好地进行回答。

我们发现引导模型进行链式思考是很有效的，这在许多讨论中都得到了证实。我从「快速思考与慢速思考」的概念中得到启发，认为让模型执行链式思考其实就是让它运用两种系统：快速思考（即直觉）和慢速思考（即理性推理）。当我们引导模型进行链式思考时，我们要求模型按照一定的顺序，步步为营地逐步推理出结果，而不是直觉性地一次性给出答案。这也解释了为什么链式思考能引发进一步的思考，因为它是以步骤为单位，逐步深入思考。

然而，有时不是我们要求模型一步一步思考，然后让它全部执行。更常见的情况是，我们在外部将一个大任务分解成许多小任务，再让模型去执行。执行这种方式的主要原因在于，虽然今天的模型可能能完成一项大任务，但在完成后，我们无法确定其结果是否符合我们的预期，也无法知道其在整个过程中是如何工作的。因此，通过将大任务分解成小任务，能让我们更具信心地指导模型的工作。

确实，当我们面对终局结果时，往往并无足够的信心去预判其是好还是不好。不过，情况会在我们对任务进行分解后发生变化。我们可以逐步完成任务，通过每一步的执行，我们都能对它的结果进行合理的评判 —— 它的结果是好还是不好。在每一步步骤结束时，我们能对整个过程产生信心，进而对最终的结果产生信心。在执行过程中，我们也鼓励相关人员介入其中，以期通过他们的参与、优化，使最终结果更加理想。

同样，当我们把一个复杂任务分解为简单的步骤后，那么在每一步的执行过程中，我们都可以利用 AI 模型进行优化。这样，在优化我们的步骤后，每一步的结果可以更进一步地优化，使得整体的结果更优秀。显然，这种方式要比我们编写一个提示语句，给出一个模型，然后让 AI 模型直接给出一个推理结果的方式要好很多。

接下来进入原则之六的内容，即我们要将复杂的任务拆解为简单的任务。例如，如果我们提出的问题比较短，那我们的问题本身就比较简单。但是当我们提出一个很长的问题时，那我们就会涉及到很多部分。在处理这些部分时，我们需要用不同的方式，使得语言模型能够很好地理解它是什么。如，代码可以用反引号标示，长段的文章建议用三个英文引号等等。在举例说明的时候，我们用什么样的方式来进行编号，都没有特定的规式，只需要采用一种相对固定的方式，以便让模型更好地理解。找寻和借鉴各种经验，通过尝试，最终找出一个自己对现阶段满意的方法，这就需要每个人自己去做。

最后提到第八个原则，也许是最重要的一点。我们常说 AI 就像机长的副驾驶，但我们仍应坐在主驾驶的位置。坐在主驾驶位置的我们，肩负着四个角色的职责。首先，我们需要明确一点：我做的这件事情的目标是什么，或者更深入一些，我做这件事情的目的是什么？只有人类才会去追问这个问题，机器是不能做到的。第二，我们需要了解 AI 在哪，了解它的状态、位置。第三，我们要有判别和鉴赏的能力。在判断方面，我把它细分为两部分，一个是直觉判别力，另一个是理性判别力。

首先，我们谈到当前人工智能 (AI) 的能力，它已经能够参与到大量的事务中，如你们大家都熟知的，甚至可以利用 AI 进行股票投资，帮助决策。然而，请注意，虽然 AI 可以提供建议和决策支持，但对于任何结果，无论是利益还是损失，最终承受者始终是我们自己，并非 AI。答案的风险和收益仍然由我们来承担。

然后，我们来探讨如何设计有效的提示语。提示语有很多种模板，我知道工程师们之前使用过一套叫做 ICDO 的模型，它的设计理念我认为是十分合理的。ICDU 就是最初别人写出来的简写，我们只是对其重新命名。不过此后，我们其实还进行了一些进一步的优化和改善。我们认为在指令部分，我们可以进行更详细的划分。首先，我们定义了角色，你是什么角色，要承担什么职责？接下来，我们给出任务目标，你今天的任务是什么？并规定了一些规则，例如，你在中国环境下，甚至是全球范围内，都不能讨论任何有关政治、星座或娱乐的议题等等。设置了这些规则后，AI 就能在这些规则的指导下进行操作。

接下来，我们给出了更多的上下文。我们认为至少应该有三类上下文。第一类，假设今天我要求你运用某种特定的商业模型，例如，我要求你使用这样的商业模型进行分析，那我就需要把这个模型的相关知识告诉你。同样假设大家中有不少人是从事心理学相关工作的。假如我需要你用心理学模型进行分析，那我就会再对这个心理学模型进行一次详述，以帮助 AI 更好地完成任务。第二类，我们会详细叙述完整的操作步骤，一步一步讲清楚该如何进行，并要求 AI 将整个执行过程都记录下来，这样 AI 的表现会更好。第三类就是少样本学习，我们可以在数据里放一些少量的样本，帮助 AI 进行更好的学习，从而获取更好的结果。

最后我们来谈谈 ICD 模型。这里，I 就是我们输入的数据，C 代表上下文，D 就是我们对输出的一些要求。以翻译为例，我们应明确哪一段文本需要翻译，这就是输入数据；在上下文部分，我们可以提供许多有用的背景信息；然后，我们需要设定对输出的要求，指导 AI 如何进行输出。例如，我们希望 AI 的输出可以放在 markdown 文件里，使我们能方便地复制，或者我们会有一些特定的格式需求等等。

按照以上的方式组织提示语，我们可以获得相对理想的效果。这种做法在之前，可能只有程序员才会去用。但如今，我们让它成为了一个更加通用的工具。

后来，我们引入了「自定义指令」（customer instruction）的概念。这个概念表示，在界面的设置中，我们可以把相关内容放入自定义指令里，从而获得优良的效果。

我们从此得到了一项重要的启发，即在今天使用大型语言模型时，我们其实处于一种「人机共舞」的状况，也就是人和 AI 共同合作的状态。在这种合作中，AI 的角色主要是辅助性质的。我这里用三个相关的词来描述其角色：助教、助手和顾问。

首先，AI 可以被理解为是一个热情的「助教」。他极其热情地获知我们需要的知识，然而他所提供的信息有一定概率会出错，至少与教授相比，他出错的概率会相对较大。我们在对待助教的态度上，不会轻信其每一项建议，但我们又相信他是聪明而且热情的。

其次，AI 可以被视为一个「助手」。他并不是负责一个部门的负责人，因为如果是部门负责人，他必须为整个部门的运行承担责任。但作为一个助手，他只负责帮助完成任务，然后由我们检查他的工作效果。

最后，AI 也可以被视为一个「顾问」。顾问与高级公司管理人员的主要区别在于，管理人员需要承担责任，而顾问则不必。尽管顾问会提供许多建议，但如果最后结果不理想，责任并不在他。即使是大型的咨询公司，他们只是提供咨询，收取咨询费，如果提议实施后公司业绩下滑，还是公司自己承担责任。顾问可以提供许多聪明的想法，但最后承担责任的还是我们自己。

因此，我们认为，AI 的角色类似于助教、助手和顾问。那么，人应该做什么呢？我认为，尽管 AI 现在能够做很多事情，我们人类应该去做更难的事情，即机器无法完成的事情，或者说大部分人无法做好的事情。这就是我们需要做的「更大的作品」。

例如，AI 在处理小事情上表现得相当优秀，但在理解和完成大事情上，他有些力不从心。因此，我们需要让自己去做更大的事情，像写一本书这样的事情。我们知道，写一本书需要投入巨大的精力，例如，进行大量的采访，跟许多人交谈，阅读和研究许多学术论文，实施大量实验，进行大量的文本调研，进行深度的讨论。这些事情都不可能由 AI 来完成。

除此之外，我们也需要做品味更高的事情，因为机器没有品味，他的品味最好也只能达到普通大众的水准，或者只能达到互联网上一些普通人的平均水准。而作为一名有追求的人，我们应该致力于达到更高的品味水准。

最后，我们需要做的是为我们的客户提供有价值的事情。在这个过程中，我们需要去理解客户的需求，然后用我们的产品去满足他们的需求。

在研究和实践中，我发现我们确实需要以一种更优化的方式来提高自身的表现，尤其在进行知识生产类工作的时候。在操作过程中，我发现存在几种不同的情况。

首先，有时我能完成一个项目，但是却无法感受到成就感，即不论我产生了何种成果，产出都显得不够，不满意。此时，我认为我应着重于将自己能够做好、并对本身极为满意的作品尽可能地做出来。然而，仅此还不够，我们需要再深入一步：我们所做出的产品，应该不仅仅出于自我需求，而更应当能满足他人实际的需求。

然而，我们如何判断他人实际的需求呢？一种有效的方式就是看这个人是否愿意为此付出些什么。付出的形式不一定是实打实的金钱，也可能是时间、注意力等等。例如，一个人会说，我可以找时间与你面谈，讨论这个问题。他对这个问题的诚意是完全不同的，因此，明辨我们所做的东西，究竟是否真的被其他人所需，是非常重要的。

在这个过程中，你会发现有时我们无法完成一项工作，有时又觉得我们的表现并不理想。但是，对于那些连人工智能都无法完成的工作或产品，我们是无法将其转交给 AI 来处理的。期间，你可能会察觉到一个有趣的框架，它可以帮助我们思考：实际上，有许多事情，我们必须亲自去做。

然而，随着时间的推移，我们也会逐渐理解一点：我们不应去做 AI 可以并且可以做得很好的事情。只要 AI 能够出色地完成，我们就应该将其交给 AI，让 AI 尽可能地去做。而我们则应该专注于那些更加困难、大规模、并且对最终的用户客户具有实质价值的工作。

这之后，我想进一步探讨第三个观点，这也是个使我深感痛苦的启发。因为我们在长期的工作中，一直强调产品的精确性和准确性，否则它就无法投入使用。这就像在工作中，我们常常纠结于一定要把这个结果做得非常准确。然而，大语言模型却不同，当我们以准确性为评估标准时，往往只能给它打四十分或五十分。

即使我们付出了许多的努力，让它的得分提升到六十分及格，甚至在后期达到了七十分，但是我们还是不能让它达到满分。现在，我们已经意识到，其实大语言模型达到七十五分，基本上对于一些浅层次的使用已经足够了。

与此同时，我们还发现了一个有趣的事实：我们与 AI 合作的最好方式，可能就是享受它的随机特性。也就是说，我们要接受这一点：AI 并非总是完美的，而且在一些情况下，它可能表现得颇有随机性。

我们首先通过使用 "Control that" 对图像进行草图设计，无论是我们怎样引领其进行绘制，或者我们训练模型让它了解我们期待的效果，我们发现，它总是无法完全满足我们的期待。但如果我们稍微放宽一些要求，比如当我们希望设计一些配图或者插图，此时，如果我们仅仅给出一些创意的提示，让模型未受约束地发挥其创造性，然后再根据模型输出的结果进行相应的调整，我们会发现其实这样的结果还是不错的。

我个人觉得，可能在未来的一到两年的时间里，我们还需要在探索如何有效地引导机器进行创造性工作。例如，前不久我在设计一本书的插图时，并未寻求外部设计师的帮助，而是我们自己进行了绘画。在尝试和修改的过程中，我发现这种方法其实很有用。当然，在此过程中，我查看了很多不同的设计，逐一筛选，最后选出了一个不错的设计并进行了相应的调整。在这个过程中，我们会发现，充分利用模型的随机性，最终可以生成一系列有趣的设计，并达到很好的效果。

因此，我认为在使用 AI 时，我们需要充分利用其内在的随机性。接下来我们再展开讲述大语言模型在教育方面的应用。

在教育领域，我们看到了很多大语言模型的应用例子。尽管这些模型还未在 K-12 教育中全面应用，但已经有许多相关的讨论和尝试。这个过程中我们开始了解到，大语言模型有很多可能的应用场景。比如在一本名为 "GBT 入门" 的书中，作者用了一个例子说明我们可以让 GBT 进行文章的撰写。

此处的撰写，并不是简单的文字输出，我们可以有策略的向它提问，从而让其输出不同风格的文章。最后我们可以看到，同一内容，大学生、研究生、四年级小学生、初二学生、AP 英语学习者等不同群体的写作结果将有怎样的区别。这只是一种理想的应用场景，然而如果我们将这种策略应用到实际的教学场景中，教师可以让 AI 模仿一种特定的风格撰写文章，或者生成不同版本的样稿，之后教师可以根据这些样稿进行修改和指导。

此外，教师还可以让 AI 生成一些错误的文字，让学生们对其进行修改，从而提升他们的学习效果。因此，我们可以利用 AI 扮演不同的角色，展现出不同的风格。我们还可以让 AI 做一对一的导师，这种方式可以大幅度提升学生的学习成效。

经过查阅若干相关资料后，我相信大语言模型（例如 GBT）对于教育的影响力。虽然有人将其视为过时的说法，但在我看来，其理论是经过反复验证，并且从常识角度来看，也是合理的。

我们可以从教学模式的角度来理解这个问题。设想一个班级，哪怕只有二十个学生，教师也需要面临分配注意力的困难。然而，在一对一的教学环境中，教师能够就学生的问题进行有针对性的指导，这无疑可以极大地提高学生的学习效率。在过去，我们可能需要借助家教来实现一对一教学的模式，而这往往会付出较高的成本。

然而当今，基于深度学习的大语言模型，例如 GBT，可以通过智能提示语来实现更加精准的指导。比如说我们可以让 GBT 适应每一个学生的学习水平，并对其进行个性化的辅导。自然，这也可以用于辅助学习。

想象我们有一个教师，其手下有三十个学生。这位教师可以将每个学生的作文输入到语言模型中，让模型给出修改建议。这些建议将针对每个学生的特性，因此每个学生获得的都是高度个性化的改进建议。用这种方式，教师、家长，甚至我们作为成人，都可以在学习过程中得到语言模型的有效帮助。

在教育领域，我看到的一种具有启发性的应用示例是翻转教学。大家可能听说过课堂翻转，这次翻转的是角色 —— 让 AI 模拟学生，让真实的学生扮演教师的角色。我非常欣赏这个想法，因为它巧妙地避免了 AI 的一个主要问题：不可避免的错误答案。

如果我们将 AI 的答案视为正确的，介绍给学生，那么学生可能会学到错误的知识。然而，如果我们反过来，让 AI 扮演学生，让真人学生扮演教师，那么就算 AI 的回答错误，学生也有能力发现并纠正。找出彼人的错误，实质上是一个很好的学习过程。这样，通过改正 AI 的错误，真人学生不仅提升了自己的理解，同时也避免了接受错误答案的风险。

这种巧妙的方式，既利用了学习的原理，又避免了 AI 的缺陷。我们还可以进一步优化这个教学模式，例如，我们可以在学生找出并纠正 AI 错误后，提供正确的答案，以便学生能够更好地理解判断。在这个过程中，学生的学习过程也能够连续地进行。

在我最近的一本书中，我画了一个 2x2 的图，以便更直观地展示这一理论。

在我观察过的材料中，有一些具有高完成度和正确性，这类资料基本上呈现出教科书的特点。然而，这种资料虽然内容正确，但并不全面地覆盖一个领域。例如，许多人采用学术论文作为学习材料，但这些论文其实只是个别领域发展进程中的一部分，材料本身的内容仅一块一块地展现出特定专业的知识点，它们是非常合适且重要的参考资料。

此外，一些学生的作业也可以作为参考。某些作业可能看起来已经完成了，但实际上可能存在很多错误。此外，我在研究的话题有一部分可能还没有完成，因此与自己关联的问题模型都还是「未完成的」，可能存在着错误。正因为如此，这些其实是非常好的学习材料。

目前，AI 的发展为我们提供了大量全新的学习材料。例如，沃顿商学院的教授伊森·蒙克和他的妻子（从他们的姓名看，我认为他们应该是夫妻关系），就是一对这样积极进行研究的学者。她在沃顿的一家与教育相关的中小学教育机构担任教学总监。在过去一年中，他们发表了多篇论文，其中一篇探讨了如何将 AI 用于教学的五种策略。虽然这不是一篇严谨的论文，但他们以快速精练的方式做出了一些总结。

我认为他们提出的这五种策略都十分出色，非常适合学校的教师用以辅助 AI 教学。可以借助 AI 解释各种知识，提供实例进行说明，这样可以帮助学生更好地理解概念。AI 还可以生成详细解释，让书本的内容更为充实；也可以替教师产出一些不重要的考试题目，这称作「低风险测试和诊断」。因为期末考试对于学生的影响大，意味着高风险，如果考试成绩不好，则可能得到低分。但是平时需要进行大量的低风险测试，这样即使学生答错了也无关紧要。也因为过去这样的题目太少，所以他们提出可以用 AI 来为我们生成这样的测试题目。

同时，他们也建议让学生们进行「翻转课堂」，让学生们试着教授一个话题。过去，老师需要花很多精力去详细审阅每一个学生的作业，而现在在 AI 的辅助下，教师可以先用 AI 工具看一遍学生的作品，然后在 AI 给出的建议基础之上，给出对学生的最终评语和建议。

让我们进一步讨论如何利用计算机技术和深度学习，将老师的教学压力减至最低，同时还可以让他们有更多的时间去关注学生们具体且深入的问题。在这方面，状元教育的一种重要理念值得我们借鉴，即在新单元的考试中，把上一个单元或前几个单元的相关内容放进来，以插播或交错的形式出现。这样的布置将有助于学生更好的掌握整体知识。

传统教科书通常按单元来组织，很难将相关内容融入进来。但利用大语言模型，我们可以将这种教学理念告诉模型，让模型为我们组织相关的知识和测试题，然后调整后放入教学内容。通过这种方式，老师可以更好地将分散练习的方法应用到实际教学中去。

对于小学生，可能还需要别人的辅助使用，或者只能提出简单的问题。但对于成年学生，比如商学院的学生，他们就可以自己设计各种新的提示，新的提示语角色。

在这里，我想谈谈微软的提示语仓库。他们已经将一些实例录入进去，其中主要的部分是放在角色那里。但是，角色部分并不只是简单地定义一个角色，而是需要复杂的分析和考虑：他是什么角色？现在扮演的是什么？他的特征是什么？遇到的问题是什么？最后该如何解决？因此，这套提示语在我看来，具有非常大的借鉴意义。

在我稍后分享的链接中，你们可以找到相关的提示语。这个仓库除了教育领域的内容之外，还有许多其他领域的提示语，都值得借鉴和学习。

在此，我想提及一个启示：当我们使用 AI 进行工作生产时，应该首先想到的一个人可能已经有六个月前就提出了这个观点。这可能对我们的工作有所启发，帮助我们从不同角度审视问题，提出新的解决思路。

因此，当我们提出一个问题时，似乎我们自身的知识框架能让我们得到更好的回答。我也是在经过几个月之后才逐渐领悟到这个道理。当然，并非是我们后来才将知识框架添加进去，而是我们一直被质疑：你们所说的那个提示语，似乎既重要又不重要，因为你们所做的提示语可能很快就会被模型能力的提升所替代。例如，你们以前花了大量时间编写的 SD 绘图的提示语，它是基于 mediant 的提示。然而，现在我们用新的 GPT 和 DLE 机制，普通人就能够让它说话，他肯定会觉得提示语并不重要。

在一段时间里，我也被这种观念影响。但后来为什么又坚定了呢？因为我们发现，如果你从提示语这边观察模型，你会发现使用提示语改善模型的能力虽然速度快，但随着模型能力的提升，提示语的重要性会逐渐降低。然而，如果我们将提示语和大语言模型的能力应用到一个具体的领域，比如将我们之前提到的翻译场景应用到具体的专业领域，或者将其应用到教育领域，你就会发现，你对该领域的认识，对教育任务以及学生们的情况等等的理解，甚至你的知识储备愈丰富，你就愈可能有效地运用大语言模型的能力。

因此，当我们谈及提示工程时，我们并不只是粗浅地说把提示语写好，让模型反馈出一个好结果，而是我们需要如何将具体的知识框架与提示语结合起来，以及如何将这些与大语言模型的能力结合起来。如此一来，我们发现，提示工程并不是虚无飘渺、六个月后就会消失的事情，而是在相对长期中作为软件应用的开发者，我们需要仔细考虑的问题。因为我们需要将提示语固化到我们的应用中。每当专业用户使用时，他们还需要掌握一些提示语的技巧，才能获得他们想要的答案。这就是我们得到的启示，也就是我们需要自带一个领域或者场景的知识框架，然后才能有效地应用大语言模型。

在此之后，我会继续分享关于 AI 的进一步观念，哦，不好意思，刚才我似乎暂时丧失了音频，是清华耳机没电了。我看到刚刚方老师在讲得非常精彩，我们都听得如痴如醉，这可能是叫做聆听的神韵吧。我为耽误大家时间感到抱歉，我马上继续，应该很快就能讲完。

在这个阶段，我们会发现，当我们将工具应用到个人情境时，条件变得相当复杂，就好像我们使用平台技术工具一样。在使用这个技术工具的过程中，我们需要考虑四个方面。

首先，我们要了解工具本身的特性。其次，我们需要评估工具本身的优势和劣势，以及在未来发展中的可能潜力。然后，我们需要对此工具的用途进行单独的点评。有效的应用针对于各种类型的用户，比如像宝玉老师那样，将工具应用于字幕的翻译中，或者将其应用于软件中，甚至是将这个工具应用于中小学教育中，不管具体用途如何，我们都在评估一个具体的单一使用场景，以便了解如何最有效地使用这个工具。

在后面的阶段，我们需要思考如何规模化这个工具的使用。当我们考虑这个问题时，一个关键的问题就是我们如何在实际场景中使用这个工具。我认为，我们首先需要进行一些实验性的使用，这并不是随意的试用，而是在一个具体的领域中多次使用工具，可能达到三十次，五十次，这样我们才能充分理解在这个特定领域中，这个工具有什么样的可能性。

然后，我们还需要找到一个更实用的领域去应用。如果你没有一个足够实际的应用场景，你可能不会用到一千次这个工具对吧？虽然一千次的使用可能不那么常见，但如果找到对我们来说重要且频繁使用的任务，我们就可能会用到一千次。一旦你使用了工具一千次，你会发现你每天都在考虑如何改进这个工具，这样我们就会对所涉及的问题有更深入的理解。当我们充分了解并熟练使用这个工具后，我们就可以进一步拓展其应用了。

在我整理完这个课件之后，我看到乔布斯的一句话，他说，如果你没有真正体验过一件事，长期去做一件事的话，你看到的只是表面。你可能能看到一个香蕉的图片，但你永远不能闻到香蕉的香味，也无法体验到香蕉在口中的感觉。因此，我坚信，只有将技术工具应用于实际，频繁使用的场景中，我们才能真正感受到这个模型的特点。

目前我个人在两个方面做了大量的尝试。第一个是在编程方面，尽管我并非专业编程人员，但我仍然需要处理很多与编程相关的任务，对编程方向的使用十分频繁；另一方面，便是与写作相关的事情，因为我每天都在写作和修改各类文本，并频繁使用此工具。在这两个方向上，我受益匪浅，获得了很多深入认识和体悟。

因此，我建议大家，如果你想要尝试使用这个工具，不用着急去理解它全部的特性和功能，你只需要从一个非常小的、实际的点开始，就可以找到工具真正的价值和潜力。

例如，我有一位程序员的朋友，他最大化地运用了 AI 技术的优势，特别是在生成他每日的提交记录 (message) 上。这位朋友的工作中，需要将编写的程序放入 git 的版本库中，他便开始努力研究如何利用这个工具生成更多、更高质量的提交记录，并且他还通过提交记录来拟写每日的工作报告。实际上，这位朋友每天至少要进行十次提交操作，每天需要整理一次工作报告，而每周则需要完成五份报告。在这个过程中，他对工作流程产生了深刻的理解和领悟。我认为这是第一步，我们要意识到如何将 AI 技术融入到工作流中。

然后，你需要开始使用它，把它融入到你的工作流程中。在这个过程中，你会开始对你的工作流有一个全新的认识：原来的工作流是什么样子？我一步一步按照流程做事情需要花费多少时间？

我有另一个朋友，他经营着一个网站，每天都需要更新大量的文章。原来，他可能需要请几个同事一起花费整整一天的时间来更新网站内容。但是现在，他只需要一个人通过运行自己编写的脚本，在两三个小时内便能完成所有的更新工作。这就是把 AI 技术融入工作流程后的效果：你的工作流程有了什么样的变化？这个时候，你需要保持持续的改进，持续的优化你的工作流程。

工程师思维的人，总是乐于将事情自动化，愿意持续改进，哪怕这个改进并没有带来太明显的效果，或者这只是满足了自己的需求。但是在这个不断的调整、优化过程中，我们就能更好地发挥出 AI 的能力。所以我们呢，可以把这种思维方式融入我们的工作流程中来，利用 AI 去改进我们的工作。

第三个阶段是，当我们使用 AI 到一定程度后，我们就需要开始尝试使用更为专业的 AI 工具。「AI 编程」正是我们经历这个转变的例子。我们曾经尝试过使用 GitHub Copilot 这个工具，然后发现效果并不理想。当 GPT-4 发布后，我发现这个工具非常好用。虽然用 cura PI 也可以完成一些工作，但显而易见，使用 GPT-4 的效果要远胜于我们自己拼凑出来的效果。因此，我转向了使用 cutter，但是后来我发现 cutter 并没有我想象中的那么好，github copilot 在专业性上有了提升，于是我又转向了使用更加专业的工具。

我想说的是，在开始使用 AI 时，你可能会尝试自己拼凑一些工具，但当你将 AI 技术运用到一定程度时，你可能需要更加专业、更加高效的工具来提升你的工作效率和质量。

在杨教授的讲座中，我曾听到过一段观点，认为我们应当尽可能使用最尖端的工具。对此，我想补充的是，我们不仅需要使用最先进的工具，同时还要考虑使用他人创造的专业工具。因为当你使用别人创造的专业工具时，你会发现他们已经考虑过很多我们从未想过的问题，这些问题通常位于某些特定领域的边缘，对于这些问题的处理，常常会使得工具的输出结果变得更为优良。

谈到视力问题，我发现在进行文稿或者书稿的修订时，我们可以利用 AI 来进行。我刚刚完成了一本书的最后修改阶段，发现过去我们可能需要一个月的时间来修订一个文稿，大部分时间主要在修改内容上，至少要把一半的时间用在改错字和语法错误上。而现在，虽然我们修订文稿的时间并没有缩短，我们依然需要一个月的时间，但是我们现在可以花更多的时间来处理内容本身的问题，而把错误的字词和语法问题以及表述问题交由 AI 来处理。在过去，我们可能需要自己修订好几遍，或者请别人帮忙修订，现在则可以通过 AI 来进行多次的修订。

在这个过程中，我们虽然花费的时间看起来并没有减少，但实际上我们的文本质量得到了极大的提高。我相信这次编辑老师收到的书稿比我以前提交过的书稿在错字和语法等问题上都会有显著的提升。

那么，具体如何操作呢？我会把每个段落都放入 AI 中，给出修改错别字和语法错误的指令，然后人工进行调整。另外，我也会把几个段落一起放入 AI 中，让它帮我改进表述的逻辑问题。同时，我们还可以把一些常犯的错误放入 AI 中，例如，我曾写过一本书的一个章节，编者非常认真地帮我改正了许多我自己的个人表达特性造成的问题。这些问题不一定都是真的问题，但如果做得更好，我们会发现如果我们把这些例子放入 AI，AI 能够发现我们现有文稿中的类似问题，并给出针对性的建议。

借助 AI 的力量，我们的成果可以比以前的要好很多。接下来，我们就需要试图规模化这种方式。虽然我认为交互式的方式更能发挥模型的能力，但毕竟它非常耗时，有时我们还是选择批量式的处理方式。总的来说，AI 不仅帮助我们提高了文稿质量，也极大地增强了我们的工作效能。

在探讨如何优化与 AI 的批量交互方式时，值得注意的是编写 Python 脚本与 API 接口的交互方式。利用 Python 脚本，用户可以实现链式处理及分布式相关处理。

在工作流中，就有可能存在一些环节是由具体的程序完成的。现在，我们可以尝试将其中一部分工作环节交由 AI 来完成，完成后再通过人工断点的方式进行检查并确认。这种方法可以相对自动化地完成原先需要大量人工投入的工作。

除此之外，我认为在个人市场中也可以引入一种被称为「检索 - 增强生成」的机制。这种机制的运作方式大致为：当用户提出一个问题时，系统首先在数据库中匹配相关资料。匹配完成后，将匹配出的片段作为语境输入大语言模型，由此生成回答。实际上，这种机制在各种产业应用中已经得到了广泛的引用。对于个人使用场景，我也认为值得尝试。

尽管能够做出什么程度的响应还无法确定，因为在产业应用中回答问题的过程相对简单直接。例如，如果是客服问题，只要拥有客服规则和相关数据库，就能得出回答。或者，如果问题涉及编程，只需查询历史代码及相关文档即可。然而在个人场景下，如果采用不同的数据库，如何判断答案的对错就成了问题。因此，需要进一步思考。

在这个方向上，我们可以先慢慢探索，虽然可能不能立即得到有效的应用。例如，对 RAG（检索 - 增强生成）的使用，我并不特别推荐在个人生产中使用。因为在开发 RAG 应用的过程中，我们发现从文档中检索内容然后将其作为输入片段送入模型，存在很大的不确定性。例如，如果使用 Inverted Index，有五六种检索方式，我们很难确定哪一种最优，或者在调整参数后，哪种结果是更好的。如果针对单一数据库，或许我们有足够的时间去多次尝试和鉴别，但对于普通用户而言，思考如何最优地使用 GPT 来读论文，这并不理想。因为用户可以直接读摘要，或者阅读文章的开头和末尾，这也是一种有效的方式。

首先，我们想要理解一篇文章的重点，你可以尝试阅读摘要、文章的第一部分、最后一部分；这些通常是包含主题信息的关键部分。同时，你也可以通过快速审视文章的图表形式，获取文章主旨。然而，当你希望从文章中提炼出一些信息，让它来回答你的问题时，问题就来了。你没法知道它选择的信息是来自哪一段，那么在这种情况下，它的回答的可信度究竟有多高就很难衡量了。

因此，我认为面对变化多端的信息和解锁新知识的需求，它的生成能力这一点是需要深入讨论的。我已经谈到了四个方面，但如何在这四个方面中找到规模化的道路？对于这个问题，我在个人实践中还没有找到满意的答案。

我想再强调一下 AI 的输出。哪些内容是 AI 生成并值得我们关注的呢？今天的 AI 在某些内容的生成方面做得很好，但往往并无实际用处。因为它经常喋喋不休，尽管语句在逻辑上无懈可击，但结果却是毫无新意、毫无价值的传统观念和陈词滥调。大家在日常生活中已经听过太多这样的话，我们不需要再从 AI 那儿听到。

有时，AI 产生的信息是正确且有价值的，这些我们需要高度重视。但我们同时也要对它们的误导性提高警惕，特别是那些有可能带来严重后果的错误回答。这也是我们需要持续关注的问题。我把这种问题标记为蓝色，需要关注；而那些需要警惕的问题，我采用了红色标记。

另外，有一类错误是无害的，我个人觉得这种情况下我们不必过于介意。比如，我们在使用大语言模型进行普通阅读或翻译时，它的错误通常可以被我们自己修正，因为我们看了中英文对照之后，即使它出错，我们也可以理解正确的意思。所以对于此类错误，我们可以选择忽略。但对于完全错误的答案，我们需要提高警惕。

因此，在讨论完四个象限后，我们应该关注的重点是正确且有用，以及错误且有可能造成危险的部分。

到最后，我发现面对 AI 的出现，我们需要有一些独特的能力。首先，我们需要有判断力。当我们看到一个回答时，或我们面对一个问题时，我们需要能够用自己的直觉和判断力去大致知道正确的答案应该是什么。其次，是推理能力。我们要根据 AI 的回答，一步一步进行推理，看看它的逻辑至理是否合理，结果是否正确。同时，我们还需要有鉴赏力，去判断一种答案是否正确，这具有多大的重要性。

这并非意味着只需要有正确的答案就足够了。在工作过程中，我们会发现对的答案虽然重要，但往往只是基础，却并不意味着我们已经取得了成功。

假设你领导过一个团队，或者说当有责任牵头一批人完成某项事物时，你发现你最关注的问题并不仅是 "这个人的工作做得对不对"。如果每天你的同事们都期望你评估他们的工作，识别出正确与否，你会认识到这样的工作真的相当艰难。面对这样的挑战，你可能需要寻求一些更有能力的伙伴来协助你完成任务。实际上，当我们有了这样的协作伙伴后，我们最关注的话题将会转变为「我们能否做得更好」。当 AI 成为我们的伙伴、助手时，我们同样可以考虑这个问题，即有没有可能提升效果或者产生更高的价值。

因此，我认为在 AI 时代，我们追求的应该是一种可以优化的能力，对这种能力每个人都有自己的解读方式。我个人将其定义为一种类似于鉴赏力的能力，或者说更具有艺术性地，称之为品味。在我看来，这就是我从 AI 中得到的启示。我们现已处在 AI 的时代，我们逐渐拥有了强大的 AI 助手或者顾问，人的角色演变为需要有足够的洞察力并能做出有品味的判断，然后在实际生活中采取行动，并最终承担相应的责任。

可能你们读过纳西姆·尼古拉斯·塔勒布的一本书，叫做《Skin in the Game》，中文版翻译为《非对称风险》。他的主要观点是你需要分享风险。如果一个人提出许多观点，而自己根本不承担相应的责任，那么这样的观点，你本质上只能听取，并需要反复思考。当 AI 出现后，你会发现不会有人比 AI 更善于提供观点，AI 可以变得非常权威，非常专业，完全超出你的想象，他可能按照任何你期望的方式来进行讲述。但是，AI 所缺乏的恰恰就是它不会承担风险，无法存在风险。所以，我们人类需要承担这份风险。

在总结我的观点，我提出三个主要的观点。首先，我认为 AI 是一种生产工具，我们应该将其视为一种工具，尽可能发挥其在各个领域内的作用。其次，我认为当我们与 AI 交互时，采用某种有效的提示语，例如 ICDO，虽然它看似过于工程化和复杂，但实际上是一种高效的方式。最后，我认为这种提示语言不仅仅是为了与 AI 提供交流，最重要的是我们需要实现的是对模型以及特定专业领域的理解。

在我们这个专业领域当中，重要的是运用专业知识，有效地使用提示语和模型。当我们将人工智能运用到逻辑领域时，就如同我们使用过去所有的技术工具一样，我们需要理解和评估它在单一领域的应用，而非仅停留在入门阶段，而是要从入门提升到精通。我们应该首先在某个特定领域熟练运用它，然后提升技术等级，这样可以更好地理解和掌握其使用。最终，我们要考虑如何规模化应用，使人工智能更普遍地服务于社会。

今天的人工智能发展已经达到了让几乎每一个人都有机会用一点点程序代码去控制的程度。对于稍微具有技术能力的人来说，可以很容易地开始使用 Python 进行编程。即使你没有技术能力，只要具有逻辑思考能力，你也可以用英语编程。抑或是有一天你甚至可以用中文进行编程，因为编程其实只是逻辑运用的一种表述方式。从这个角度看，编程其实是可以面向任何人的。

在这个人工智能共舞的过程中，我们留给自己的五个启示是，首先，我们要把人工智能融入工作流。其次，我们需要明白在人和机器共舞的过程中，我们建设的这些角色是什么？第三，可能在相当长的时间里面，我们还是不能追求无论是语言模型还是图像生成模型的完美精确性。相反，我们应该欣赏它的随机创意属性，并结合自己的知识框架去运用。

此外，人工智能是在生存生存的一个长期的考量下时刻存在的。我们要思考如何提升自己的审美，如何降低自身的风险。其实，有责任感和愿意去承担风险是相辅相成的。因为，你所谓的风险，其实就是你愿意去承担责任。

这些都是我今天花了很多的时间来分享的内容，感谢大家的耐心聆听。我要说的是，有了这些，我们就可以与 AI 共舞了。

参与这次讲座的同学们，也鼓掌欢迎我的分享。我知道现在的平台上有鼓掌的功能，所以请大家鼓掌表示感谢。好的，让我们暂时让方军老师休息一下，我来对他的分享做一个简单的概括。

我的一个深层次的感触是，方军老师的分享实在是精彩至极，我建议他讲座的内容扩充为一本书。最早的时候，我以为这本书的名字可能会是「如何在 AS 中提问」，或「工程师的提问技巧」。但实际上，方军老师已经出版了一本这样的书。然而，我今晚听完他的讲座后发现，这本书的重点并不是提问，而是他反复强调的「个人生产工具」这六个字。这是他分享的核心，也是最有价值的部分。

整理这次讲座的内容并呈现为书面语，未来讲者方军老师的这次演讲内容可以扩展为一本书。可能的书名启示包括「个人生产工具」，或者是「AI 时代的知识生产」。这些标题可能会更具吸引力。我深深地感受到，这次讲座的内容确实有扩充为一本精彩大作的潜力。当这本书出版时，希望读者们都能去支持方军老师。

进一步的感触是，方军老师的背景看似与我之前邀请的其他讲者非常不一样，但其实与我的行业背景有许多相似之处。我们都有深厚的编程经验，并同时担任作家。我们在思考问题时，不仅嵌入了工程师的思维方式，也并入了作家的视角。

在这次讲座中，这两个特点都得到了完美的体现。一般来说，作家不会像工程师那样去思考规模化、自动化等问题。然而，大家可能会发现，方军老师和我便是这样思考的。比如说，我们可以将自己每日的工作量总结出来，然后找出最高效的工作时段。在这个过程中，AI 可以帮助我们明确认知效率在哪些环境下会提高，哪些环境下无法提高。实际上，这些问题其实很容易通过粗略评估得出结论。

这个讲座围绕整个流程，让我们了解到 AI 在哪些具体问题上能立马帮上忙，哪些领域需要我们耐心去等待。随着相关技术的成熟和大型语言模型表现的提升，我们可以看到这一过程体现了典型的工程师思维，即先实现某个最易被突破的环节，然后再进行自动化和规模化。

那么，作家的思维又是怎样的呢？我们这些作家并不过于关注别人怎么说或怎么写，尽管在 AI 时代，我们可能每天听到成千上万篇讲座和文章。真正吸引作家的其实是对知识的合理引用，以及如何构建自己的知识框架。方军老师在今晚的讲座中也特别强调了这一点。虽然在整个讲座中，方军老师引用了很多其他名人的名言或学术理论，但他主要的目的是为了整理和构建自己的知识体系。

我们作为作家，我们通常能够对我们引用的材料进行更深入的解读，我们会将这些材料有机的整合在一起，进而形成一个更清晰、更完整的框架。这是我在今晚的讲座中获得的深刻体验。在二十一世纪，我们需要以工程师的方式思考问题，这意味着通过逐步的修正和调整，进行快速的试验，然后从单点向更大规模的突破，这样会大大降低我们每日的体力劳动量，提高我们的工作质量。同时，我们也需要像作家一样思考问题，将大量的知识和经验转化为我们的个人作品。

其次，我对今晚听到的另一点感到深有感触。那就是，在二十一世纪的 AI 时代，我们实际上还处在一个刚刚起步的阶段，许多事情并未定型，还有很多空间进行探索和创新。今晚，方俊老师展示的这种开放的学习态度，让我深感敬佩。他并不会立即下定论，而是在学习和探讨的过程中不断修正自己的想法。他不会害羞地隐藏他以前的错误，相反，他会直接告诉我们，他以前犯过错误，但现在他已经改过自新。这种开放的学习态度，能够帮助我们在这个 AI 的长跑中走得更远。

如你所知，AI 并不是一个短期的冲刺，而是一场可以持续 20 到 100 年的马拉松，对我们所有的生产力都会产生深远的影响。如果你太过纠结于过去的想法，过于坚持自己的固有观点，那么你的成长速度可能会比其他人慢很多。因此，我要对今晚方杰老师的讲座表示深深的感谢，相信在场的都感到非常精彩。

我的一些好友，包括一些著名的教授，我也邀请他们今晚一起来听讲座。他们在群里也表示，方杰老师讲得太好了。于是，我们非常期待方杰老师能将今晚的内容扩展为一本更完整的书籍。让我们再次向方杰老师表示敬意。现在，就把时间交给方杰老师，谢谢方杰老师。

接下来，方杰老师，你可以暂停屏幕共享，这样我们就可以看到你的头像了。谢谢，我们期待您的下一个讲座。

首先，请对方军老师赞赏，几乎所有的在场听众都像我一样，即使在方军老师失去是耳机电量的那一刻，仍饶有兴趣地热切地听讲。尽管听众们可能有些杂乱，但不管怎样，大家都在认真倾听。而今天晚上，方军老师的分享情绪激昂，充满激情。他不倦地演讲，我们也抓紧最后的时间，给出三到五个问题进行解答。

我们已经看到了同学易斌提出了第一个问题。如果有同学想要提问，请大家抓紧时间，在 Q&A 区域以 Q 为开头，输入自己的问题，并请方军老师来回答。现在，请允许我介绍一下易斌同学。他在一家知名的音频公司担任技术主管的角色，他的背景和你有一些相似之处。

细看这个场合，我发现许多听众来自知名的大型模型公司，比如是卓普和百圈。所以，我推测在场的同学基本上都是在互联网科技公司工作的多数。如果有专业问题，或者想进一步加深关于大型模型的认识，我们非常欢迎你们联系方军老师，深入探讨。当然，我也非常希望你们在创新模型上能够取得成功，让我们这些互联网行业的朋友也能从中受益。

下面我看到了易斌的问题。他问了一个很好的问题：会不会有限制在传统的管理咨询或组织咨询顾问上？我觉得并不会。传统的顾问，比如我们来说是一个具体的话题，像管理咨询顾问。想象一下大型的管理咨询公司中的顾问，比如麦肯锡，IBM，BCG 和国内的许多其他大型顾问咨询公司。他们通常需要一个庞大的团队来完成咨询任务。但是今天，他们可能只需要一个人配备 AI 工具就能完成原来需要众多一般性助理才能完成的工作。

因此，我认为最终的结果有可能是：原来规模较大的团队可能会转变为由少量合伙人组成的小团队来完成任务。而原本为大型的团队在逐渐减少。在这个过程中，我们会发现像麦肯锡和 BCG 这样的公司，他们原来的精英团队或许也会有所改变。

在这种背景下，他们可能会更迅速地采用这种专业的工具进行辅助。前一段时间我读过一篇论文，旨在用 BCG（波士顿咨询公司）的咨询顾问做技术推广效率的实验。实验结果也显现出，当这些顾问使用了 AI 工具后，他们的工作效率实际上能够得到大幅度的提升。

然而，对于过去的一种工作模式，就是有大量中间工作环节，其实还存在很多种类。比如，会计咨询所，他们也可能提供了一些需要大量人力的咨询服务，也就是顾问服务。而在 AI 技术的干预下，他们的工作可能会被 AI 大规模取代。到最后，那些技术精湛的顾问才能留下来，给企业提供基于财务资料的相关服务，而那些原本依赖人力完成的工作可能会被机器代替。

再次，如果说到 AI 或 IT 工具的落地应用，或者是底层数据的工程实施，我认为它其实本质上并非仅仅是个咨询的问题。问题的本质是首先要了解客户的需求，因为我在这方面有一定的工作经验。基本上需要了解客户的需求，然后找到一个对应的技术解决路径，接着找到对应的具体的技术解决方案，不论是内部团队还是外部技术团队来实现。这部分任务有可能就是原来的顾问需要去理解的客户需求及企业需求。这个部分的工作依然会存在。据我了解，这将会是新时代的顾问工作。

而实施的部分，可能会留给工程师来完成，就目前来看，我觉得工程师的工作并不太可能被 AI 取代。以你提出的问题为例，这正是 AI 无法回答的问题。AI 需要有人去把这个问题拆开，指出问题的各个方向，然后才能逐步得出解答。因此，咨询顾问实际上就是要将一个大问题，一个复杂的问题，在现实世界中没有数字化的问题进行分解。举例来说，许多顾问遇到的问题都是存放在人的思维中的，对具备书面概念的人来说，这些问题最终一定需要拥有高技巧、甚至人际技巧的人来实现解决。

以上就是我对这个问题的讨论，谢谢大家的倾听。

现在我注意到接下来的第二个问题。转眼看到时间压力，今晚的时间有限，而我们已经讲解了相当长的时间。所以我今晚只会再回答三个小问题。第二个问题由带有首字母 k 的同学提出。现在能听到我的声音吗？好的，来吧，我们开始吧。

讲座整理稿：

好的，让我补充一下方军老师提出的问题。众所周知，阳老师历来是一家管理咨询公司的员工。在过去的五年中，管理咨询行业发生了巨大的变化。曾几何时，管理咨询与 ID 咨询是两个截然不同的行业。在 ID 咨询行业，Accenture (艾胜哲) 名列榜首；在管理咨询行业，以战略咨询为主的 McKinsey (麦肯锡) 稳坐第一。但在最近的五年里，一个显著的变化发生了，那就是 Accenture 的表现越来越不如人意，裁员的消息屡见不鲜。

五年前，麦肯锡的一项关键战略决策颇具前瞻性，他们预判到，传统咨询行业已经无法跟上时代的步伐。因此，他们先后收购了大量的人工智能咨询公司，如今已经拥有了自己强大的 AI 实力。他们接管了 Accenture 在 ID 咨询市场的份额，犹如熊掌挥舞，无坚不摧。现在，麦肯锡才是排名第一的人工智能咨询公司，同时也是人工智能行业排名第一的公司，具备了极强的市场实力。他们涵盖了我们所有的能力，所有公司都已经过他们的收购。这就是作为曾经的管理咨询行业从业者，你需要了解的信息。这一点突然显得非常有趣，反映了麦肯锡具有强大的前瞻性判断能力。

对，你的补充比我全面的多了，我的观点只来源于与一些企业的个人体验交流，非常感谢你的补充。

刚才有一位朋友提出了一个与 Web 3.0 相关的话题。我周围有许多 Web 3.0 的朋友，他们分别在几十个不同的团队中执行与 Web 3.0 和 AI 相关的应用，我们自己也在进行少量的研究。目前看来，最有价值的一个 AI 应用，实质上是生成式 AI 之前的应用。尽管他们使用了一部分生成 AI 的语料库进行训练，但主要是利用语料库和价格趋势来判断市场的趋势。然后，他们预测市场的短期涨跌。很明显，这个 Web 仓市场里有期货市场这种所谓的合约。他们利用这个单头信号和多头信号进行期货市场的操作。

这个操作的效果，无论是他们自己实际执行的操作，还是他们把这个信号卖给了第三方，之后第三方执行的操作，都显示出了这项业务的盈利能力。事实上，如今，他们已经并未频繁使用到当下的生成式 AI 了，我们曾多次讨论过与生成 AI 相关的应用。但我们一般认同，生成 AI 已经不再作为他们的主力应用。

在今天的讲座中，我主要会聚焦在 Web 3.0 这个话题。Web 3.0 只是一个非常专业的细分领域，其中包含了众多相关的语言资料。然而，将这些语言资料组成语言后，其实所带来的价值并不特别明显。站在宏观的视角上，我们可以将 Web 3.0 视作任何一个细分的领域，比如芯片设计领域、机械制造领域，或者是专门生产某一种机械或某一种服装的领域。

同时，从数据的角度来看，我们曾经也探讨过一段时间的方向。在 Web 3.0 领域内，有很多的数据，其性质并不同于传统行业的数据。比如，一些行业的数据是封闭的，只有其内部人员才能获取。然而，Web 3.0 的数据确实开源的，开始于它的起源就是开放的。这个领域积累了大量的结构化的数据。

这些结构化的数据，也有一部分人进行分析。在人工智能（AI）兴起之前，我们甚至有像 Licson 这样的产品。当 AI 出现后，也有一些工具试图用 AI 来分析并超越 Licson。然而，即使在技术上有所超越，但 Licson 仍然领先，原因在于它抓住了一个重要的用户需求点，即用户想要看到链上资金的流动以及后续的相关操作。如果你不加选择地去分析链上的数据，并未产生明确的结果，这种情况下的结果虽然可能在某些方面更好，但实际效果并不明显。

当然，另一个可能的解释是 Licson 已经形成了自己的独特的市场定位。所以说，Licson 所提供的数据质量好坏的判断，在目前阶段大多由他们自己来做，其他人很难做出有效的评价。

在 Web 3.0 领域中，如果你打算应用 AI 的话，我认为并不必急于尝试生成式 AI，应优先考虑传统的那种 AI。因为在这个领域，关键信息实际上是用来判断价格变化的。如果我们对 Web 3.0 进行更细分，其本质其实是一种资产投资行为。在这个领域里面，我认为大多数的模型都可以采用传统的模型来进行。同时，你可以利用链上的数据和网络情绪作为辅助线索。

最后，关于范军老师的问题，那是由殷同学提出的。我们稍后再进行讨论。

尊敬的听众，对于该问题，我遗憾地表示，它已超出了我的专业能力范围，我无能提供满意的答复。但是，请允许我在此强调，人与人工智能的区别之处在于，人类当面临超越能力范围的问题时，最直接的反应便是尽力避免答复。非常感谢范军老师的引导和支持，我也相信在座的所有同学应该对此深有体验。

在我参加这次讲座之前，范军老师曾经提过的一个例子让我非常有感触。就在前几天，我偶然遇到了一位学长，他从事的研究领域正是大语言模型。在交谈中，他向我询问我当前的工作。当我跟他提及我在公司处理的工作恰好是与大模型相关的任务时，他告诉我，在建立大模型的过程中，并不存在所谓的提示词，这点几乎是不容置疑的。

这个观点让我在当时产生了疑惑，我不禁开始怀疑，我自己是否在优化提示词的过程中为了一个看似无用的目标而浪费了大量的精力和时间。然而，今天在范军老师的讲座中，我明白了我这样做的意义所在。其实，这个过程促使我在特定的专业领域内，不断提升自己的专业能力，迈出实实在在的步伐。尽管学长的观点带着挑战和质疑，但这正是我提升自我专业能力的一种推动力，对我来说，这是一种宝贵的倒逼机制。

因此，我要再次向范军老师表达我由衷的感谢，感谢您今天带来的深入浅出的演讲，以及后续的答疑环节。我也期待在座的每位同学，能够在听完范军老师的精彩讲解后，能汲取到能量，得到启发。请不要忘记将讲座中的精华内容记录下来，以便于自己随时回顾和复习。

各位同学，现在你们可以在范军老师的「知识星球」提问，进行互动交流。我也希望大家能够在知识星球中，反馈给范军老师你们的想法和感受，提供更多的反馈信息。

当然，我也希望大家能够支持范军老师的工作，他的专业梳理无疑是我们进步的阶梯。今天，我们「AI 生产力」系列讲座的第一场直播在此告一段落，感谢范军老师、阳老师及所有参与的同学们。此刻已近深夜，相信每位同学心满意足地接受了知识的洗礼。

今天的会议到此结束，愿大家有个美好的周末，晚安。