## CH0201信息的度量分布与传播

### 课件汇总

P01 —— CH1 学习目标

来到信息分析第二讲，我们将来了解信息的度量、分布与传播。

本章卡包概览：

信息如何度量？

信息有什么分布规律？

信息传播有什么特点？

P02 —— 本节视频说明

根据香农在《通信的数学理论》说法，凡是在一种情况下能减少不确定性的任何事物都叫信息。

那么，你是否好奇：

信息如何度量？

信息又有什么分布规律？

信息传播有什么特点呢？

P03 —— 如何度量信息？信息熵

熵（entropy）的概念最早起源于物理学，用于度量一个热力学系统的无序程度。

在 1948 年，香农在他的论文《A Mathematical Theory of Communication》中将热力学的熵引入到信息论，因此它又被称为香农熵。

例如。如果有 16 个外形完全一样的铜球，其中有一个球的重量比其他球略轻。那么，用一架天平称几次一定可以把这个轻球找出来？

答案：把 16 个球平分成两组（第 1 次），每组 8 个，放在天平的两边。立知轻球在天平轻的那头，剩下 8 个球。同样，再把这 8 个球分成两组称一次（第 2 次)，剩下 4 个球。称第 3 次剩下 2 个球。称第 4 次时，那个轻球就被找到了！用二分法，16=2^4（2 的四次方)，可知分 4 次就一定可以找出轻球。

P04 —— 如何度量信息？比特

信息的度量：比特（bit)

比特（bit）：指二进制中的一位，是信息单元的计量单位，信息量的最小单位。

在需要作出不同选择的情况下，把备选的数量减少半所必需的信息。

即信号的信息量（比特数）等于信号数量 n 以 2 为底数的对数值。

P05 —— 如何度量信息？自由能

自由能的概念源于统计物理学。热力学自由能，是对可用于从事有效工作的能量的度量。引入认知/信息加工领域后，指对世界的表征（建模）方式与其真实状态间的差异。

神经科学家 K.Friston 提出自由能原理（free-energy principle)，认为任何与环境保持平衡的自组织系统必须使其自由能最小化。

惊奇、熵和自由能：

有机体抵制热力学第二定律

他们必须最小化平均惊奇（熵）

他们通过抑制预测错误来最小化惊奇（自由能）

预测错误可以通过改变预测来减少（感知）

预测错误可以通过改变感觉来减少（行动）

感知需要在大脑中反复传递信息以优化预测行动

行动使预测成真（并最小化惊奇）

P06 —— 科普：自由能理论

自由能是个十分抽象的概念，若想进一步理解，可以阅读这篇科普文章：

[说说 Karl Friston 的自由能原理 - 知乎](https://zhuanlan.zhihu.com/p/161419921)

P07 —— 信息的分布

虽然信息数量巨大、类型多样、变化频繁、结构复杂、质量参差不齐，但信息的分布并非完全无序。相反，信息的分布呈现一定的规律性。

信息的三大分布形态：正态分布、幂律分布、偏态分布。

P08 —— 无标度网络

无标度也就是网络上的节点无特征标度（characteristic scale)，比如身高、智商或者行车速度等，你对它们的预测会有一个范围。常见于达尔文信息。

但朋友数量、财富等，不具备特征尺度（scale-free)，可以很小，也可以任意大。常见于香农信息。

无标度网络的通俗理解就是二八定律，又叫幂律定律。形象地说，就是「富者越富，穷者越穷」定律。

如下图（右 1)。不同的人拥有的朋友数量有量级的差别。

二八定律呈现的曲线像是拖着一条肥厚的尾巴，所以二八定律又被称为肥尾效应，或马太效应（即富者越富，穷者越穷）。

P09 —— 什么是异步律？

异步律（也称异速生长律）由生物学家 Huxley 和 Tessier 在 1936 年提出，他们发现潮蟹（fifiddlercrab）的钳子大小随着螃蟹身体而变化，且钳子的增长速度要远快于它的体积增长速度，这就是「异速生长」的来源。

P10 —— 信息传播的模型

巴斯模型（经典信息传播模型）

病毒传播模型（SI、SIS、SIR 模型考虑网络结构的影响）

学习模型（德格鲁特模型考虑朋友的影响）

网络的博弈（网络交互作用模型考虑变量之间的作用）

巴斯（Bass）模型

巴斯模型是由美国管理心理学家弗兰克·巴斯（Frank M. Bass）提出，常用于创新产品、技术的采用和扩散。如图是标准的巴斯曲线图。

巴斯模型呈现 S 形。有两个关键参数：1）人（产品）创新或自发的采纳率；2）其他人（产品）进行模仿的采纳率。

三种典型的病毒传播模型：SI、SIS、SIR。

德格鲁特模型

德格鲁特模型由美国统计学家德格鲁特（Morris H. DeGroot）提出，他指出了一种模仿和社会影响的社会学习过程。

德格鲁特模型：模仿和社会影响。

德格鲁特模型由美国统计学家德格鲁特（Morris H. DeGroot）提出，他指出了一种模仿和社会影响的社会学习过程。

德格鲁特，Morris H. DeGroot（19311989）世界知名统计学家。生前任国际统计学会、美国统计学会、数理统计学会、计量经济学会会士。卡内基梅隆大学教授，1966 年创办该校统计系。

网络中的博弈

我们行动通常会依赖身边人采取行动的比例，比如，是否买房、吸烟、上开智的课程等等。

这过程可能有，多个均衡点，比如当有人采用一种新技术时才会跟进。这样反应或策略引入社会交互作用中，模拟的方式就是博弈。

举例：囚徒困境

专业比赛中，服用兴奋剂也是一场囚徒困境的博弈。假设一方服用兴奋剂，在比赛中就会取得优势。但是，服用兴奋剂有长期伤害。用数值刻画这种收益如图。

最佳的结果（收益 4），是你选择服用兴奋剂，你的对手没有服用。若双方都服用的结果收益均为 2；若双方都不服用，收益均为 3。

这个过程犹如均为竞赛。试想之前教育的鸡娃现象。

P11 —— 关于信息传播的推荐读物

《人类网络》马修·杰克逊著

《社会与经济网络》马修·杰克逊著

《巴拉巴西的网络科学》艾伯特 - 拉斯洛·巴拉巴西著

P12 —— CH2 小结

本讲卡包学习要点回顾：

信息的度量：信息熵、比特、自由能。

信息的分布：无标度网络与异步律。

信息的传播：巴斯模型、病毒传播模型（SI、 SIS、 SIR 模型）、德格鲁特模型、网络中的博弈。

### CH0201信息的度量

什么是信息？信息学的经典定义是由香农在 1948 年提出的，他被公认为信息学之父。他把信息定义成「发送者传给接收者的信息」，也就是说，凡是在一切情况下能减少不确定性的任何事物都叫信息。这是香农在他的重要著作《通信的数学理论》中作为信息论的创始人提出的定义。

那么，如何度量不确定性呢？香农在冯·诺伊曼的提醒之下引入了一个重要的概念，称之为「信息熵」。「熵」这个概念最早起源于物理学，尤其是热力学中的熵，用于衡量一个热力学系统的无序程度。冯·诺依曼当时建议香农把信息的概念取名为「熵」，他的理由比较搞笑，认为这个热力学名词大家听不懂，容易被吓唬住。因此，信息熵这个概念往往也称之为「香农熵」。

我们可以看一个简单的例子来理解什么是信息熵。现在想象一下，有 16 个外形完全一样的球，其中有一个球的重量比其他球要轻一些。那么用一架天平称几次可以把这个比较轻的球找出来呢？答案是 4 次。这样的做法是：先把 16 个球平均分成两组，这是第一次，每组 8 个。把它们放在天平的两边，假设左边轻一些，右边重一些，那么显然我们把左边轻一些的球保留下来。接着我们再拿这 8 个球继续分成两组，这是第二次。再拿这 8 个球继续分成两组，这是第三次。接着再如此寻找，到了第 4 次的时候，这个轻的球就可以被找到了。从数学上来表达，16 个球等于 2 的 4 次方，我们可以知道分成 4 次就可以找出这个轻的球。

我们放一个数学表达式来看，实际上它也是一个对数的格式，就相当于以 2 为底，4 为对数，取对数后等于 4。这里引出了另一个概念，也就是信息的度量单位「比特」。我们可以看到，在刚才 16 个球的例子中，我们是以 2 作为底数的对数值。大家可以看到，这个 4 其实就是信息论中我们指的「比特」。

刚才前面求的是选择，每次选一半。那么这里面我们可以假设一下，假设这些球不是只有轻重两个答案，而是有三个答案的时候，比如有的球特别重，有的球比较重，有的球是轻的。那么当你有三个答案时，实际上在取对数的时候，这个底数就不再是 2 了，而是以 3 为单位。大家就明白了，这样就表示我们可能的答案有几个。

当然，在绝大多数时候，在计算机系统里面，因为我们用的是开关的 0 和 1，它可以表示很多内容。所以绝大多数时候在信息论和计算机科学中，我们常常采取的是二进制。这与我们电位的开关能表示 0 和 1 有很大关系。这样的话就能简化很多问题。三进制无非就是拆成两个二进制，十进制无非就是拆成几个不同的二进制。

这里面有一个非常有意思的人生哲学问题：假如你一生要开一千次盲盒，那么关键的选择不超过 10 次。这个推论是怎么来的呢？因为 2 的 10 次方表示为对数，实际上是 1024，所以大家就明白了，原来对我们人生最有信息含量的关键选择其实没有超过 10 次，它约束了我们人生发展的走向。

刚才我给大家通过一个简单的小游戏，向大家阐述了信息熵究竟是怎么回事。在真实的数学世界中，信息熵实际上比我们想象的要复杂，因为我们不仅存在一个球有三种情况、四种情况、五种情况…… 那么这里面我们把它泛化成数学概率的表达。

这就是香农最原始的论文和著作的定义：假设有一个可能事件集合，这些事件的发生概率是 p1，p2，…，pn。那么整个事件组合在一起的概率集合，我们可以把它累加在一起，最终来进行计算。这个用 H 来表示，对数取 2，实际上是把这些负的信息量加在一起，最终形成了信息熵。

这里面我们可以看一个具体的例子。假设你现在要抛一个硬币，这个时候我们只有两种可能，要么正面朝上，要么反面朝上，出现的概率都是二分之一。抛硬币的信息熵，我们可以按这个计算结果，最终取二的对数，实际上是 1 比特。这样大家就明白了信息熵是怎么算出来的。像硬币的信息含量和不确定性是 1 比特，这是容易理解的。

我们再看一个更难一点的例子。像现在有八个八宝格，每一个格子中都有可能存有宝藏。那么这个时候就不再是二分之一的概率了。大家可以看到，每个格子的概率变成八分之一了。我们把八分之一累加在一起，最终按照公式计算之后，你会发现它的信息含量是 3 比特。这是第二个例子。

我们再在这个基础上继续延伸。刚才我们看到抛硬币是二分之一，八宝格是八分之一，它们每一个概率都是一样的。那么这个时候我们再举个例子，比如在香港赛马中，赛马公司开出的赔率给每一匹马是不一样的。我们假设一号马的赔率是 1/2，二号马的赔率是 1/4，三号马是 1/8，四号是 1/16，五号、六号、七号、八号是 1/64。那么每一匹马你会发现它的概率就变成了 1/2，1/4，1/8，1/16，1/64。我们再把它以 2 作为对数进行计算，然后放在一起最终计算出来的，我们会发现大概是 2 比特左右。也就是说，如果你已经知道赛马公司每一匹马的赔率，你要分析这场赛马的冠军是哪匹马，你需要的信息量实际上是 2 比特左右。

通过这三个例子，我们就明白了信息熵是怎么回事。当然，香农的整本著作和论文，实际上关于熵还有更复杂的一些定义，不仅仅局限在我们刚刚说的定义。我们刚刚谈到的熵更多是一种情况，而香农还提出了两个非常重要的概念：

第一个是条件熵。我们刚刚谈到的熵实际上取的是一个单一的离散变量，那么当两个变量交叉在一起的时候该怎么去计算呢？这就是香农称之为条件熵，它会涉及到两种情况：一种是我们需要计算条件熵 —— 获取一个信息之后，不确定性还有多远；另一种是掌握多个信息之后，概率有多大。

还有一种就是在信息论中，我们经常需要考虑的负信息，就是掌握的信息和解决的问题的相关性有多大。这是对信息论的一个扩充，这里就不再展开介绍了，感兴趣的同学可以自己去了解。

这里面我们有一个非常有意思的问题：香农的信息熵能适用于一切信息吗？其实答案显然是不适用于一切信息的。我们可以看到香农对的地方在于，作为信息论的创始人，他影响了我们 21 世纪计算机的诞生，影响了我们步入信息时代，实际上是因为他的计算公式非常清晰。这是他非常正确的地方。我们说得再直白一点，没有香农，没有冯·诺依曼，就没有 21 世纪的计算机，没有 21 世纪的信息时代。这是他非常对的地方。

当我们明白了信息熵是怎么计算的，我们用比特来表示信息熵，我们用电子管的 0 和 1 开关来表示二进制，这样我们能够更好地对世界进行数字化。但他有一个很大的局限性是什么呢？实际上通过前面的介绍大家会发现，香农熵有一个前提条件，你需要已知各个事件的信息概率分布。比如我们举的三个例子：抛硬币，你明白它的概率分布是二分之一；八宝格，它的概率分布是八分之一；赛马，我们有赛马公司给我们开出的赔率。但是在绝大多数情况下，我们在人生中还存在另一种情况，对很多概率，我们其实是不知道的。虽然香农有负信息、条件概率这些概念，但是它有一个前置的概率空间，我们没办法预测未来。

所以大家会发现，所有基于香农、基于冯·诺伊曼体系的计算机有一个很大的缺点：它没办法给你制造一些惊喜。当你给计算机写入程序，约定了什么样的情况，那么这个计算机最终就会按照这个情况去输出，所以这是它很大的一个缺点。我们会发现，香农的信息熵默认事物的状态可以用经典集合论的概念模型来表达。但是在我们真实的世界，在我们整个人生发展的过程中，有太多太多事物的运动状态我们很难找到一个合适的概念模型，这就是传统信息论的缺点。

我们可以看一下一些科学家从不同的角度对香农的信息论进行了完善。首先是阳老师在行为分析和认知系统论中非常推崇的一位科学家贝特森。他是英国人类学家、社会学家、心理学家，也是著名的控制论、系统论和信息论学者。在麦凯 1969 年《信息、机制与意义》这本书中的影响下，他提出了一个概念，认为信息是「造成差异的特色」。贝特森所开创的「心-灵-身学派」认为，信息不仅仅是数据，信息是「造成差异的差异」。这与香农的定义不同。如果说香农非常注重信息的量化和态，那么贝特森非常注重信息的意义和语境。我们可以用一个常见的比喻来理解：香农的那些信息其实就是我们计算机科学经常处理的「数据」，而贝特森这里所讲的信息其实接近我们心理学所说的「认知」。这是他们两者之间很大的区别。

『已下载原文书籍「2024041Information-Mechanism-and-Meaning」「2024042Steps-to-an-Ecology-of-Mind」，其中 2024042Steps-to-an-Ecology-of-Mind 即为《心灵生态学导论》。（2024-05-28）』

我们再看一下另一位科学家，这是加拿大科学家洛根。他发现香农关于信息的定义有一个很大的缺点，就是香农把信息作为不确定性减少的量，大家会发现这个定义其实特别适用于计算机、特别适用于物质，但是特别不适用于自组织系统，也就是生物系统。因为刚才前面谈到的香农信息熵，我们必须对概率集合进行前置，但像达尔文式的进化，我们完全没办法把这些概率事件前置。我们是通过一个极其简洁的规则，最终推演出非常复杂的生物系统。并且在达尔文进化的过程中，我们的生物系统更多要体现的是自己对环境的一种适应。那么这个时候你使用香农的信息熵去进行计算，显然会存在很大的不足。

这个时候，在 2014 年，洛根写了一本书《什么是信息》。他在这本书中尝试提出一种不同于香农信息的信息，他称之为「学习信息」或者「生物信息」。他又借鉴了另一位物理学家洛西的定义，认为信息可以定义成「过程输出的特征」。这就相当于能够把达尔文式的信息包括进来了。

『书籍是没找到，只找到论文「2024009What Is Information?: Why Is It Relativistic and What Is Its Relationship to Materiality, Meaning and Organization」。（2024-05-28）』

我们可以看一下洛根对的地方是什么。他注意到了生物学的信息，比如我们人对环境的适应、我们人主动去学习、我们人对信息的感知，还有我们作为基因和模因的载体，我们的基因如何携带信息、如何最终发展出一个极其复杂的人类社会，我们的模因如何在人类社会以语言、观念、文化的形式进行传播。这是洛根特别对的地方。他注意到生物学信息、学习型信息、符号型信息与香农的信息并不相同，香农的信息并没办法解释和计算这些生物学信息。这是他非常正确的一方面。

但是他错误的地方是什么呢？他实际上没有给出生物学信息一个数学的形式，他只是从理论上讲认为我们存在一个生物学信息，但是生物学信息究竟从数学上该怎么表达，洛根这一步完成得不太好。香农采取了信息熵的概念然后进行了一个极其优雅的表达，而洛根没有做到这一点。如何更好地度量这一类生物学信息？

这里面我们引出一个新的概念，就是「自由能」。自由能这个概念是我在另几本书《心智三部曲》中写到的。我之前没有意识到信息分析跟自由能有紧密关系，但是这几年随着我对信息论了解的增加，我突然发现我之前在其他书中写的自由能概念，实际上能够更好地解决信息论没有解决的问题，也就是香农没有解决的问题 —— 我们如何从传统的冯·诺伊曼体系的计算机，到新一代的计算机体系。

这里面我们需要引入一个新的概念。热力学中不仅存在熵，还存在另一个重要的概念叫「自由能」。我们先来看一下什么叫自由能。我们前面已经明白了，熵在热力学中表示的是混乱的程度，当热力学系统越混乱，它的熵越大。这个大家我相信在 21 世纪接受各种信息轰炸，作为一个科普概念，各位同学都了解了。

热力学领域的另一个概念，大家也许不太了解的，叫「吉布斯自由能」。它跟熵是紧密相关的，但是它又比熵多了一些东西。大家可以看一下，这是热力学中关于吉布斯自由能的定义，它是来描述一个热力学系统的热力学性质的。这里面大家会发现，它是如何计算热力学的吉布斯自由能的。用 G 来表示，U 表示系统的内能，T 表示热力学理想系统的绝对温度，S 是熵，P 是压强，V 是体积。绝大多数时候，我们的压强和体积是相对确定的。那么这个时候会出现一个非常有意思的现象。在热力学中，我们实际上使用了自由能这个概念来表达一个热力系统可以做出多少的非体积功，也就是将内能转化成能够对外部产生作用的能量。

这就是热力学中非常著名的「自由能原则」：在等压可逆的条件下，封闭体系中的过程总是自发地朝着自由能减小的方向前进，直至达到在该条件下自由能最小的平衡位置。

我们可以看两个具体的例子。第一个例子是，我们在热力学中经常会发现，当温度不变、压强不变时，碳和氧在一起，它们总会自发地进行混合。这其实就是一个很典型的吉布斯自由能原则的应用。

我们再看另一个例子。各位同学也许在生活中都听说过，一杯热水会自然地变凉。比如我现在有一杯茶，把这杯热茶放在旁边几十分钟之后，它会自然变凉。这其实也是吉布斯自由能原则的一种应用。从热水到凉水，水还在杯子中以液态存在，水本身没有发生变化。从热力学状态上讲，它的体积、压强也没有发生变化。但是它的内能变小了，转化成了外能。也许这杯水旁边的空气变得多了一些热能。这就是吉布斯自由能在热力学中经常应用的一个原理。

最神奇的是什么呢？热力学的自由能这个概念，实际上在一百多年前已经变得相对比较普及了，已经成为我们整个物理学和化学领域的一个基础知识。只要你学习热力学，必然会接触到这个基础知识点。

但是到了 21 世纪，出现了一位伟大的科学家，这位科学家叫弗里斯顿。我开玩笑说他是注定要获诺贝尔奖的科学家。大家都知道，在学术界有一个衡量一个人学术贡献的指标叫 H 指数。弗里斯顿在他 40 岁左右的时候，他的 H 指数其实已经非常高了，因为他发明了一种非常重要的神经成像算法。基本上他可以代表整个认知科学、神经科学、心理科学界的 No.1。相当于他在非常年轻的时候，基本上就已经可以获诺贝尔奖了。然而整个认知神经科学领域，我们只要涉及到对大脑成像来进行计算，我们必然要使用弗里斯顿开发的软件和算法。

作为一名认知科学家，虽然我不是很精通认知神经科学，但也了解一些实验细节。我更精通的是计算认知科学。在认知神经科学领域，我们其实是绕不开弗里斯顿的。但是这位科学家最厉害的地方是什么呢？他没有停留在这个地步。他意识到，整个认知科学、神经科学、心理学自从诞生几百年以来，其实存在着非常混乱的理论。它始终不像经典力学领域，我们存在着一个牛顿定律；不像热力学领域，我们存在热力学定律。弗里斯顿就一直在思考，是不是在认知科学、神经科学、心理学领域，也存在着第一定律？

所以最终他完全放弃了他在极其年轻的时候取得的这些重大成就，就是在认知神经科学这部分，然后提出了「自由能理论」。我们用一个简单的比喻：刚刚谈到，吉布斯在热力学领域的自由能，它其实表达了一个概念 —— 我们的热水接触空气之后，自然会变凉。从物理学上讲，总是会出现水往低处流的现象。

那么，我们人作为一个自适应系统，其实也有一个相对应的现象：我们人会往高处走。那么为什么我们在行为层面会往高处走？为什么在分子和细胞层面，我们人能从达尔文式的简单 DNA 中演化出无穷无尽的智慧？显然这些东西，你会发现采取传统的科学观念是解释不了的，采取香农信息熵也是解释不了的。

所以弗里斯顿在 2010 年左右正式提出了自由能理论。这个理论在近十年不断完善，在我的《心智三部曲》中，我把它称之为「心智第一定律」。这个定律是什么意思呢？他参考了热力学中的自由能概念，认为任何自组织系统，都会保持自己的自由能最小化。

我们会发现，在前面，香农引入了热力学的熵这个概念来表示我们怎么对不确定性进行估算。但是我们会发现，香农在估算不确定性的时候，我们更多是已知的概率，没办法估算人、没办法估算生物系统，所以这是香农很大的一个不足。

我们来简单地看一下自由能公式。先给大家解释两个重要的前置概念。第一个叫「惊奇」，第二个叫「熵」。熵前面我们已经很明白了，那么接着来解释一下什么叫「惊奇」。惊奇在弗里斯顿的公式中定义成「结果的负对数概率」。比如我们前面谈到，从物理学上讲，水往低处流是一种物理学现象。那么当你掌握到这种物理学现象时，你碰到水往低处流的时候，你作为大脑不会产生惊奇感。但是突然有一天，你会发现水往高处流而不是往低处流，这个时候你就特别莫名其妙了，你是不是就会产生一种惊奇感了？

比如在人类社会，这种惊奇感也是非常普遍的。突然之间有一天你会发现一个外向的人突然间变得有点忧郁，或者一个内向的人突然特别主动地去拉着别人说话，这个时候我们就会产生惊奇感。

传统意义上的熵的计算、信息的计算，实际上没有考虑到我们人对外在世界的感知，也没有考虑到惊奇的因素。这就是自由能非常重要的贡献。

我们再来看一下自由能公式。这个公式实际上目前因为是学术界一个极其热门、极其有争议的话题，有很多问题还没彻底解决，所以我们先给大家简单介绍一下。更详细的介绍大家可以看我的《心智三部曲》，里面会介绍得更详细。

我们先看一下自由能的作用机制是什么。首先，自由能的量和熵就不再一样了，它引入了内部状态和环境状态。我们会发现，像赛马、抛硬币、八宝格，我们前面举的三个例子，无论什么样的人来赛马、抛硬币、开八宝格，它其实对人与人是相对公平的。但是在生物系统中，实际上我们对外界信息的感知是不公平的，我们会因人而异。

所以这个弗里斯顿的自由能其实定义了两个计算原理。第一个是内部状态，第二个是环境状态。内部状态指的是什么呢？比如在行为科学层面，指的是我们人对外界的一些感知；在认知科学层面，指的是大脑的认知机制对外界的感知；在神经科学层面，指的是大脑的神经元对外界输入信息的感知；在细胞层面，指的是 DNA 信息对外界信息的感知。

大家会发现，弗里斯顿的自由能之所以能够把所有认知科学、神经科学、心理学的理论统帅在一起，是因为它能兼容不同层面。

再看一下环境状态是什么。环境状态其实就存在一些客观的物理规律，这部分就跟传统的热力学、传统的牛顿定律关联起来了。比如我们这个环境状态总是水往低处流，当它符合重力学规律、出现了水往低处流的现象时，你的大脑不会产生惊奇。但是一旦出现了违背这个物理状态，比如水不再往低处流而是往高处流，这个时候你就会产生一种惊奇，你的自由能这部分就相当于开始有了一些变化。这是作用机制的左边。

我们再看右边这个图是什么意思。弗里斯顿罗列了很多东西，这些其实都是比较重要的，但是今天不展开讲。这里面我们人和香农的信息熵有个很大区别是什么呢？香农其实只用了一个简单的条件熵、负熵、条件信息来表示信息和信息之间的关联。但是弗里斯顿非常不一样。他发现我们人类整个信息的关联，我们基本上下一步的决策特别依赖上一步的决策。所以我们人其实存在着一个行动与感知两者之间的关系。行动和感知，我们使用的是将预测误差降到最低，也就是说我们人总会驱使自己的自由能最小化。大家就明白了。

这里面是他的详细公式，这些详细公式我先不展开讲。这个是自由能的影响变量，外部状态、感觉信号输入、内部状态和行动或者控制信号输出。这是它具体的公式。

弗里斯顿提供了三种辨识。第一个辨识，自由能是对惊奇的约束；第二个辨识，我们人始终会最小化预测误差；第三个辨识是感知也会最小化预测误差。这部分我先都不展开讲了。

看完这些自由能的公式，实际上我们会发现，弗里斯顿做了一个比较重要的工作，他实际上对传统的香农熵还有热力学进行了扩充。假设按照传统的观念，我们始终会认为人是永远处在一个我们称之为「熵增」的情况，我们永远没办法逃脱「熵增」的世界。但是你会发现，人作为一个自组织系统，我们始终又会寻找各种信息，我们生下来之后并不是像很多人想象的那么悲观。

那么我们人是怎样抵抗热力学第二定律的呢？实际上是借助于惊奇和自由能去抵抗。这里面有一些详细的介绍。我们人类始终会把自己的惊奇最小化，最终使得我们对这些预测成真。这是弗里斯顿对我们的一个巨大启发，也是不同于传统的只看到熵的一些物理学观点的看法。他认为我们来到世界就一定是熵增熵确定，但是其实除了熵之外，我们人还会行动。我们的行动是建立在惊奇感之上，建立在感知和行动之间的预测误差之上，我们始终会使得我们的惊奇最小化，使得我们的误差最小化。

通过这些介绍，我们实际上发现了一个重要的学术脉络关联。这也是我在研发信息分析 3.0 的时候第一次发现的。因为我之前写了一套《心智三部曲》，写了好几年，我之前没有意识到香农的信息熵和弗里斯顿这个我最熟悉的认知科学自由能之间的关系。但是在我研发信息分析 3.0 的时候，我突然间意识到他们两者之间其实是一个重要的关系。弗里斯顿将自组织系统的行动理解为一个贝叶斯主动推理的过程，从而超越了香农的局限性。香农没有意识到我们人有这种生物学的信息。

大家就可以看到了，信息不仅仅是香农信息，还存在一个达尔文信息。达尔文信息是我提出的一个新的名词，到时候抄写我的人注意不要抄错了，这个词之前没出现过。

我们可以看一下香农信息和达尔文信息究竟有什么样的差异，有什么相同的地方。香农信息从信息的定义角度来讲，实际上指的是在已知情况下能减少不确定性的任何事物，这部分大家都明白了。但是达尔文信息其实不是这样的，它是一个过程中输出的特征。比如我们人行动的时候会输出特征，我们的 DNA 会输出特征，这些特征值其实就是信息。

然后我们再看下香农信息的载体。香农信息的载体与媒介是分离的，所以我们能够很好地把计算机中存储的文件放到另一个计算机中。我们也能够通过微信、通过各种工具传输不同的文件。对于香农信息来说，信息的载体与媒介是分离的。但是对于达尔文信息来说，媒介即信息。比如我们人的 DNA，携带的信息，我们并没办法把它单独脱离某一个人。我们的 DNA 信息是媒介即信息，这类信息是极其特殊的，它是与个体直接相关的。这是媒介即信息，它的载体和媒介不是相互分离的。大家明白了。

我们再看一下信息的概率集合。香农信息它的信息概率集合是已知的。当我们抛硬币的时候，我们事先已经知道了硬币只有正反两种结果；当我们开八宝格的时候，我们知道了宝藏放在八宝格里面的概率是八分之一；当我们赛马的时候，我们也知道了每匹马的概率是多少。但是对于绝大多数涉及到达尔文信息的，我们的概率集合是未知的。我们小时候很难预测这个人长大之后会成为什么样的人。我们甚至连一个更简单的预测问题，我们在 21 世纪从科学上来讲依然解决得不够好。比如我们已经对一个人进行了基因全测序，我们连预测他可能出现什么疾病、他的智商可能达到多少，我们都预测不准。这里面就相当于会存在一个很大的不确定性，因为达尔文信息有很大一部分是未知的，它的概率结果是通过生物体与环境的交互，最终达成的一种平衡的结果。

然后我们再看一下香农信息的度量。我们使用的是信息论的一个经典指标 —— 信息熵来进行度量。我们信息熵的单位，我们今天在 21 世纪大家都明白了，我们可以使用比特。那么像达尔文信息，我们今天通过我的介绍第一次明白了，原来我们可以使用自由能来度量达尔文信息。但是像弗里斯顿自由能究竟能不能存在一个类似于比特的单位呢？到了 21 世纪这个答案依然没解决。相当于是一旦解决了，我们就非常容易发明出类似于冯·诺伊曼体系的计算机，我们能够实现类似于大脑的高速计算，而不是像传统计算机的计算。我相信这个难题是整个 21 世纪科学界非常关心的一个难题。我个人认为答案就在于，我们能不能更好地找到一个类似于比特的单位来估算弗里斯顿自由能，还有就是我们能不能找到类似于开关的电荷来模拟自由能的做功过程。我认为整个人工智能和下一代计算机的突破方向就在这个领域。这个是我的一个提前预测。

通过这部分，我们就终于明白了，原来生物存在既是物质的存在，我们可以表现为生物有大小，比如我有身高、体重等等，这是一种物质存在；我们人这种生物存在也是一种信息存在，比如我现在给大家讲课，在传递一些我的新的认识，关于信息论怎么超越香农信息的一些看法，还有对未来计算机世界的一个发展看法，这是一种信息存在。但是人的生物存在既不是物质存在，我们会发现即使是同卵双胞胎，他们两个人也没办法发展得一模一样；也不是一种信息存在，我今天讲过的东西，明天再重新来讲，也必定讲不了一模一样。所以我们会发现，生物存在是一种相对特殊的存在。

这就是整个人类社会，甚至是整个地球上，我们最经典的三大类存在。第一大类存在是物质存在，第二大类是信息存在，第三大类是我们的生物存在。我们会发现这三大类存在，它们所采取的基本单位其实都是不一样的。比如像物质存在，我们有热力学单位、重量单位等等；像信息存在，我们会发现最好的单位、最好的度量是信息熵，单位是比特；而生物存在，我们会发现最好的度量是弗里斯顿的自由能，但是这个单位到了 21 世纪的科学界还没解决。

这就是人类的三大存在。我们一旦找到这些基本单位，我们是不是能够更好地理解世界运作的规律？这部分我在三大存在的基础之上，总结出了三大存在的各个基本场以及各个基本参数。这就是我们下一讲的全局认识，我要跟各位同学分享的关键内容。

### CH0202信息的分布

接下来，我们来看另一个有意思的话题：信息的分布。信息与信息会交错在一起，最终形成信息网络。我们谈到两种信息，一种是偏达尔文的信息，这种网络我们可以称之为生物网络或人际网络；另一种是香农式信息，在 21 世纪你身边无处不在的计算机网络、互联网，我们也可以称之为信息网络。我们会发现，这些信息交错在一起，虽然信息的数量巨大、类型多样、变化频繁、结构复杂、质量参差不齐，但是它们的分布依然会遵从一定的规律。






无论是香农信息网络还是达尔文信息网络，在数学上都会表现为三大网络：第一个网络我们称之为随机网络，也称之为同质网络；第二个网络我们称之为小世界网络；第三个网络我们称之为无标度网络。这里涉及到一个有意思的词汇，什么叫「同质」和「不同质」。

刚刚我们谈到达尔文信息，比如阳老师的身高、智商、开车速度等，这些都是人类的一些指标。像这些指标，它其实是一个无标度的、同质的。比如你的身高和我的身高，我们可以基本上认为差异不会特别大。我是个子比较矮的，但是你比我再高，你也不可能高出两倍，比如你不可能是一个三米多的人。所以在统计物理学上，我们称之为无标度的，它的特征不太明显，也称之为同质类信息。大家明白了。

另一类，比如像朋友的数量、你读过的书的数量、你拥有的财富，这个时候你会发现它是异质的，它不具备特征尺度。比如大家知道我家里的书特别多，昨天晚上我几位同事来我家，他们做了一件比较无聊的事，他去数我一个书架上有多少本书。他们数了半天发现，差不多一个书架上有六百多本书。但是像我家里差不多有三十多个这样的书架，所以估算还不够准确。大家会发现，这个时候我家的藏书和你的藏书数量，其实我们是不具备特征尺度的，可以很小也可以很大。比如有的人家里没有一本书，有的人家里书特别特别多。这一类信息在香农信息中是非常普遍、非常常见的。

我们再回到这里，可以看一下随机网络。它实际上更多是由像力学、身高、智商这些构成的。无标度网络，它就更多是像朋友数量这些构成的。小世界网络是介于两者之间的。

在统计学上，我们都知道有三大常见的分布。第一个是正态分布，第二个是与正态分布相对的幂律分布，幂律分布有时候我们也称之为帕累托分布等等。还有就是偏态分布，它有个相关的左偏和右偏。

那么这三大网络呈现的分布规律是什么样的呢？在随机网络中，绝大多数时候我们是正态分布。比如像一个人的智商，它会呈现一个经典的标准钟形分布，这部分我们称之为中心曲线。在无标度网络中，绝大多数时候是幂律分布。因为我们关于无标度网络有一个定义，就认为它的度的分布要呈现幂律分布，它才能称之为无标度网络。小世界网络有时候是介于两者之间的，看你是站在一个什么样的角度来看。小世界网络其实更切中的是人际关系还有节点的连接度。

这就是在信息分布上，这三大网络呈现出的一个规律。那么无标度网络，这是它的一个定义，是由巴拉巴西提出来的。为什么会出现无标度网络？实际上是因为它跟我们网络的生长和偏好连接规律有关系。比如为什么一个人的朋友数量，有的人会有几千几万朋友，有的人只有几个朋友？当我们想去寻找别人做朋友的时候，我们其实都倾向于寻找那些拥有朋友数量更多的人做朋友，这样最终他的朋友数量就越来越多了。

同样地，一个人挣钱，当他拥有的钱越多，他挣钱就相对越容易。所以网络的生长和偏好连接，使得那些异质网络特别容易出现无标度网络的特征。大家就明白了。尤其是在香农信息中，特别容易出现。相当于对一个信息网络的概率集合能够越好地进行估算，这个时候就越容易出现无标度网络。

举个例子，比如在人生发展的时候，我们可以选择不同的职业。有的职业特别容易计算胜出的概率，比如参加奥运会的体育竞技项目，基本上它的概率值是相对确定的。每年只有那么几个冠军，这个时候它就特别容易出现无标度网络的分布。这个时候它会呈现一个很典型的香农信息分布特征规律，最终就成了奥运冠军。像苏炳添这些人，如果他不是冠军，那些国外领先的人就拿走一切，相当于一些不是冠军的人最终就什么都没得到。

但是有的信息网络中，它的概率是不确定的，比如写作领域。一本书能不能成为一本畅销书，虽然我们也能够进行一些近似的概率估计，但是还是有大量随机的情况出现。总会有一些神迹结构，它和传统的信息结构不一样。这是上一节课我给各位同学介绍过的，比如像《哥德尔、埃舍尔、巴赫：集异璧之大成》（Gödel，Escher，Bach: an Eternal Golden Braid，简称 GEB）就是一种神迹结构。在写这本书之前，没有任何人能预见到它会成为一本畅销书。

同样地，在人类历史上这样的例子特别多。我们刚刚前面谈到的「媒介即信息」，这句话出自英国传播学的一位重要学者马歇尔·麦克卢汉（Marshall McLuhan）的经典著作《理解媒介》（Understanding Media）。当年他这本书刚开始出版的时候，其实销量特别不好，卖得比较惨淡。但是之后，它慢慢地成了一本世界非常经典的畅销书。所以你会发现，在写作领域并不会出现「赢家通吃」的规律。

当然，在 21 世纪，有越来越多的傻瓜，他们把这种概率变得越来越透明了。比如他们制造了各种各样的图书排行榜，还有各种各样的指标，最终使得大家普遍出现了内卷化的现象。这个就是从网络科学角度来理解这些社会的底层规律。

我们再看一下，这里面还有一个非常关键的因素是什么呢？无标度网络在日常生活中有一个通俗的词汇，就是「马太效应」—— 穷者越穷，富者越富。这个定律在学术领域最典型的就是「帕雷托法则」。在城市发展上，你会发现 20% 的城市会贡献 80% 的 GDP。

这里面会出现一个特别有意思的转化。比如像城市的 GDP，我们是站在一个幂律分布的角度来看的。但是你可以对它们做一个数学变换，最终取一个对数之后，大家可以看到左边和右边的图，它就不再是一个幂律的帕累托分布了，而是变成一个类似于指数分布。这个时候其实对我们有一个非常重要的启发，就是需要找到关键的「K 值」，一旦找到之后，你能够预测很多信息的走向。

这个规律在科学上我们称之为「异速增长律」。它最早是由生物学家在 1936 年发现的。他们当时研究螃蟹的螯（qiāo）子大小与身体的关系，发现螯子的增长速度要远远快于它的体积的增长速度。这就是异速生长的来源。中间有一个数学推导的过程，这部分我们不详细展开。总之你会发现，螃蟹的螯子大小跟它身体体积的 1.57 次方成正比，也就是说斜率 k 等于 1.57。这就是我们前面讲的 k 值。

1『关于 k 值的知识，具体可以去看书籍《2018148规模》。（2024-05-02）』

其实这意味着，所有生物体的成长都会有极限，通过异速率就能够很好地理解。我们再看另一个 k 值，这次以体重为例。一个生物的基础代谢率与它体重的 3/4 次方成正比。大家会发现，这样所有生物长到一定程度就不会再生长了，因为它需要拿一部分能量来维持现有身体，另一部分在产生新细胞。它们不能够完全都用于新细胞，否则这个生物个体就没办法成长。所以一般来讲，就是 3/4 这样一个比值，这是一个关键的 k 值。

我们再回到城市发展。实际上，刚才前面谈到城市发展，你会发现有科学家做了类似的计算。他对一个城市的工资总额、GDP、总住房面积、加油站等指标进行计算之后，发现普遍存在类似的标度。只是它不是 1/4，而是 0.85 次方。这就是一个关键的 k 值。大家明白了。

这个发现相当于，一个城市的人口越多，所需要的基础设施越多，但是基础设施的增长速度永远比人口增长速度慢。我相信这个现象大家在日常生活中也非常容易理解，因为盖房子、盖地铁这些都需要时间，但是人口迁入的成本和速度会快一些。

当我们再看另一个统计结果时，正是一个城市的财富创造与人口的 1.15 次方成正比。也就是说，人口越多，城市的财富创造越快，且城市创造财富的速度比人口增长的速度还快。这就相当于有一个现象，在 21 世纪你会发现大城市变得越来越大，小城市变得越来越衰败，因为这实际上也跟这个规律有关系。

那么我们刚刚拿这两个例子，会发现给大家一个非常重要的启发。城市这一部分实际上有两个 k 值，第一个 k 值是 0.85，第二个 k 值是 1.15。像螃蟹，我们存在一个 1/4 的 k 值，也就是 0.75。这提醒我们，假设如果我们能了解到一个信息网络中的关键指标，那么我们是不是能够更好地预测一个复杂系统的发展规律？比如我们究竟应该选择什么样的城市，我们究竟应该去什么样的城市，究竟存在哪些关键指标？

这就是接下来给大家分享的第一类关键指标，是跟信息网络的整体层级有关系的。主要有这几个指标：密度、中心性、互惠性、传递性。这是当年指导俞文的一篇论文，他做了一个表格。什么叫密度？其实指的是信息网络中边的数量与可能边的数量的比例。什么叫中心性？指的是中心度最大的节点与其他节点中心度的差异。什么叫互惠性？指的是信息网络中的双向程度。比如 A 喜欢 B，B 喜欢 A。当信息网络中是三个人构成的人际网络时，A 喜欢 B，B 喜欢 A，B 喜欢 C，C 喜欢 A，它们之间都相互喜欢，那么三个人构成的人际网络，它的互惠性就非常高。什么叫传递性？比如像节点 A、B、C，A 和 B 相连，B 和 C 相连，那么 A 和 C 也就会相连。这些就是指标。

我们这里可以看一个简单例子。大家可以看到，这是当年我拿北京市一个中小学班级做的一个试验。这里面对我们有一个非常关键的启发是什么呢？我们之前在信息分析 1.0、2.0 时代，我们其实不知道怎么去计算全局认识。当时我们会发现，陈昌北老师在学术信息分析领域使用了一些类似的概念，最终能够很好地计算一个学术领域的信息网络分布。

同样地，在信息分析 3.0 中，我们明白了，一旦使用密度、中心性、互惠性、传递性这些概念，就能够更好地理解一个信息网络的信息分布。还有后面提到的有趣度，我们的计算跟前面介绍的概念有紧密关系。当然，信息分析 3.0 这些内容依然还不算特别成熟。我相信到了信息分析 4.0 时代，我们甚至能开发出更多新一代的计算机软件，能够更好地识别这些信息特征。这里只是一个前置知识点的介绍。

我们再看一下节点层面。节点层面有程度中心性、中介中心性、接近中心性和特征向量中心性。这涉及到两个重要的概念：一个是度，一个是中心性。度其实指的是节点的连接数。比如说相当于 A，它的度就是 2，它连接到两个节点。B 大家可以看一下，它连接了一个、两个、三个、四个，那么它的度就是 4。

中心性就是衡量节点和边重要性的一个指标，最常见的有四种中心性。这四种中心性分别给大家做一个简单介绍：

- 程度中心性指的是谁是明星，谁是边缘人物；

- 接近中心性指的是谁是公司的八卦传播者；

- 中介中心性指的是两个网络中的跨界者；

- 特征向量中心性指的是像电影《教父》中的教父那样的人物。

我们可以看几个具体的例子。比如在微博的信息网络中，我的好朋友魏坤琳老师有四百多万粉丝，那么显然他是一个名人，他的程度中心性比较高。

我们再看一下，在一个公司中，有些人虽然不是领导，但是很多人都跟他关系非常好，他的接近中心性比较高。很多八卦从他身上很容易知道。

我们再看一下中介中心性。比如有一位计算机博士，他本身也是摇滚乐队的主唱，那么这个时候他的中介中心性就比较高。

我们再看一下特征向量中心性。比如像我喜欢躲在幕后，认识不少大佬，但是自己出现在前台的时间比较少。像这种躲在幕后的人，他的特征向量中心性其实比较高。他连接的那些有影响力的人比较多，但是他自己本身又不像魏鲲鹏老师那样被很多人知道。

给大家介绍这些概念，有一个非常重要的作用是什么呢？我们在第五讲中将介绍有趣度。有趣度实际上跟信息网络的整体边界有关系，也跟中介中心性有关系。这是最常见的一种有趣度。比如在人际网络中，一个极其有名的人，像魏坤琳老师这样的人，绝大多数人不一定会认为魏坤琳老师有趣，因为他的程度中心性高不是一个很好的对他有趣度的估计指标。但是一个人既是计算机博士、程序员，又跑到乐队去当主唱，那么我们基本上会认为这个人是有趣的。比如像刺猬乐队的主唱，他在互联网科技公司当程序员，这样的人我们一定认为他是有趣的。

所以大家会发现，当我们知道一个信息网络的边界之后，再来计算中介中心性，其实我们非常容易推断出一个信息网络中谁的有趣度会高一些。这也是我们在第五讲中会谈到的计算有趣度的一个常见思路。当然，有趣度的计算思路在信息分析 3.0 中依然还不算特别成熟。我估计到了信息分析 4.0、信息分析 5.0，会变得更加成熟。

这里我只是给大家介绍了一个重要的思路。事实上，这些前置知识大家就明白了。

### CH0203信息的传播

接下来我们再来看一下信息的传播。信息的传播最终有四类模型。

第一类模型是巴斯（Bass）模型。巴斯模型是由心理学家巴斯提出来的，之后又被著名作者在《创新的扩散》(Diffusion of Innovation）一书中普及。巴斯模型说的是什么意思呢？相当于一个信息的传播，它跟两个关键指标有关系：第一个是创新率，第二个是模仿率。我们接受一个新的东西、一个新的产品、一个新的信息，依赖两方面：一方面是这个人创新的思想，也就是这个创新产品被别人自发地接受；另一个指标就是其他人进行模仿的接受率。它的公式计算大家可以看到，这里面有两个关键指标：一个是创新率，一个是模仿率。

在《创新的扩散》这本经典名著中，作者举了一个例子，技术的创新往往会遵从巴斯模型。刚开始的时候，一个新的产品、一个新的思想，它的信息传播速度是非常慢的，然后逐步加速，再逐步放慢，最后平稳。这本书里面举了一个例子，就是一个新的药物叫四氨醌。推出之后，两个月中有 15% 的医生使用，四个月之后这个比例攀升到 50%，17 个月内美国伊利诺伊州的全体医生都开始使用了。所以这是巴斯模型对于信息传播的一个理解。

但是巴斯模型有一个比较大的缺点是什么呢？它没有考虑到网络结构，信息网络的结构。所以有另一个模型，它是特别依赖网络结构进行传播的，会呈现不同的规律。比如我们今天都来接受病毒的传染和扩散，像现在的新冠肺炎，还有最早的黑死病，这一部分其实是特别依赖特定的网络结构。比如在一个特别荒芜人烟的地方，新冠肺炎相对来说没那么容易扩散；但是在像武汉、上海这种大型城市，新冠肺炎的扩散速度就会快很多。

通过这个例子，我们就明显会发现，信息在进行传播的时候，其实是很依赖不同的网络结构的。科学家总结了三个最经典的病毒传播模型来描述信息传播的规律：

第一个模型叫 SIR 模型，第二个模型是 SIS 模型，第三个模型是 SIRS 模型。

第一个模型可以理解为最简单的模型。以新冠肺炎为例，S 是健康的，I 是感染的，这是最简单的模型。这个时候要计算各种干预。

SIS 模型多了一个东西，多了「康复」的状态。一个人感染了，然后康复，康复的人也许会出现新冠肺炎的复发。

SIRS 模型又多了一种状态，就是「免疫」状态。相当于我们有一些人打了疫苗，然后对这个事情开始免疫了。

这三种模型在传播的时候，它其实会出现一些不同。SIR 模型传播的极致情况，就是所有人都会被感染。SIS 模型的传播极致情况，最终是犯病的人长期存在一个稳定的占比。SIRS 模型就是所有人最终都会康复成功。

我们会发现，我们人类和病毒作战的过程，其实就是对信息传播理解越来越深刻的过程。为什么新冠肺炎在今天 21 世纪不像流感那么容易处理？实际上是因为有很多不确定性，比如我们不太清楚现在的疫苗究竟对抵抗力有多少，究竟是一个 SIS 模型还是一个 SIRS 模型，这部分在学术界存在很大争议。同样地，我们也不太清楚新冠肺炎有一些什么样的并发症，还有它的易感染等等状态。所以这部分我们现在是处在跨学科收集各种关键信息的地步，最终我们能够更好地与病毒共处。

我们会发现，病毒的模型实际上也代表了行为和思想的传播。比如一个人的观点，一项信息、模因、概念知识等等都是一样的。这里面大家可以看一个具体的例子，这是来自于推特的一个例子。大家可以看到推特上的传播规律，一个模拟从一个社区跳到另一个社区，特别是用病毒传播模型能够很好地解释这种现象。

我们会发现，病毒传播模型比巴斯模型多了一个很大的优点，它考虑到网络结构的差异。但是信息的传播比这个事情还要复杂。我们人在信息传播的时候，你的观点形成和共识达成更复杂，因为你还会受到朋友的影响。我们发现，病毒传播模型假设人和人之间的影响是类似的，但是其实人和人之间的影响不一定是类似的。这就属于德格鲁特（DeGroot）模型。

德格鲁特模型特别注重社会影响、人和人之间的模仿。他是世界著名的一名统计学家。这里面大家可以看一下，他举了一个经典的例子。他邀请了五个人去估算一头牛的重量。这头牛的重量是 1200 磅。一上来这五个人里面，有两个人低估了牛的重量，他认为是 1000 磅；有两个人高估了，认为是 1400 磅。只有中间的节点估计比较准确。当他们相互交流意见之后，最终交换几轮之后，他们估算出来的结果反而有点接近平均值了。这就是一个经典的德格鲁特模型的例子，就是我们人特别容易受到朋友平均意见的影响。

这个影响不一定是坏事，有时候是好事，但有时候也会给我们带来一些不良影响。比如一个研究发现，朋友会让我们变得更胖一些。大家可以看到这是 2009 年的一个男性和女性的社交网络分析，发现如果你的人际网络圈子中有一个肥胖的人，那么未来两至四年内，你变成胖子的概率就增加了 57%。大家可以看到这个研究。

刚才谈到的德格鲁特模型是一个相对比较简单的模型，我们估算牛的重量只是采取一个平均数。但是在很多时候，我们还没这么简单。我们还存在一个回声影响，比如存在一些偏差。你的观点是通过跟别人交流、别人反驳、补充之后，你又会修正自己的观点。还存在着一个重复计算的偏差。所以这里面是要特别提醒大家的。

通过德格鲁特模型，我们会发现社会网络会影响到人，同样地会影响到网络的结构。当网络的结构发生变化的时候，人的行为又会发生什么改变呢？这就是德格鲁特模型所估算的一个不足。这个时候我们需要考虑到网络中不同力量的博弈方向。

比如我们的行动会依赖身边人采取行动的比例，比如是否买房、是否吸烟、是否学习信息分析 3.0 来开始上课。但是这个时候会存在多个均衡点。比如有人学习信息分析 3.0，然后他得到了比较大的进步，他掌握了信息分析和行为分析这种技术，在他工作上得到应用，他的同事就会更容易跟进。所以这个时候大家会发现，我们存在一个网络博弈的问题。

网络博弈最经典的就是大家都听说过的囚徒困境。比如在奥数培训之前，北京的海淀区还有其他地方很多爸妈进行这个培训，那么他们陷入了一个囚徒困境，最终出现聚散效应。原本一家教育巨头公司刚开始创办的时候，他的初衷只是小学三年级、四年级才开始学奥数。之后有的家长发现，三年级、四年级学奥数是不是太晚了，一年级、二年级学是不是更好？这家教育公司就迎合这种需求。又有家长发现，一年级、二年级学奥数是不是又太晚了？最终慢慢地出现一个很极端的现象，差不多小孩三岁的时候，刚开始学会语言，他们就开始学数学、学奥数了。所以这就是一个很典型的囚徒困境。

通过前面的总结，我们会发现，我们人在信息传播的时候，会出现四类经典模型：

第一类是巴斯模型，简单的扩散，跟创新率和模仿率有关系；

第二类是病毒传播模型，跟一种思想、一种病毒的感染状态和康复状态有关系，他开始考虑到网络结构的影响；

第三种是学习模型，我们考虑到朋友的影响，我们跟胖子在一起更容易成为胖子，我们一群人来做一件事，最终达成的结论更容易成为一种平均值；

第四种情况，我们还需要考虑到网络中的博弈，比如在教育中的奥数现象，它们最终出现了变量和变量之间的一种博弈。

通过这部分介绍，大家会发现，它都跟我们前面第一讲给各位同学介绍的时间空间变量关系的分析框架有关系。我们通过这部分分析发现，在信息传播的时候，我们从变量的角度，对我们之前传统的自变量、因变量这种单纯的线性关系、相互与因果关系，在 21 世纪进行了一个极大的扩充。不再是采取一个简单的线性思维，而是有点像网络科学所说的非线性思维。我们明白了，在世界上不是一个简单的单因对单果的关系，而是多个原因、多个结果交织在一起。

交织在一起的时候，我们再回到前面，采取一个网络视角来抓它的整体特征。看一下它在整个大网络中是什么样的分布，是幂律分布还是正态分布？我们再看一下它的密度、中心性、互惠性，再看一下节点层面，假如我们要计算有趣度，我们重点看一下中介中心性。

这就是第二讲基础知识给各位同学的一些重要启发。第一讲和第二讲是我们整个信息分析 3.0 的基础知识，这样能够让大家在后面更好地理解整个知识点，也能够成为我们几门专业课程，比如学术信息分析、商业信息分析、职业信息分析的一些前置资料。

这就是阳老师给大家的一个简单小结。最后我给大家一句话：信息不仅仅是香农信息，还存在达尔文信息。这是我们今天通过推演告诉大家的。我们不仅可以在商业世界通过信息熵去对已知的概率事件进行计划，我们还存在通过弗里斯顿自由能对未知的世界进行适应。人既会主动适应环境，也会受环境影响传播信息。

这就是第二讲基础知识给各位同学的一个简单介绍。大家有一点感觉了吗？我们下一讲再见。