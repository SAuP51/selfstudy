## 0401. 创作像大师一样写作

第二个活水产品：活水指令（42words.io）。

[42Words: 活水指令，更高效的使用GPT](https://42words.io/)

### 提炼




### 音频整理

大语言模型的指令应用中存在两大核心痛点。在上一节课中，我们已经提及了执行力。首先，不少人不清楚 GPT（大语言模型）拥有如此强大的功能。其次，市面上的指令过多，缺乏一个统一且高效的框架来整合和改善这些指令。

为了解决上述痛点，阳老师及其团队做出了两大重要创新。首先，他们开发了一个新产品。这个产品中特殊的部分是角色、上下文、任务、输出以及重复控制。这实际上是阳老师创立的「行动者框架」或称为「角色框架」。这个框架由五个关键要素构成：

行动者（actor）

上下文（Contex）

任务（Task）

输出（Output）

重复控制（Repetitive Control）

这五个要素构成了一个完整的框架。在书面语境中，我们通常称之为「行动力证」，而在口语中则称之为「决胜」。这个框架可以帮助我们更高效地构建指令。当我们使用这个框架重写某个指令后，GPT 给出的答案会与原来截然不同，且通常更为精确和出乎意料。

阳老师形容这种转变如同从小米步枪升级到核弹。这种巨大的变化是因为阳老师深谙认知科学、语言学、人工智能和自然语言处理等领域的知识。这个框架实际上对 GPT 进行了一种「优化」操作，使得它能够产生更加出色的效果。

在上一节课中，我们提到了执行力、社会意向性、意图的阶级、心理理论和主语对齐等概念。GPT 在工作过程中首先会寻找行动者，找到后才进入下一步的搜索。

为了更好地利用 GPT，我们需要明确指定角色，例如作家、翻译、教师、咨询师或分析师。例如，如果我们希望 GPT 帮助写作，选择「作家」角色会更合适。如果想与 GPT 聊天，选择「咨询师」角色则更为恰当。如果希望 GPT 帮助进行商业战略分析，「分析师」角色最为合适。

需要理解的是，GPT 本身并不具备真正的知识。它只是将人类的知识和背后的符号集合，按照概率进行组合。当我们不明确指定角色时，GPT 的搜索方向可能会变得混乱，导致输出的答案并不是我们所希望的。因此，很多 GPT 的教程，无论是官方还是民间，都建议用户明确指定角色，以提高搜索效率，更快地找到相关的答案。

在上一节课中，我们深入探讨了「上下文」的概念。上下文主要分为两大类：第一类是情景线索，涉及时间、空间、任务、人际关系和情绪等因素，这是我们上次课中主要讨论的内容。第二类是情景特征，即我们对客观环境的主观感受。

阳老师提出的 38 模型是一个情景特征的框架，该模型在人性系统论中有详细的描述。其中在 GPT 中最为突出的三类情景是：工作、两性和社交。这三类情景在 GPT 中的应用十分明显，因为它们可以显著地降低向量空间的搜索成本，更快地找到相关的知识。

例如，如果你想让 GPT 描述某种消极的情境，但给出的是一个积极的信号，那么 GPT 的描述会有明显的差异。当我们明确地指定情境特征，如在消极的情境下或在欣喜若狂的情境下描述某人应该如何行动，GPT 给出的答案会有很大的不同。

尽管时间和空间线索在描述上下文时仍然重要，但实际测试结果显示，GPT4.0 版本对情景特征的区分度更强，甚至超过了时间和空间的区分度。因此，阳老师建议更多地关注情景特征，这样可以得到更为准确的 GPT 输出。

关于任务的解释，任务是指我们希望 GPT 帮助我们完成的具体行动或工作。在课程开始时，我们已经介绍了 GPT 具有四个核心的能力，帮助我们完成各种任务。

GPT 具备 12 种核心的任务能力。为了更具体地描述这些能力，我们将其归纳为四大类，每类包含三种能力，从而形成了 12 种核心能力。这四大类包括：通用兑换能力、通用创造能力、通用推理能力和通用个性能力。通过这四大类，GPT 实际上能够帮助我们完成 16 种不同的任务。例如，本节课将介绍如何利用 GPT 完成与创作相关的任务，而下一节课将介绍如何利用 GPT 完成与推理决策相关的任务。

接下来，我们讨论输出。输出主要包括两个方面：风格和格式。在风格方面，GPT 可以进行两种主要的输出：一种是严谨的、基于事实的输出，另一种是更具创意的输出。许多人不了解 GPT 的这一功能，因此可能会误认为 GPT 是在「胡说八道」。然而，如果用户未指定输出风格，GPT 可能会默认采取一种更加自由、有创意的输出方式。但如果像阳老师这样的专家明确指定了「严谨、尊重事实」的输出参数，GPT 将按此要求提供答案。当然，当我们需要写小说或其他需要创意的内容时，可以调整参数以获得更有创意的输出。

至于格式，我们也有多种选择，并将在今天的课程中详细介绍。这样，无论是在风格还是格式上，我们都可以根据需要调整 GPT 的输出，使其更符合我们的期望。

阳老师在构建指令框架时，除了前四个常见的部分，又创新性地添加了第五个部分，这也是他的独创之处。这部分被称为「重复控制」。

首先，我们有「重复指令」。例如，当我们要求 GPT 完成写作任务时，可以加入指令要求其重复输出一到三次。这样，用户可以从多个版本中选择最满意的，或者结合几个版本来创造新的内容。例如，当要求 GPT 写诗时，通过得到三首诗，用户可以了解 GPT 的模式，并据此进行拼接和改写，从而创作出完全原创的诗歌。然而，这一功能在实际应用中似乎并不为大多数用户所知晓和使用。

其次，我们有「控制指令」。这些指令可以直接告诉 GPT 如何进行输出，例如，「请不要胡说八道」或「请用英文输出」。这种指令可以更直接地控制 GPT 的输出。

基于上述框架，阳老师和团队推出了一款新产品，名为「活水指令」。这个产品是阳老师在上周四晚上 11:30 才构思出来的。随后，他与程序员和内容团队连续工作了几天，尽管产品还有待完善，但已经有了初步的版本。这一版本主要有两个核心工作：首先，整理市面上已有的开源指令；其次，按照阳老师的新框架对这些指令进行改写。

继前述的指令框架工作后，阳老师发现市面上的指令仍存在不足。为了改进这一点，阳老师利用自己的框架生成了更多的指令。虽然目前的产品还是半成品，但已经能让大家感受到其实用价值。在未来，产品将会有更多功能上线。

为了继续改进产品，阳老师计划召集第二批志愿者。与第一批志愿者不同，第二批志愿者的要求更高。他们不仅需要理解阳老师的框架，还要对 GPT 的过往知识体系比较熟悉。阳老师计划招募 30 位这样的志愿者，并由空飞同学负责协调。志愿者报名时需要与空飞进行简单的自我介绍。第一批志愿者招募了 100 人，而第二批只需 30 人。

在志愿者的帮助下，利用 GPT 对生成的指令进行打分，最终希望构建一个包含上万条高质量指令的库。阳老师期待大家能快速完成这一任务。一旦这个指令库完全上线，用户会真正体验到 GPT 的强大功能。

为了更直观地展示这一点，阳老师进行了一次实际操作示范。他使用了「重复三次」这一功能，让 GPT 为他写了三首诗，从而展示了其强大的潜力和实用价值。

少数工作可能不到一小时就完成了。你们试试这种方式，体验一下。你会发现，某些事情人类做不到，但大语言模型（简称 GPT）可以做到。如果觉得结果还可以优化，我们再进行筛选。

现在大家应该已经有所感受。如果我们继续使用这种重复控制指令，你会发现生成的内容质量非常高。

事实上，这样我们真正地发挥了大语言模型的能力，仿佛它从一个初级阶段升级到了更高级的阶段。

大家大致了解后，就知道大语言模型可以帮助我们完成无数任务，极大地提高我们的生产效率。它不仅仅是一个有价值的工具，而且真的非常宝贵。从之前的例子，大家应该已经有了深刻的体会。

这种应用方式是阳老师聪明地想出来的。今天在开始正题之前，似乎还有一些广告要播。广告内容今天比较多，随后我会为大家继续介绍。

上一节课我与大家讨论了管文珍的课本。今天的直播主要是关于课程的预售。我们计划开设三门课程：AI 写作、AI 编程和 AI 绘画。这些课程将在接下来的 3 到 9 个月内逐步开设。考虑到阳老师的重心是深入理解 GPT，我们决定用这种开课方式，带领大家一同深入探索，这是最有效的学习方法。

大约在 5 月底，我们会开设第一门，即 AI 写作课。我们将探讨阳老师的认知写作学方法，并结合 GPT 为大家提供模板，帮助大家解决商务文案和论文写作的问题。

其次是 AI 编程课。这门课主要面向在大型企业工作的工程师。我们会深入探索大型模型，并掌握一些基础的编程概念，如 CLI。一些初学者可能对 CLI 这种基础概念不熟悉，但了解之后，可以使用 GPT 帮助你大量编写脚本，从而提高工作效率。该课程主要使用 Python 语言，因为 GPT 是用 Python 编写的。

第三门课程是 AI 绘画课，主要面向设计团队和有兴趣的同学。AI 在绘画领域取得了很大的进展，阳老师对此有深入的了解。这门课将教大家如何使用开源模型，在单机上获得最佳效果。

这三门课程的目标是让大家在未来 9 个月内全面了解。今年，我们所有的计划都将受到 GPT 的影响。这是一个技术大变革，大家应当高度重视。

阳老师，作为见多识广的专家，20 年前就亲历过互联网的崛起，他非常重视 GPT。只要大家跟随主流，就能保持不落后，并在 GPT 时代享有红利，成为第一批 AI 专家和教练。

希望大家都能理解并跟上这一趋势。

价格其实是主要面向老同学，不建议新同学报名。因为这门课完全是为老同学设计的，没有开放给新同学。如果此时让新同学参与，会浪费我们的时间，因为他们经常提出一些基础问题，这对我们产生了很大的干扰。

目前，我们的 GPT101 课程以及其他 AI 课程都未对外开放。但我们为支付 50 元的新同学开放了其中的部分内容。大家请注意，这些课程的价格未来可能会上涨。

至于两门课程的年报优惠，目前还没有。请大家相信阳老师，跟随他学习的编程与你以前所学的完全不同。阳老师保持着一颗新手的心态，尽管他很擅长编程，但长时间没有接触代码了。即便如此，他和张一鸣都还在学习。大家不要过于自负，现在的技术日新月异，与我们之前了解的完全不同。

关于非法作品，这要看我们使用的开源软件协议。有的开源软件可以商用，有的则不可以。

这门课程是为零基础的人设计的，不论你的背景是编程还是美术。今年我们还会介绍一些关于政治写作的内容。但在这个时代的巨变之前，我们首先要稳住阵脚。

现在的编程与之前有所不同，更像是写作。不论是编程、写作还是绘画，都像是在写提示语。现在的编程更像写作课，不再那么偏重数学。

对于学习所需的电脑，最好是苹果机，尤其是配备 M1 处理器的机型，因为它的 GPU 和 CPU 性能都非常出色。如果是老电脑，那么性能好的任何电脑都可以。我强烈推荐大家购买配备 M1 处理器的苹果新机。这样的机器会使你的学习过程更加流畅。

课程主要解决学生普遍遇到的问题，如使用大型模型进行写作和绘画时遇到的问题。而活水咨询则是解决学生特定的问题。例如，你不知道如何解决某个技术问题，老师和助教都不能帮助你时，活水咨询就非常适合。可以将其理解为专业会员版，为学生提供一些特殊的服务。但由于当前对这些技术的监管加强，很多事情我们只能低调处理，避免过多的曝光。

以下是经过修改的内容：

我了解课程大概在 5 月底开始。考虑到可能有很多人参与，如果出现无法观看的情况怎么办？这肯定有办法解决，大家不用担心。关于「人生山歌」，是否需要等到明年？按照今年的进度，人生的三大课程中的后两部分可能要延至明天。今天我们要面对的是时代的巨变，仿佛是一场大梦，有如狂风掀翻小船。首先，我们要坚守自己，应对这个巨大的变化。明年，我们将更加深入地和大家探讨人生资本论和人生周期论。

今年确实是一个标志性的年份。我了解到，像 CEO 张雄这样的人对于很多没有经历过 20 年前互联网变革的人来说，他们可能感触不深。但对于像阳老师这样经历过互联网变革，且深入了解自然语言处理的人，这次变革的影响是显而易见的。我目前已经掌握了许多信息，我将逐步与大家分享，但目前还不能全部公开。例如，我已经了解了如何训练大型语言模型，但这些信息不能让百度知道，否则会有麻烦。即使百度不知道，我们训练的模型效果也不会太差。

我们现在需要加速这些知识的应用，将其转化为核心竞争力。你会发现，之前强调的四大分析在当前的 2.0 时代已经被日常应用，例如，如何判断 GPT 的真伪，这都是基于数据分析的。

好的，宣传部分结束，我们进入正题。欢迎更多的同学参与。今天我帮助葛巴同学做了很多宣传。现在，我们进入正题，今天的课程依然精彩，主要是关于模型的展开进行介绍。

请大家稍等，我找一下相关资料，与大家分享关于模型的细节。我相信大家听后会有所收获。现在，我要与大家共享屏幕，你们能看到我的课程大纲吗？昨天，阳老师与王小川成为了朋友，他们在微博和微信上都有互动。好的，我们开始今天的课程内容。很抱歉，似乎有些技术问题，稍等我解决一下。

今天我们将如专家般深入探讨语言模型，特别是 GPT-4 的相关内容。但是，我似乎遇到了一些技术问题，鼠标不太好用。请大家稍等，我再次尝试共享屏幕。你们现在可以看到我的文件了吗？

注：原文内容有些部分似乎是与特定背景或上下文相关的，可能需要更多背景信息才能更准确地进行编辑。

阳老师继续讲解，今天我们主要介绍的是第四讲，主题为「像大师一样创造读书破万卷，下笔如有神」。相对于其他大型模型，GPT-4 在文本处理方面有很多优点。与 GPT-3.5 相比，GPT-4 的优势非常明显。其中最突出的优势是响应速度、准确性和连贯性。GPT-4 在这两个方面都远胜于 GPT-3.5。响应速度是指生成文本的速度。当然，GPT-4 还有其他许多优势，但我们这里不再详细展开。

在文本创作能力上，我总结了 GPT 的三个主要优势：

1. 文本分析。

2. 文本内设。

3. 文本生成。

许多人误认为 GPT 最强大的能力是文本生成，但实际上，文本生成有一个重要的缺点，那就是它存在不可控性，不能真正生成用户想要的内容。因此，尽管在使用 GPT 生成文本时，原本可能只需要 30 分钟来完成一篇千字的文章，但由于 GPT 的这种特性，实际上可能需要更长的时间来修正和完善。

相对于自然的写作过程，使用 GPT 进行文本生成并不一定是好事。因为你可能会花费大量的时间进行修改和确认。而 GPT 最被低估的能力其实是前两点：文本分析和文本内设。在文本分析能力上，GPT 的表现极为出色。根据官方数据，其错误率大约在 20%~30% 之间。对于像阳老师这样的专家，他们可以轻松地识别出这 20%-30% 的错误，但对于普通人来说，这是非常困难的。

实际上，当我们让 GPT 进行文本分析时，它几乎总是能给出正确的答案。在这方面，GPT 的表现无与伦比。事实上，在文本分析方面，GPT 的答案几乎总是正确的，其正确率已经超过 90%。所以，这是我们可以放心使用的。

至于文本分析，它是自然语言处理的一个领域，主要包括文本统计、文本摘要、文本分类和文本总结等任务。这类任务的主要特点是分析文本的特征并从中提取相关信息。

我们可以看一下 GPT 在文本分析方面的一些原理。然而，我认为文本统计和文本分类的细节大家可能不感兴趣，所以我们不讨论这部分。

关于文本分析方面的限制，主要包括时间限制、数据限制和歧义限制。对于特定的专业，如医学、法律和高科技领域，GPT 可能无法准确地理解其中的细微差异，尤其是中文方言。但总体来说，GPT 在文本分析方面可以达到 90% 以上的准确度，而在文本分类方面可以达到约 70%-80% 的准确度。尽管 GPT 非常强大，但在日常生活中，很多人更多地将其视为玩具而不是实际的生产力工具。

文本分析中的一项核心功能是文本校对，主要包括改错别字、语法错误、标点符号调整、词汇选择和语句重组。有些功能，如错别字识别和语法错误修正，与之前阳老师开发的软件「血浆」相似。但 GPT 有些独特功能，例如标点符号调整和词语重组与调整，当前市面上的软件基本无法完成。一个具体的应用场景是，当需要按古典风格写作时，将「我们」修改为「你」。现在，只需给 GPT 一系列指令，就可以快速完成这些修改。

与此相比，传统的软件，如「血浆」和阳老师开发的其他软件，无法完成上述功能。这也展示了 GPT 与其他软件在投资和功能上的差异，GPT 的投资达到 10 亿美金，而传统软件的开发成本可能只有 1,000 万人民币。此外，GPT 还可以保持一致的写作风格，这是「血浆」等传统软件无法实现的功能。例如，可以使用 GPT 将文本改写成张爱玲风格或鲁迅风格。

总之，GPT 在文本教育和文本改写方面的功能已经得到了广大用户的认可。

首先，我们探讨了大语言模型（以「GPT」为例，但此处可能为「GPT」之误）在文本分析方面的应用。我将不深入探讨文本统计和文本分类的共享原理，因为我认为大家可能对这部分不感兴趣。

在文本分析方面，大语言模型存在一些限制。最主要的限制在于文本统计部分，这是受到时间、数据和歧义的影响。文本摘要也有相似的问题。文本分类方面，模型在某些特定的专业领域，如医学、法律和高科技领域，可能无法准确理解其中的细微差异。特别是对中文的方言，模型存在理解的难度。

尽管存在这些限制，大语言模型在文本分析方面仍具有很高的准确度，可以达到 90% 以上。在文本类似的分析中，准确度可以达到 70-80%。但实际上，在日常生活中，许多人将其视为玩具，而不是真正的生产力工具。

文本类似的主要应用包括文本校对，如修正错别字、语法错误、标点符号调整、词汇选择和语句重组等。

市面上的一些软件，如「血浆」（可能是某种软件的名称或误译），也具备错别字和语法错误的修正功能。但大语言模型具备的核心功能，如标点符号调整、词汇选择优化和词语重组与调整，是其他软件所不具备的。尤其是词语的重组与调整功能，它可以实现主语或人称的调整。

举个例子，当你想要调整文章的写作风格，如将「我们」改为「你」，或者排除某些特定的句子不进行修改，只需给模型下达相应的指令，模型就可以快速完成这些任务。

很显然，这种高级的文本处理技巧是传统软件如「血浆」或其他软件所不能比拟的。大语言模型在这方面的强大功能，展现了其高昂的研发成本与其他软件的巨大差距。

此外，大语言模型还具备文本风格的改写功能，可以将某一风格的文本改写为另一种风格，如张爱玲或鲁迅的写作风格。这是过去尝试多次但从未达到满意效果的功能，而现在通过大语言模型完全可以实现。

总之，大语言模型在文本处理、文本改写和文本教育方面都展现了其强大的功能和潜力。

在口语转书面语的应用中，我曾让自信哥为大家展示过一个实际例子。此外，文本简化也是我经常使用的一个功能。但在使用大语言模型（如 GPT，可能指 GPT）生成文本时，我们必须注意知识产权的问题。当 GPT 为你生成了一大段文本时，有可能会触及他人的知识产权。为此，我通常采取的策略是：首先，我会给模型展示一个我的写作风格示范，让它学习「杨志平」老师的写作风格。当它学习完毕后，我会进一步指示它将生成的文本改写成简洁版本，并要求其尽可能保持「杨德平」老师的风格。

通常情况下，模型最初可能会生成长达 1000 字的文本，但经过简化后，我们可能只会使用其中的 100 到 200 字。这样，通常可以避免知识产权的问题。

与此同时，大语言模型具有一些传统写作软件所不具备的能力。例如，我曾在「写匠」软件中教导大家如何使用它的功能。这个过程包括：首先上传文章，然后使用软件的文本统计功能来标记复杂或较长的句子，接着手动逐句修改。这个步骤相当复杂，对于新手来说并不友好。但对于 GPT 来说，我们只需下达简单的指令，比如要求每句话的字数不超过 25 字，它就可以迅速地将文本转化为简单句。

此外，文本优化和文本扩写是两个相似的功能。前者强调保持文本的一致性，而后者更侧重于文本内容的扩展。这两个功能与我之前在课程中讲述的快速写作和慢速修改的理念是一致的。

关于文本的扩写部分，我们会在后续进行深入探讨。在此，一个常见的误区是过于简单地给大语言模型，如 GPT，下达指令，例如要求其帮忙写一篇文章。但我们必须明白，模型的逻辑与传统的写作课程是相似的，即先进行快速写作，再进行慢速修改，逐步扩写并拼接各部分。事实上，GPT 在处理每一段文本时，最为得心应手的字数限制是 300 字。这与我们在「快写慢改」课程中提到的一张卡片的容量是如出一辙。

你可能会发现，无论是我们的课程还是使用 GPT，其核心技术和逻辑都是相似的，只不过 GPT 利用了高科技来大幅节省我们的时间和精力。例如，一篇 1000 字的文章可能由 3 到 4 张卡片构成，而一篇 3000 字的文章可能需要 10 张卡片。如果你不确定应该写什么内容，可以让 JPG 为你生成一个大纲，然后根据这个大纲进行逐步的写作和优化。

对于初学者，简单地让 GPT 写一篇文章可能会得到一个很基础的结果。我会在后面为大家展示一些实际的例子。

此外，关于「微笑的原理」和「微笑的性质」，这两部分我们暂时跳过，因为它们目前不是重点。

接下来，我要展示一个实际的例子，这是 GPT 为我写的一篇文章。虽然文章已经过错误检查，但仍然可能存在一些问题。这篇文章实际上是一首诗，但你可能觉得它的情感深度不够。

在写作的例子中，除了文学创作和营销文案，还有一些是编程相关的。其中，有些例子可能并不十分出色，但后面我会为大家展示一些更为成功的例子。

最后，值得一提的是，许多人可能忽略了 GPT 在音乐创作方面的能力。它在作曲方面表现出色。对于那些不懂音乐的人，他们可能不会理解其生成的音乐到底好不好听。但我们可以尝试将其转换为 MIDI 文件，让懂音乐的同学来评价。

我们后续将继续深入探讨。由于我当前的身体状况不佳，需要预留一些时间进行休息。文本创作部分我们简要概述，然后进入如何有效地创造高质量文本的框架，这部分我之前已经向大家介绍过。为了更具体地理解，我为大家展示了阳老师制定的一个示范指令。

在此，我要强调几个重要的原则。首先，对于 GPT 来说，其内置的文本分析功能和统计功能是非常精确的。我们应该充分利用其高准确度的特点，这样可以减少不必要的验证和修改次数。

以阳老师的实例为例：「请将杨志平老师的写作风格总结出来。」在这里，我们可以利用模型的统计功能，例如询问阳老师、纳博科夫或鲁迅常用的词汇是什么。目前，GPT 能够从多个角度为我们提供上百项的统计数据，这比早期的血浆模型要强大得多。

其次，我建议大家使用重复指令来一次性生成多个版本的内容，这也是一个关键的注意点。

第三，我们应该为模型提供充足的背景数据和事实性信息。例如，当我请求 GPT 为我编写一篇文章时，我会提供详细的大纲和要求，如「请帮助我撰写这本书的图书简介」。此外，我还会明确地告诉 GPT，例如在致谢部分要感谢四类人，包括 OpenAI 团队、开源社群、教研志愿者以及其他特定的人员，并列出他们的具体名称。

我们应当特别感谢第四类人，这群人对阳老师的支持尤为重要。他们是第一批为阳老师付费的 1000 名同学。GPT 为我生成的致谢内容十分专业，以至于当我提交给出版社时，他们完全没意识到这是 GPT 生成的。我在与他们上午聊天后，当天下午便将大纲提交给了他们。

关于音乐的部分，董月同学提出和弦可能有些问题，我们可以再进行测试。我们必须明确，GPT 不仅仅是一个信息查询工具，它更像一个推理引擎。它拥有大量的符号以及这些符号之间的组合关系。GPT 能够帮助我们生成所需的特定符号组合。例如，它可能不知道谁帮助你写书，但如果你提供具体的人名，它能够恰当地将其融入文本。

这引出了第三个注意事项：当我们为 GPT 提供足够的背景信息和事实数据时，它能够更准确地为我们生成内容。

接下来，第四个注意事项与生成风格有关。我在此为大家展示了参数设置，特别是严谨和创意参数的设定。

关于参数的具体设置，它通常在 GPT 中被称为「30」，有时也被翻译为「温度」或者「随机性」。这个参数决定了生成内容的多样性。

我通常建议使用英文进行参数设置，因为在中文环境中，设置严谨与创意的效果可能不尽如人意。你可以直接为 GPT 设置一个英文参数，如 "t1m"，这样 GPT 能够识别。这个参数实际上决定了 GPT 生成内容的风格，是更偏向事实还是更具创意。

例如，如果你是一名律师，你当然希望生成的内容更为严格和严谨。反之，如果你从事文学创作，可能希望生成的内容更具有创意和新颖性。除了这种「严谨与创意」的风格设定，GPT 还支持其他风格，如古典风格、平实风格、城市风格、实用风格、浪漫风格、演讲风格和乡村风格等。

但需要注意的是，GPT 并不直接知道这些风格具体是什么。比如，它不知道什么是古典风格或浪漫风格。因此，我们需要为其提供一些具有代表性的示范文本，让它了解这些风格是如何写的。一旦 GPT 能够识别并区分这些风格，我们可以结合其文本统计功能，让它学习并记住古典风格的特征，然后为我们提供与古典风格相符的内容，并给出与古典风格的匹配度评分。

大家都知道，在写作课程中，阳老师常强调，获得大师级的指导是非常困难的，而他推荐的方法是进行翻译练习，例如与张爱玲和余光中共同翻译《老人与海》。

然而，自 2023 年 3 月 15 日起，你拥有了一个价值 10 亿美金的写作导师，那就是大语言模型。你可以选择任何你想学习的写作风格，例如阳老师的。将你认为最代表阳老师风格的 10 万字文本输入模型，让它为你总结出阳老师的写作风格。随后，你可以将自己的文字输入，询问自己的写作与阳老师的差异，并寻求改进建议。

这个强大的工具就如同一个 24 小时在线的 10 亿美金级写作老师。同样地，你可以让它为你总结张爱玲、纳博科夫、王小波、鲁迅等人的写作风格。但需要注意，如果不给它足够具体和代表性的文本，它可能只会提供一些基于维基百科的浅显总结。

我们应该为它提供真实且典型的文本，让它基于这些文本为我们总结写作风格。一旦它总结出风格，我们还可以指定某些输出风格，使其效果更为理想。实际上，这种方法可以应用于所有的写作任务。我们可以为每种文本建立一个模型，用示范文本训练它，然后进行评估和改写。这就是 AI 写作课的核心内容。

文本格式有多种，如麦克风录音、txt 文件、剧本、曲谱、表格等，还包括各种代码格式，这些都是大家很容易理解的。

接下来，我们讨论参数的设置。正如大家在之前的示例中看到的，我们可以围绕 "act" 模型来制定创造指令。其中，「act」模型包括四个方面：角色、情景、任务和输出。例如，「你是一位作家」、「你是一位政治科学家」。这样的指令方式，实际上已经成为了大家熟悉并频繁使用的一种模式。那些真正理解大语言模型的人会自然而然地使用这种方式，而不熟悉的人则可能感到困惑。

「act」模型中的「情景」部分，描述了你所处的具体环境或背景。例如：「你正在和恋人共度一个浪漫的夜晚」、「你正在参加小说比赛」或「你正在商务沟通会议上」。这样的上下文描述，帮助确立了整个模型的背景。

第三部分是任务描述。在描述任务时，要确保明确提及关键词，这样可以得到最准确的结果。例如，当请求进行文本统计时，应明确指出统计的具体指标，如「字、词、句法、情绪」。正确使用关键词可以帮助获取令人惊艳的结果。为了简化此过程，我们的团队正在整理与梁老师提炼的五个核心能力相关的关键词，总结为十五大类任务。这样，大家未来只需复制粘贴即可，无需再自己思考。

例如，「法律文件」和「项目计划书」这类关键词，有些同学可能想不到。在我们的工具中，你只需进行搜索，找到相应的关键词并复制粘贴即可。

接下来是输出与重复控制部分。你可以要求输出更有创意或更严谨。输出还可以根据不同格式进行，如「麦克风格式」或「表格」。

在文本分析部分，我们强调文本统计和摘要。尤其是对书籍的摘要，效果是最理想的。从 1.0 时代开始，对书籍的摘要准确度就达到了 80% 至 90%。但对于某些特别专业的文章，摘要的准确度可能会稍低。

第三部分是清单。你可以指定输出格式，如「APA 格式」或「表格」。

第四部分是套用模板。你可以为模板设定特定的约束，如「1234」。模板可以帮助你获得更多高质量的文本。例如，阳老师在写书时使用了模板功能，要求找出书中的错误人名。考虑到书中提到了超过 1000 个外国人名，这一功能大大简化了校对过程。另外，还有其他功能如格式转换、文风模仿等，都为写作提供了很大的便利。

大家都知道这是关于文本生成的，可以按作者或类型进行分类。这里，我要提醒大家，GPT 对国外著名作家的识别相对更准确。

例如，它对张爱玲、鲁迅和北岛的风格识别准确度大约在 40%~60% 之间，而对海明威的风格识别准确度接近 80%~90%。因此，如果你希望改写自己的文风以获得更好的效果，我强烈推荐你选择国外著名的作家。

接下来，我会列出国外十位最知名的作家和诗人。请在下周购买这 20 本新书，我们已经为大家总结了他们的理论。在 GPT 时代，如何更高效地利用这些知名作家的知识和经验，例如海明威，是个关键。当你让 GPT 以海明威的风格改写文本时，输出的效果通常非常出色。然而，对于像张二林这样的作家，由于其在语料库中的数据较少，GPT 可能不太熟悉其风格。

实际上，由于许多作家模仿海明威，他在整个语料库中的比例相对较大。因此，我想提醒大家，选择国外的著名作家作为参考，其效果可能会比国内的著名作家好得多。

对于某些平台，你可能需要为 GPT 提供一些示例，尤其是对于语料较少的平台，如小红书。大家应该已经明白了这点。关于关键词扩写和头脑风暴创意模式，这是一种高级的玩法。比如，融合张爱玲和李清照的风格，创作一首描述离别情感的词。不过，当我尝试分享时，似乎出现了错误。我会查看这个错误，并在修复后分享给大家。希望大家喜欢！

大家可以看到，我已经分享出去了这份内容。我们的分享平台也支持一些被称为「黑科技」的内部技术。但我建议大家在使用这些黑科技时保持低调，因为当前这些技术仍然只限少数人使用。

接下来，我想再继续深入讲解这个模板。有一种模式可能有些人不太了解，尤其是当你引用国外的两位大作家，例如海明威和另一个名为「1b 怀恨」的作家。如果你用英文来写，你会发现生成的效果非常出色。这种高质量的文字，坦白说，是一般人难以书写出来的。这样生成的文字不仅非常漂亮，而且知识产权完全属于你。

为了总结，每个人的大脑实际上也可以被看作是一台强大的 GPT，只是我们难以用语言来描述它。但在某种框架下，例如 Iq 框架，我们人类大脑的潜力可以被极大地激发。

接下来，我想与大家探讨一个新的问题：知识产权如何界定？当前，这个问题已经为业界带来了一些新的挑战。我为大家提供了一个操作性建议：不要直接使用 GPT 第一次生成的内容。建议在 GPT 第一次生成的基础上进行第二次、第三次的改写。当使用 GPT 生成的文本时，我们应当以文学性质的文字为主，并确保在整体内容中，GPT 生成的部分不超过 1/5。例如，如果 GPT 为我们生成了 1000 字的解释某概念的文本，我们最好只使用其中的 200 字。如果大家遵循这些规则，那么知识产权的问题就可以得到妥善的避免。

人们往往受到路径依赖和首发效应的影响。例如，20 年前有一家二手车创业公司，在当时的标准看来，它的技术和管理水平并不算高。但由于它是国内首家从事此业务的公司，即使依靠那时的初级编程技术，也积累了巨大的资本。在创始人 28 岁前，他已经赚取了足够的财富，使他一生都用之不尽。

很多人可能不了解阳老师年轻时的经历，他们只看到了阳老师文艺的一面，或那种出世的态度。但他们不知道阳老师在 28 岁之前已经取得了巨大的成功。这是很多人对阳老师的一个误解。

近期，我感觉仿佛回到了 20 年前。似乎新的时代已经到来，所有的产品都需要重新设计和制造。因此，我特别希望有编程能力的同学能够加入我们。虽然一开始我们可能无法提供全职的工作机会，但我希望有志之士能以志愿者的身份参与。我们特别需要产品经理和编程能力强的程序员。我们的团队成员大多都有在大公司工作多年的经验，他们对工作流程非常了解，这使得工作更加高效。

那些工作经验丰富的人们，他们能够迅速地讨论需求和解决问题。而对于那些经验不足的新手，我们现在可能没有太多时间进行手把手的教导。所以，我诚邀那些有时间、有能力的同学参与到我们的项目开发中来。未来，我们计划推出七个关键项目，并争取运行一个大型的模型。我相信，一旦我们的项目成功运行，大家的学习体验将会完全不同。无论你想学编程还是写作，你只需咨询一个 24 小时在线的大模型即可。

在未来的人生发展咨询中，我们将看到与以往完全不同的体现。我曾认为，在大模型时代，最不容易被替代的职业是心理咨询师。但当我看到 GPT 与一位学生的实际对话记录，我意识到心理咨询师实际上可能很容易被替代。在中国，由于心理咨询师的费用较高，并且受到交通的影响，他们不能 24 小时陪伴患者。此外，许多初级咨询师的专业水平并不高。但人生发展咨询师，他们更多地是为你设计人生，这种角色很难被 GPT 所替代。

目前，我们正在进行大量的项目，并诚邀更多的同学加入。在项目初期，你可以作为志愿者或兼职者参与。对于那些表现出色的同学，随着项目的快速发展，未来我们将优先为他们提供全职的工作机会。

关于 GPT，当它被指定为某个作家的风格并进行多次训练时，生成的作品不会超过该作家本身的水平。为了说明这一点，我建议大家参考某节课中的「之星的诗云」。无论 GPT 如何训练，其水平短期内很难超过真正的作家。但真正的作家使用 GPT 时，他们可以更高效地生产作品。

在使用 PPT 辅助写论文时，由于引言和讨论部分的不确定性较大，并且有大量的文献需要参考，我们必须明晰如何利用 tbt 的价值。下周，我将与一个「活水咨询」的客户讨论这个问题。除了一些技巧外，未来还有许多开源软件可以帮助我们。但详细地讨论这个问题可能需要至少 30 分钟。因此，我想先提醒那些从事科研和写论文的同学：在撰写引言时，不要直接使用 GPT 为你生成的内容。最好的方法是先为其提供 10 篇相关的论文，并从中提取摘要。

首先，当你需要引用某一段落时，你应该先摘取相关的内容。接下来的步骤是将这些摘要合并成一个简短的段落。在合并之前，可以参考一些其他优秀的、格式相似的文本，以确保合并的摘要既简洁又不失细节。

完成上述指导后，你会发现文本的写作质量已经大大提高。当然，除了上述建议，还有许多其他的写作技巧。我称之为 "独占技巧"，我相信在网络上只有我知道如何使用这种方法，而其他人可能还没有意识到它的价值。这种技巧能极大地提升文本的价值。

转向下一个问题，当与他人进行交流时，每个人都有自己的交流规则和风格。这对于现有的 AI 技术来说是一个挑战，因为 AI 在多轮对话方面的能力仍然有限，它没有像人类那样的长期记忆功能。目前，GPT 这类大模型没有长期记忆功能，只能进行模糊记忆。但考虑到 AI 技术的快速进步，这个问题在未来应该可以得到解决。

阳老师的团队正在测试一些解决方案，我预计在接下来的两个月内，这些方案将完全实现。一旦测试成功，他们可能首先与活水咨询的用户分享，然后继续进行测试。如果一切顺利，三到四个月后，这些方案可能会被开发成产品并分享给更大的社群。技术上，这是一个容易解决的问题，但它不是当前大模型需要优先解决的问题。

对于科普类文章，建议遵循一些基本原则。首先，不要直接使用 AI 第一次生成的文本，而应该使用其第二次或第三次生成的文本。此外，让 AI 生成尽可能多的内容，然后将这些内容合并。这样做可以避免知识产权的问题。但在使用这些文本之前，还需要确保它们不是直接抄袭自其他来源，并正确引用了原作者。

当使用大型模型如 GPT 进行训练时，由于训练语料丰富，可能存在版权风险。因此，在使用生成的文本前，需要进行抄袭检查。确认没有抄袭并且已经正确引用了原作者后，才可以放心使用。

最后，随着人类进入 AI 时代，我们过去的许多法律，尤其是与知识产权相关的法律，都面临着巨大的挑战。

按照阳老师的原则进行操作，你所面临的知识产权风险是最低的。目前，体力劳动者还未受到显著影响，而知识工作者和脑力劳动者受到的冲击最大。不过，体力劳动者很快也会受到冲击，特别是与机器人和机械臂结合的领域。但体力劳动的工作相对复杂，与符号语言书面语言相比，GPT 在这方面已经取得了突破，但机械臂的突破可能会相对慢一些。

劳动者现在并不需要太担心知识产权问题。例如，如果你自己写了一个初稿，然后让 GPT 对其进行改写，这不会存在知识产权风险。但过度依赖 GPT 可能会导致心理上的空虚感。

在 GPT 的时代，像姚 20 这样的博学之人和深谙 GPT 的专家，他们的优势会被进一步放大，增加约 30%。这对于那些居于知识生产中间层次的人是不利的。底层的知识生产者有可能通过利用强大的工具如 GPT，来挑战并取代中层知识生产者的位置。他们可能会更高效、价格更低，因此，中层知识生产者应该有所警觉，特别是在技术初期。

对于那些工作完全在电脑上进行的人，比如作家和文字翻译，他们面临的 GPT 冲击是最大的。这类工作模式指的是：在电脑上接受任务、在电脑上完成任务，并通过电脑提交成果。在这种工作流中，有很多环节可以被 GPT 取代。例如，一个在北京月薪 2 万的员工，可能会被一个在三四线城市月薪 3000 的员工所取代，只要后者利用了 GPT，他们生产出的作品质量可能会相当。

阳老师一直强调我们要迅速适应 GPT 时代，并不是因为他想制造焦虑。大家都知道，阳老师的风格从不制造焦虑。我们已经跟随他七八年，始终未感受到焦虑。但这次他特别重视是因为 GPT 确实将对许多人产生巨大的冲击。我们现在看似已经享受到了这技术的初步红利。因此，作为团队的领导者，阳老师希望我们能尽快前进。如果我们自己不给予足够的重视，未来可能会被时代淘汰。二十年后，不要因为当初没有被及时提醒而后悔。

大家应该深入掌握工具的细节，这样，你就不会被来自三四线城市的人取而代之。关于 GPT，它无法处理超过 3 亿的大量信息，那么如何提供足够多的信息让 GPT 进行总结呢？虽然 GPT 的多轮对话能力有限，但是我们可以通过更复杂的技术方法来解决这个问题。目前，团队正在测试这些技术方法。其中一种方法被称为 "胜任化"，例如有一个团队将 Java 的所有文本转化为上述格式，测试效果还算不错。

但这种技术相对复杂，有些细节现在不能公开讨论，因为它涉及某些法律的灰色地带。我们计划首先在活水咨询的内部对其进行测试。如果测试效果良好，并且能合法绕过相关法律障碍，未来可能会有一些产品公开提供，例如，用户可以将自己的聊天记录输入，从而形成一个个性化的 AI 助手。

有一个在互联网上的报道提到，有人将自己的几十万条聊天记录和博客文章输入讯飞 AI，再灌输给 GPT。这篇报道非常有意思，希望有同学能将这篇报道转发到「完全 GPT 知识星球」。

我要探讨 GPT 是否特定于某些人格特征。实际上，GPT 与个人的人格特征无关，它只是一个高效的工具。对于初学者来说，学习 AI 编程后，是否更容易进入这个领域呢？这很难确定。有人说，杨先生更倾向于创业，他的风格更像是建立同盟关系。

现在，他招聘全职员工的次数逐渐减少，因为 7 年前他一次性招聘了过多的全职员工，达到了一两百人。但实际上，拥有几十人的团队和一两百人的团队在生产力上可能是相似的。他从这次经验中吸取了教训，这次他更注重招聘高水平的员工，而且他更喜欢与那些有主见、竞争力强的同学合作，显然，这些同学也会想方设法与他一同创业和赚钱。

不久前，我们发起了一个挑战赛，目标是在 1018 个月内通过 GPT 赚取第一个 100 万。而阳老师，作为一个创业高手，仅用 42 天就完成了这个目标，这当然也得益于大家的支持。对于他来说，现在挣钱已经没有什么成就感了。但我认为，未来的成就感可能来自于在 42 个月内帮助 42 位伙伴赚取他们人生的第一桶金，无论这桶金是 30 万、100 万还是 300 万。

对我来说，这才稍有成就感。如果有人挣不到第一桶金，那他至少应该挣到第一桶酱油。即使挣不到 30 万，至少应该有人生的第一个 3 万或 10 万。关于如何使用 GPT 处理大量文本，我之前提到的向量化技术在未来的 GPT-4 中可能会有所提高。对于获取 GPT 的 API 的窍门，我不能公开说，因为一旦公开，这个窍门就失效了。

如果有同学想知道，可以私下联系我。记得，你有我的微信。使用 GPT 写论文时，我们的方法是将 GPT 视为一个卡片式的软件工具。在写论文时，我们的目标不应该是一开始就写一篇完美的论文，而是如何写出一篇高质量的卡片。对于这种方法，我们有非常详细的教程，你们一周内就可以掌握。

当我们将阳老师的教学内容与 GPT 结合，我们会发现其潜力惊人，可以极大地提高我们的效率。如何使用 GPT 来帮助孩子提高写作水平呢？这确实是一个挑战，因为许多家长可能没有足够的耐心去批改孩子的作文。在这种情况下，GPT 可以发挥巨大的作用。首先，我们可以使用 OCI 技术将孩子的作文上传给 GPT 进行批改。接下来，GPT 不仅可以找出作文中的不足之处，还可以为孩子提供一个总结，列出作文的三大优点和不足。你可以将 GPT 的建议打印出来，并用笔进行注解。

此外，孩子们的创造力是无穷的，远超我们的想象。随着技术的进步，如机械臂等新发明，一些传统工作，如中餐制作，变得更为简单。例如，炒菜机器人目前已经迭代到第二代。我预测，当它迭代到第五代时，它可能会达到普及的水平。因此，从事烹饪行业的人应该时刻关注技术的发展。然而，健身行业可能会受到的影响较小。

成为我们团队中的 42 个小伙伴是基于缘分的。有些同学自然而然地展现出了他们的潜力和才华，这也是我们选择他们的原因。

此外，需要指出的是，阳老师提到的内容并不都是事实，有些可能只是虚构。随着 2.0 时代接近尾声，我们需要回顾过去，总结哪些同学在这个时代中发展得最好。实际上，回顾 1.0 时代，我们已经帮助了成千上万的同学成功地实现了职业生涯的跃迁。

许多同学成功地进入了大公司，成为了算法工程师，迈进了竞争激烈的人工智能行业。在 1.0 时代的开始，他们完成了许多杰出的工作。然而，这个时代所完成的工作对公司的整体价值和生态价值贡献有限。因此，进入 2.0 时代，我们更加注重对开发生态的整体提升。在 1.0 时代，由于个人的能力、人脉和信誉都较为有限，我们采取了逐步发展的策略。到了 2.0 时代，我们团队的口碑已经建立，大家对我们的工作持有较高的信任，因此得到了越来越多的同学的支持。

当然，不可盲目地依赖 GPT。虽然 GPT 目前还没有开放各种插件，但在未来，我们会深入讨论如何使用一些巧妙的插件来解决问题。当前，GPT 还处于较为初级的阶段，许多所谓的 GPT 专家其实对其了解并不深入。

我们团队现在也在不断摸索中。为了给大家提供更好的服务，我们提供了一系列产品，价格非常亲民。我们团队的目标是，通过集体的力量，在阳老师这样的专家的引导下，汇聚更多的资源，成为真正懂 GPT 的团队，确保在 AI 时代始终保持领先地位，不被淘汰。

阳老师此次的决策也是为了加速这个进程。感谢大家今天的参与，希望大家能够好好使用我们的产品。此外，我们欢迎大家报名成为志愿者，未来志愿者肯定会有特别的福利。除了可以得到阳老师亲笔签名的 GPT 产品，表现优秀的同学还会有额外的福利。虽然现在我们还不确定具体的福利是什么，但保证会有。

我们非常珍视志愿者的付出，希望大家可以帮助我们快速地收集更多优质的数据。这对于我们训练更高版本的大模型非常重要。尤其是真实的语料，它比 API 生成的语料更为真实和多样。因此，我们需要 100 位同学来帮助我们，以确保训练模型的语料真实且多样。