## CH0701信息获取

### 课件汇总

P01 —— CH7 学习目标

第七讲开始，我们正式进入课程下半场，沿着信息分析流程 — 信息获取、信息整理、信息加工与信息报告一展开学习。

来到信息分析第七讲，我们将学习到：

1、21 世纪的信息获取。

2、信息获取的关键操作。

3、信息获取的三大妙招。

本讲知识实用性很强，建议你不断练习，有意识积累专属你的信息源清单。

本节视频说明

信息分析流程有四个环节：信息获取、信息整理、信息加工、信息报告，而信息获取处在第一个就是关键的位置。

你是否好奇：

1、21 世纪的信息获取有什么特点？

2、信息获取的关键操作有什么技巧？

3、信息获取的三大妙招是什么？

本讲视频将逐一为你解答。

P02 —— 信息获取的重要概念：信息源

信息获取，也称为信息搜集，情报收集，是信息分析流程中的第一个关键环节。

「从哪获取信息」是信息获取的关键问题，对应的概念是：信息源。

按照不同的分类，信息源可分成：

按照来源分：一手信息源；二手信息源。

按照可靠性分：可靠信息源；不可靠信息源。

按照是否公开分：开源信息源；私密信息源。

P03 —— 开源信息源

开源信息源，又叫开放信息源。「开放」一词指公开可用的信息来源，而非秘密信息或秘密来源。

伴随开源运动，情报界兴起开源信息的趋势，诞生大量开源信息列表。比如，OSINT（Open-source intelligence），即开放来源情报或开源信息，指任何和所有可以从公开收集中获得的信息。

课程推荐 OSINT 列表：

Awesome OSINT list 网址

[jivoi/awesome-osint：：scream：A curated list of amazingly awesome OSINT](https：//github.com/jivoi/awesome-osint)

开智信息分析工具箱

OSINT

开智信息分析工具箱 1.0 版

P04 —— 信息获取的重要概念：信息类型

信息类型可分成两类：文献信息源与非文献信息源。

P05—— 信息获取的关键操作

课程总结了总结了 4 个关键操作。在 21 世纪，信息获取基本上会与这四大基本操作中的 1-3 个操作紧密相关。

信息获取的关键操作（一)：从一个信息源快速开始

01 利用元信息源与开源信息源

元信息源，即信息源的信息源。

在信息获取时不妨沿着这两个问题去思考：A 的 A 是什么？A 会集中聚集在哪里？

例如：

02 利用搜索引擎

三大通用搜索引擎：谷歌（https：//www.google.com/)、必应（https：//www.bing.com/）与百度（https：//www.baidu.com/).

常用学术搜索引擎（英文)：谷歌学术（https：//scholar.google.com/)、语义网络（https：//www.semanticscholar.org/).

常用中文搜索引擎（中文)：百度学术（https：//xueshu.baidu.com/）

03 利用专业数据库

常用学术数据库（英文)：wos 数据库、OpenDOAR 与 WorldCat。

专业领域有自己的数据库：PsycINFO（心理学文献数据库）、CogNet（认知科学网络数据库）。

常用学术数据库（中文）：中国国家图书馆、知网（CNKI）与万方数据。

常用商业数据库（英文)：彭博终端（Bloomberg Terminal），crunchbase（世界上最大的创投数据库）。

常用商业数据库（中文)：wind、IT 桔子。

常用职业数据库（英文)：O*NET（https：//www.onetonline.org/）。

04 访谈或调查

当市面上已有的信息都满足不了需求了，怎么办？这个时候我们就需要去自己来动手，做访谈或者调查。

以做空瑞幸咖啡为例。

信息获取的关键操作（二)：快速验证内容是否符合需求。

信息量过大，如何快速验证内容是否符合需求？

Ctrl+F 或 Ctrl+space

信息获取的关键操作（三)：调整信息源

当前信息源满足不了需求，怎么办？这时候，我们就需要调整更多、更好信息源。

找到更「多」信息源：关联推荐

关联推荐，指利用人工智能与大数据，获得更多与目标信息相关或类似的信息源。

常用技巧：

浏览器插件，例如 SimilarWeb。

AI 推荐

搜索指数，例如百度指数

找到更「好」的信息源：换一种信息源。比如，当搜索引擎得出的信息效果不好时，换用专业数据库。

信息获取的关键操作（四)：保存到本地

保存到本地有两个方向，1）批量下载；2）智能获取。

批量下载

批量下载指利用浏览器插件、软件，将数字化资源（如元数据、报告、文献和视频）批量保存在本地文件，用于下一步信息分析处理。

常用技巧：

利用 Zotero 批量下载元数据

利用插件「DownThemAll!」批量下载文件

智能获取

没有现成的文件可以下载，怎么办？这时候你需要借助爬虫技术或 PRA 技术。

P06 —— 信息获取的三个妙招

P07 —— CH7 小结

信息获取是信息加工的第一步，它的质量决定了之后信息整理、信息加工与信息报告的质量。

信息获取有四个关键操作，分别是：

1、信息获取的关键操作（一）：从一个信息源快速开始。

2、信息获取的关键操作（二)：快速验证内容是否符合需求。

3、信息获取的关键操作（三）：调整信息源。

4、信息获取的关键操作（四)：保存到本地。

这四个关键操作是本讲的重点。

### CH0701二十一世纪的信息获取

策略的部分今天我们介绍的是第六讲信息获取。在前面我们介绍了信息分析的流程：信息获取、信息整理、信息加工、信息报告。大家可以发现，信息获取处在第一个位置，也是最关键的一个位置。这就是这一节课我们要分享的内容。

第一节课我们先来学习一下 21 世纪的信息获取。在信息时代，今天人人更容易成为「韭菜」。在群聊的时候，你是否经常会看到一些这样的信息，比如说「卷发什么油膏某某专家宣称有效」，等等。特别是一些老人看到这些信息会信以为真。谨慎的人可能会警惕这一类天方夜谭的事，但往往大多数「韭菜」没有对信息的来源加以验证。在整个信息时代，我们这些信息实际上是从信息获取一开始就错了。

信息获取相当于是信息分析流程的开始，如果一上来就错了，那就相当于是无源之水、无本之木。信息获取是一切的源头，这就是信息获取为什么重要的原因。小到买东西，大到人生关键决策，比如上大学、找工作、买房子，这些关键环节都离不开信息获取。充分的信息获取能够减少决策的不确定性。

那么什么是信息获取呢？也称之为信息收集、情报收集，它是信息分析流程中的第一个关键环节。信息获取实际上涉及到两个重要的概念：第一个重要的概念是信息源，从哪里获取信息；第二个重要的概念是我们获取什么样的信息，也就是信息类型。

我们先来看看信息源在情报学中的定义。什么是信息源？它指的是人们在科研活动、生产经营和其他活动中所产生的各种信息来源，以及由此而形成的原始信息集合，比如科研活动中反映原创成果的原始记录、数据和资料等。同样地，计算机科学也有一个关于信息源的定义，它指的是信息的来源，也就是系统所处理信息的原始出处。这就是信息源。

信息源我们可以按照来源分成一手的信息源和二手的信息源。绝大多数时候，一手的信息源比二手的信息源更有价值。我们也可以按照可靠性分为靠谱的信息源和不靠谱的信息源。绝大多数时候你会发现，权威的机构，比如国家政府机关，以及一些权威的科研机构，他们发布的信息往往是可靠的。相反一些小道八卦的信息，他们发布的往往是不可靠的。再次按照是否公开分，我们可以分成公开信息源，也就是 Open Source，以及私密信息源。

我们看一下什么是 Open Source 信息源。在整个情报科学界有一个专业的词汇 OSINT，它用来指代 Open Source Intelligence。我们也可以翻译成开放信息源情报。开源这个词，它是计算机科学领域一个相对比较传统的词。我们都知道在计算机科学领域有一个开源运动，而开源信息源实际上就是情报科学界吸取了开源运动的一些经验，从而创建了大量的开源信息列表。

这里有一个极其反常识的概念。有人以为情报工作者还是通过私密的信息渠道获取信息，但实际上并不是这样的。绝大多数情报工作者是通过公开的信息渠道获取信息来进行信息分析的。OSINT 就是把这些公开可得的信息，以及在一些非公开的、私密的信息整合在一起，最终创建出一些列表给大家参考。

这整个课程中，我们推荐的最重要的两个开源信息源，一个是 OSINT，它是由国外的情报专家和信息分析专家整理的。我们可以看到它是按照搜索引擎、社交媒体、工具类、搜索配列、文件进行分类的。其中搜索引擎又包括了一般搜索、主要国家的搜索、专业搜索、视觉搜索和聚类搜索引擎等。

我们再看一下开智信息分析工具箱 1.0 版，它是模仿国外的 OSINT，由整个开智团队以及各位同学集体参与，从 2018 年我们通过几千名同学的共同努力整理出了一个更适用于中文世界的开源信息源。这个前面给大家介绍过的开智信息分析工具箱 1.0 版，它目前包括了信息分析概论、学术信息、商业信息、职业信息、报告呈现这样的框架，它是按照整个信息分析 2.0 课程学习的框架搭建的。到了今天的信息分析 3.0，我们的整个课程框架发生了重大变革，显然这里面未来我们的开智信息分析工具箱 1.0 版也将同步迭代到 2.0 版。

各位同学可以留意这些迭代的成果，我们会正式发布为一个叫做「活水网站」的网站。它包括了一些重要的功能：

第一个重要的功能，也就是信息源的功能。各位同学整理，再加上开智团队整理的成千上万个信息源。

第二个重要的功能，它包括这些信息源相关的介绍文章和使用技巧。不少同学知道一些信息源的存在，但是他不知道如何去更好地使用这些信息源。那么我们把别人写的关于这些信息源介绍的使用文章综合在一起，这样就能够更好地帮助各位同学来使用这些信息源。

目前这个活水工程的内测版已经初步开发好了，但是还不尽如人意，所以大家可以耐心地期待它未来正式发布的那一天。

接着我们再来看一下信息类型。前面我们谈到，即使对于情报工作者来说，80% 的信息也是来自于公开渠道的。那么我们这些信息类型，按照是否可以拿到手之后能否直接使用，还是需要进一步处理才能使用，我们可以分成两类：

第一类是文献信息源，它是能够直接进行使用的，比如媒体发布的新闻、上市公司的年报、各个网站的广告、政府发布的公告、行业的著作、专业社区的讨论等，这些文献信息源拿到手之后你可以立即直接使用，并不需要进行额外的处理。

另一类是非文献信息源，拿到手之后我们还需要进行一些处理。它包括广播、电视、口头交流、实物、会议、论文演讲、社交网站等等。我们拿其中的广播来举个例子，你拿到广播之后，你还需要借助于一些第三方软件，把广播的音频格式转化为相应的文字格式，这样才能够更好地进行进一步的信息分析整理。

大家可以发现，这就是我们在日常生活中常常接触到的信息类型。在人类世界，到了今天我们接触的信息类型已经变得极其庞大了。那么如何更好地对它们进行管理呢？实际上你可以借助于 Zotero 软件来进行管理。我们可以看到 Zotero 支持的常见信息类型，这是阳老师把它截了一个图。你会发现左边包括案例、百科全书、文章、报告、博客帖子、词条、地图、电台广播、电影、法案、法规等。右边这个截图我们会发现包括会议论文、即时讯息、论坛帖子、软件、视频剪辑、手稿、听证会、信件、学位论文、演示文档、艺术品、音频剪辑、杂志文章、专利、Email、预印本、TV 广播等等。

很多同学早期不明白阳老师为什么会选择 Zotero 作为整个信息分析搭配的一个重要软件。他们以为 Zotero 只是一个简单的文献管理软件。通过 Zotero 支持的常见信息类型，你会发现 Zotero 其实不仅仅是一个文献管理软件，它还是一个支持丰富信息类型的信息管理软件。与 Zotero 竞争的一些文献管理软件，比如 Endnote，它实际上只支持论文、图书等极少数格式的信息类型，对于我们如此丰富的信息类型是没有办法支持的。

在 21 世纪，我们不仅会接触到以文字为主的一些信息类型，我们还会接触到音频、视频等等。这就是当初我们信息分析挑选 Zotero 作为信息管理工具的一个重要考虑。

我们在这个表格中，把 Zotero 支持的常见信息类型做了一个初步的整理，这样能够让大家看得更清楚。大家可以发现，第一列是笔记，第二列是论文，它下面又可以按照作者、期刊、博士论文、实验报告、研讨会、期刊、杂志等进行分类。第三列是图书，第四列是个人出版物，第五列是媒体，第六列是个人工作，第七列是网络资料，第八列是你个人和别人交谈的一些文件。

这就是最早我在信息分析 1.0 和 2.0 时代给大家提供的一个模板。当然，基于这个模板，我过去从 20 多岁到 35 岁左右使用得相对比较频繁。从我 38 岁之后，对这个 Zotero 梦露模板进行了新的更新，目前进化成 2.0 时代了。在我们的这个信息分析课程里面可以给大家介绍一下 Zotero 梦露模板 2.0 和 1.0 的一些区别，它加入了更多的信息类型。

这里面我们会发现，一个好的信息管理工具，它其实需要能够对各种各样的信息类型进行一个统一的处理，这样我们才能够不至于只能处理文献。这是要特别提醒大家的。

好了，我们接着再来看一下信息获取的一个简单发展历史。从中国古代开始，在战争的时候我们就非常重视信息获取。《孙子兵法》中有一些重要的言论，在《三国演义》中也有一些重要的言论。不仅仅是在咱们中国重视信息获取，实际上在西方也是一样的，他们也重视信息获取。我们可以看到这是公元前三世纪的一个例子，这是十三世纪成吉思汗的一个例子。

那么到了二十一世纪，信息获取已经发生了一些重要的变化：

第一个重要的变化是，信息获取不再像古代一样只是军事家经常使用的一种技能，今天的信息获取成了你的日常生活的一部分，每个同学天天都在进行信息获取。

第二个重要的变化是，我们今天的信息获取难度变大了，我们需要从庞大的信息中甄选出靠谱的信息。绝大多数时候我们是在从噪音中识别信号，从垃圾中挑出金子。

第三个大的变化是，今天你需要的信息或许面对的种类变多了，不仅仅是语言类的信息，像以书面文字为主的，还包括视频、音频类的信息，还包括了大量的非结构化的信息。比如你和别人的微信群聊天，你看到别人发的一条微博，里面也许就有一些重要的信息。

很多人的信息管理习惯并没有跟上时代的变化。他们掌握的信息技巧，绝大多数时候依然是以书面文字语言为主。甚至会出现一种很常见的情况，比如一个同学在微博里面看了一条写得比较好的微博点了一下收藏，在微信里面看了一条比较好的信息又点了一个收藏，在网页上看了一个比较好的信息又点了一个收藏。一位同学他也许经常使用的软件有这么十来个、几十个，那么他的收藏也有十来个、几十个。你会发现他的收藏是分布在不同的平台、不同的软件。

那么这个时候会碰到一些问题：

第一个问题是，有时候你收藏的一些网站倒闭了，关闭了。

有时候虽然这个网站还存在、没有倒闭，但是你把你自己的密码给忘掉了，再也找不回自己的账号。

所以我们会发现，一个人的信息管理习惯，很多时候其实是没有跟上时代的发展。我们需要主动地优化自己的一些信息习惯，来跟随时代的挑战。

好了，刚才看到第三个比较大的变化是，时代给了我们一些难点，给我们带来了一些新的麻烦。那么 21 世纪同样也给我们信息获取带来了一些新的好处。你会发现在 21 世纪，信息获取与计算机技术，尤其是人工智能技术是密切相关的。出现了一些专门的信息获取软件，比如在今天之后的课程中我将给大家介绍的爬虫软件与 API 软件，这些能够帮助各位同学提高信息获取效率。

在信息分析 2.0 时代，已经给大家介绍了爬虫软件。在信息分析 3.0 时代，我们开始引入了一个新的知识点，叫做 RPA 软件。什么是 RPA 软件呢？你也可以把它简单地理解为数字机器人软件。它是最近三五年变得越来越成熟了，越来越有助于各位同学提高自己的信息获取效率了。这是在后面的课程中将给大家进行详细的介绍。

好了，这就是第一节「21 世纪的信息获取」给大家做了一个回顾。我们发现，什么是信息获取，以及我们在 21 世纪信息获取究竟发生了一些什么样的重要变化。

### CH0702信息获取的关键操作01

各位同学，现在我们来学习信息获取的关键操作。大家可以跟着我一起来看看，信息获取有哪几个关键操作。我们总结到就是四个关键操作，这就是在 21 世纪你需要提高自己信息获取能力需要注意的。绝大多数时候，你的信息获取能力之所以差，往往是你对其中两个到三个关键操作掌握得没那么熟练，或者是一些重要的技巧没有掌握，或者是一些重要的工具不知道。

好的，这就是说，我们提高自己的信息获取能力，可以努力的四个方向：

第一个重要的操作是信息源，我们需要从一个信息源快速开始。

第二个操作是，当我们从一个信息源快速开始之后，拿到了大量的信息，那么你需要掌握一些技巧来快速验证你拿到的信息是否符合你的需求。

第三个重要的操作是，当我们拿到了这些信息，也快速进行验证了，发现有的是符合我们需求的，有的不一定符合我们的需求。当不符合我们需求的时候，我们需要进行调整信息源的操作，需要找到更多的信息源，找到更好的信息源。

第四个重要的操作是，当我们找到越来越多的信息之后，我们需要把信息源上面的文件保存到本地。有时候，有的信息源给你提供的是非常现成的、相对成熟的文件，你只需要知道如何批量下载就可以了。有时候，有的信息源没有那么成熟的文件给你下载，那么我们需要借助于一些智能获取的方法，把一些零散的信息拼在一起，导出为一个 CSV 文件，或者 Excel 文件，或者其他格式的文件。

这就是我们在信息获取的时候，重要的四个关键操作。我们先来看第一个关键操作，跟着我一起来具体了解一下。

第一个关键操作，我们需要从一个信息源快速开始。那么我们可以从哪些信息源快速开始呢？

第一种类型是利用源信息源与开源信息源。

第二种类型是利用搜索引擎。

第三种是利用专业数据库。

第四种是访谈或调查。

绝大多数同学在从信息源开始的时候，他们犯的一个严重的错误是什么呢？他们会把信息获取等同于使用百度或者 Google。其实，绝大多数时候你会发现，他们的信息获取习惯就是，无论给了他什么关键词，就在百度里面敲一下。这种是很多人习惯的一种信息获取方法。我可以告诉大家，80% 的情况之下，这不是一个好的方法。

我们更好的信息获取习惯是什么呢？从平时有意识积累的信息源的信息源开始。你可以把信息源的信息源称之为「源信息源」。这就是信息源。那么在我们进行信息获取的时候，有哪些常见的源信息源呢？其实你可以沿着两个问题去思考，这也就是涉及到「源」的定义。第一个问题是 A 是什么，第二个问题是 A 会集中聚集在哪些地方。

这里面给大家举了一些具体的例子：

比如说，像论文，论文往往有一些原创分析报告和文献综述，它们相对比较权威，我们可以把它称之为「源搜索」。

我们再看一下「大师」。你可以发现有大师排行榜，还有大师的老师，还有顶级大师，他们这是一个相对比较好的信息源，能够让你一下子知道很多大事。这种我们一般把它称之为「源信息的信息」。

再看一下「媒体」。比如像媒体管理机构、媒体经费、行业大会，他们往往是媒体聚集的地方，这个我们称之为「源分析的分析」。

第四种，我们看一看像「咖啡」。比如咖啡主题网站、咖啡师协会，你通过这些能够快速了解到关于咖啡更好的一些信息，这部分我们一般称之为「源数据的数据」。

再有「原知识」，比如像音乐的音乐；再有「源学科」，比如像书店的书店，等等。

总的来说，在我们的日常生活中，我们几乎会发现，处处都有信息源的信息源，也就是说，源信息源是无处不在的。当我们把这些源信息源呈现为一个清单，你搜索的时候先从源信息源去入手，它往往是一个更优质的做法。而且，在第一步得出的这些结论，和你通过百度、Google 得出的结论极可能会不一样。

那么这里面又有同学会问：杨老师，我现在是一个信息分析小白，我现在还没来得及积累自己那么多的信息源的信息源，那么我这个时候该怎么上手呢？这个时候大家就可以掌握这个技巧：从开源信息源进行搜索。我们前面介绍的 OSINT，还介绍了开智信息分析工具箱 1.0，这些是属于整个社群和信息分析专家已经帮大家积累好的优质信息源。你通过这个清单入手，也比你通过百度来进行搜索，能够大大改善你的信息获取质量。

这里面也可以给大家举一个我的例子。我经常把自己整理的一些信息源清单发布给大家。比如说，这是在我的个人博客网站发布的一个清单，它叫做《认知科学与心理学优质资源索引》。这个清单把我自己在认知科学与心理科学领域常用的一些信息源整理成了一个列表。那么当我自己要搜索认知科学、神经科学、心理学相关的资料的时候，我也会自己第一步打开这个清单，然后再去找一下，看一下这个清单有哪个优质的信息源是最能够解决我要搜索的问题的。

在我的个人博客网站，其实我不仅仅发布了这个清单，还有很多清单。比如说有《开放科学清单》，有《不上大学该怎么学》，这是针对那些没有受过高等教育，比如初中毕业、高中毕业的同学给他们的一个自学指南。这种清单在我的个人网站上其实是非常多的。这是十多年前我当时整理的大量清单，十多年之后在我自己的日常生活中也是经常使用这些清单的。

这是提醒大家的，我们第一步从这些信息源的信息源开始，往往比直接用百度和 Google 效果更好。

接着才是搜索引擎与专业数据库。这里面有两个概念，第一个概念是搜索引擎，第二个概念是数据库。那么我们来看一下，搜索引擎和数据库有什么相同的，有什么不同的。

搜索引擎它是以数据库为基础的。一般来说，任何一个搜索引擎，它背后都有数据库，只是有的是一个数据库，有的是很多很多个数据库。但是并不是所有的数据库都是搜索引擎，这是要提醒大家的。

比如说，像通用的搜索引擎百度、Google，收录的数据量是远远超过了一般数据库能够容纳的极限，因此他们常常采取的是一个分布式数据库的架构，有成千上万台服务器来承载这些信息。当然还有一些数据量不太大的搜索引擎，他们往往是一两台数据库来承载就行了。比如说像杨老师整理的京剧数据库，就是把当时一些比较好的京剧引进来，这个其实就一两台服务器就够了。好了，这个是提前来讲的。

另一个是，搜索引擎它包括了检索、浏览等界面，但是数据库它不一定包括完整的上述界面。比如说，有的商业数据库它特别注重数据的一致性，这个时候它的检索功能并不是它最重要的功能。再比如说，像嵌入式设备的数据库，它特别注重的是大小尺寸。比如说在一些非常小的设备上运行的数据库，那么这个时候它节省流量的界面也没那么重要了。

所以说，这个是搜索引擎和数据库的区别。数据库它常常包括搜索功能，但有的也不会包括。数据库涵盖的范围比搜索引擎其实是更广阔的。还有一些非常典型的数据库，它是搜索引擎没办法包括的。它最典型的就是加密数据库。比如说，像比特币和以太坊，它背后都是涉及到加密数据库的。这些加密数据库，它就是没办法通过搜索引擎来进行检索的。

通过搜索引擎来进行检索，也是它加密之后的一个哈希值等等。对于像比特币、以太坊这种区块链生态的数据库来说，搜索功能常常不是他们最关键、最重要的功能，而是数据的一致性和安全性变得更重要了。

大家可以看到，搜索引擎和数据库，它们在搜索的时候常常相对比较近，但是它们的确也有一些内容是不太一样的。

好的，那么这里面我给大家总结了过去 20 年我最经常使用的一些搜索引擎和数据库，也许对各位同学会有一些启发。我们现在看一下搜索引擎。

这是杨老师过去 20 年时间尺度在日常生活中使用最频繁的三大通用搜索引擎：

第一个是 Google 搜索引擎，

第二个是微软的必应搜索引擎，

第三个是百度的搜索引擎。

好的，我们再来看一下，阳老师的工作有不少是跟学术研究相关的。我使用最频繁的英文学术搜索引擎，一个是 Google 学术。它是 2004 年 11 月份发布的测试版，它也是史上最大的一个学术搜索引擎，目前覆盖了英语还有很多语种，是世界上目前收录文献数量最多的。但是 Google 学术搜索引擎目前也有几个相应的缺点。

第一个缺点是，它的访问不够稳定，常常把你的 IP 给封掉了。这是因为中国不可描述的一些原因导致的。所以说从信息分析 3.0 开始，我更给大家推荐的是另一个学术搜索引擎，就叫做 Semantic Scholar（语义学者）。

Semantic Scholar 针对 Google 学术搜索做了很大的改善。Google 学术搜索以前还有第二个缺点是什么呢？它对于一些信息的整理其实不够智能化。在学者论文重要性的评估上，你没办法看到论文和论文之间的关系，它只是简单地基于引用的关系。那么 Semantic Scholar 这部分也做了相对于 Google 学术很大的改善。

所以说，Semantic Scholar 在中国更容易访问，以及它使用更方便、更像是人工智能时代的学术搜索引擎。所以从信息分析 3.0 开始，我们默认推荐的是 Semantic Scholar 学术搜索引擎。

那么它是什么背景呢？它是 2015 年发布的，是由世界著名的人工智能研究所 Allen AI 研究所发布的。目前收录了 2 亿多篇文献。它有几个很突出的优点：

第一个优点是，在大陆访问的速度非常快。

第二个优点是，目前绝大多数学科领域的文献都覆盖了。

第三个优点是，它引入了大量 2015 年之后诞生的新的人工智能技术，比如深度学习、知识图谱等等，最终能够让我们更好地评估一个学者的影响力、一篇论文的影响力。

比如拿一个学者举例，我们通过 Semantic Scholar 能够非常清晰地看到一个学者是受到谁影响、他自己又影响到谁，还有这个学者最有影响力的论文是哪些。所以说这个是一个非常好的工具。

当然，Google 学术搜索依然有一些特殊的功能是 Semantic Scholar 不具备的，所以我们今天依然还要经常去使用它。那么有哪些功能是大家需要注意的呢？

第一个重要功能是，Google 学术搜索每年会发布一个 Google 学术指标（Google Scholar Metrics）。它是一个非常有参考价值的指标，它是对全世界所有论文进行统计，然后进行人工智能处理之后，形成一个动态的排行榜。比如说你要学习经济学，你作为一个经济学小白，你参考 Google 学术指标那么你马上能够了解到，世界上最好的经济学领域包括哪些分支学科，各个分支学科最重要的学术期刊是哪些，这样就能够让大家快速地了解到一些优质的信息源。这是它第一个比较特殊的功能。

第二个特殊的功能，大家知道 Google 公司特别有钱，所以它们把全世界尤其是英语世界的很多图书信息都做了处理。所以 Google 学术搜索对于图书的信息，是远远超过像 Semantic Scholar 的。Semantic Scholar 目前收录的图书信息相对还是比较少的。

第三个，它不仅仅局限在学术论文、图书，还有大量的专利信息、法律判例、法律条款。这些信息目前 Semantic Scholar 本身都还没来得及收录。所以说这个是 Google 学术搜索它很独特的一些优点。我们在生活中，尤其是一些不是论文的场景，我建议大家还是要去使用它。

好了，接着大家跟着我一起再来看看常用的中文搜索引擎。显然，这个就是百度学术了。百度学术截止到 2020 年 4 月 21 号，它收录的文献信息已经达到了 6.8 亿条，还是比较庞大的一个数据量。它收录的国内外学术网站达到了 120 万个，其中免费的全文资源占到了 1.2 亿。所以说，对于在中文世界从事学术研究，你要检索中文相关的学术论文，百度学术目前也是一个绕不过的学术搜索引擎了。各位同学在日常工作中还是可以频繁地去使用它。

更多的搜索引擎，像通用的搜索引擎、学术搜索引擎、不同国家的搜索引擎，还有前面谈到的源搜索引擎、视觉搜索引擎等等，各位同学可以参考前面我们介绍的开智信息分析工具箱中整理的搜索引擎部分。

在之后我们的「活水」网站发布之后，有一位同学他也开发了相应的工具。这个工具能够自定义自己优质的信息源。比如说我们想同时搜索好几个搜索引擎，那么通过这个工具就能够一键搜索。同时，我们在信息获取的时候，还存在一些提高信息获取效率的小技巧，比如有的同学忘记了使用上位词、下位词，还有查找相应术语的技巧。那么在这个工具中，它也集成了相应的默认好的搜索引擎或者优质的信息源。当然，这个工具能够帮助大家更好地改善自己的信息获取效率。这个工具未来成熟之后也会发布在我们的「活水」网站，目前也是一个内测版，各位感兴趣的同学可以开始使用了。当然也欢迎给开发团队提意见。

好了，接着我们再来看一下数据库。先来看看常用的学术数据库，也是先从英文看起，我们接着再来看中文。

英文常用的学术数据库，其实是 Web of Science，也简称为 WOS 数据库。它是目前英文世界排名第一、使用最广泛的，也是得到了全世界最多科学家认可的一个数据库。大家可以看一下它收录的数据量。截止到 2014 年 9 月 3 号，它包括了 9000 万条记录，其中再包括了 10 亿条引文数据，也就是说每篇论文引用了哪些参考文献，它也包括了。平均每年，WOS 数据库会新增将近 6000 万条数据，也是目前被称为世界上最大的可访问的科学引文数据库。

这个数据库它有很多很多优点，也提供了很多特殊的功能。它的优点是，相当于目前得到全世界最多科学家的认可。

第二个优点是，这个公司它本身对这些引文的关系分析是比较准确的。比如说，各位读过硕士博士的同学，写论文的时候、发表论文的时候，经常会碰到一个要求，你需要在核心期刊发表论文。那么这个核心期刊，比如说像一区、二区，一般认为一区还是比较好的，二区稍差一些。那么像这些区域，它其实就是跟 JCR（期刊引证报告）指标有很大关系。JCR 指标又是跟 WOS 数据库有很大关系，是基于这些引文数据库得出来的一些结果。所以说，这是它第二个比较大的优点。

第三个比较大的优点是什么呢？因为它收录的引文已经非常庞大了，有 10 亿多条，并且这些引文和引用的关系构建得相对比较完整。比如说在我们中文学术界，最主流的数据库是 CNKI。CNKI 非常遗憾，你只会发现一篇论文它引用了哪些论文，但是它被引用的信息你会发现很多是有一点缺失的。国际上的学术界相对来说比 CNKI 这部分要起步早几十年，实际上它们 10 亿引文之间的关系已经非常丰富、非常全面了。

我们要进行更专业的学术信息分析，往往是拿 WOS 数据库导出的引文来进行分析。WOS 也成为一个默认的引文格式。比如说我们后面在专业课程《学术信息分析》中，各位同学要跟着阳老师、阳老师团队学习使用 CiteSpace 来进行引文共被引网络的分析。那么这个引文共被引网络的分析，它实际上使用的就是 WOS 数据库导出来的相应格式。我们通过 CNKI 导出来的格式，它常常是不符合要求的，需要进行一定的转化。这是很多同学在进行知识图谱分析的时候踩过的一个坑，这是我提醒大家的。

好了，那么通过刚才的介绍，大家会发现 WOS 数据库它有很大的优点。我们把它总结为三个大的优点：

第一个大优点，它是最大的、最被认可的、也是最权威的、使用最广泛的。

第二个优点是，它有很多特殊的功能，尤其是在它的 JCR 指标上，基本上成了学术界公认的一套学术规范。

第三个比较大的优点，它包含的引文实在是太多了，目前成了用于进一步学术信息分析的一个默认标准。

所以说，这是它三个很鲜明的优点。但是它最大的缺点是什么呢？不是免费的。很多功能，你想使用一点都不是免费的，这是它比较大的缺点。当然你可以在国家图书馆，还有一些大学图书馆，它们一般都购买了这个数据库，你可以去访问。另外一个是，它很多比较特殊的功能其实都需要权限来访问。比如说你想通过它获取一些论文的引文，你也需要通过权限、通过付费来访问。显然，这对我们在 21 世纪来进行一些研究性的工作是不太有利的。

所以说，这个时候我们需要给大家介绍另一个数据库。这个数据库叫做开放存储库目录（OpenDOAR），它收录了世界上最多的开放获取数据库。开放科学是学术界从 2010 年开始变得越来越流行的一个趋势。大家知道，明明这些论文是我们科学家自己写的，但是我们现在都被这些商业出版商把持了，然后我们反过来还要给他们交大量的费用，才能够下载自己的论文。这个事情想想有一点扯淡。

所以学术界从 2010 年开始发起了一个开放科学运动。我在个人博客上写了两篇相关的文章，一篇是《如何学习开放科学》，还有整理了一个《开放科学工具箱》，感兴趣的同学可以去看一下。在这两篇文章中，对开放科学的来龙去脉介绍得相对比较清晰。

开放科学十多年的发展，它目前诞生了大量的成果。比如说有开放数据平台，有开放获取期刊等等。那么对于我们常用的学术数据库，开放科学领域也诞生了重要的成果，就是开放论文数据库、开放获取数据库。这些论文，你就不需要任何付费，能够免费地下载。

不同的学科领域，不同的国家，不同的研究机构，他们分别发布了大量的开放科学数据库、开放获取论文数据库。比如像咱们中国的各个中科院研究机构，还有像国家自然科学基金委的一些机构，他们都发布了一些。同样地，像美国一些著名的科研机构，像美国心理科学学会（APS），它是跟 APA（美国心理学会）对着干的。APS 规定所有的论文都必须是开放获取的，不再受商业数据库的限制。大家知道，巴雷特教授他就是 APS 的主席。那么 APS 它是引领潮流的，在心理学领域就发布了大量开放获取论文。我们今天来阅读一些心理学家的重要成果变得更容易了。

那么有这么多机构发布了这么多开放获取的论文数据库，我们怎么更好地进行查找呢？我们有没有一个地方把这么多的数据库汇总到一起？这就是刚刚给大家介绍的开放存储库目录。它就把整个世界上目前绝大多数开放科学数据库都汇总到一起了，能够帮助各位同学更好地通过这个网站一站式地来查找越来越多的论文。

并且这里面我要特别提醒在学术界工作的同学特别需要注意一点，绝大多数开放获取的论文期刊，它发表的门槛实际上是更低的。它更多是遵从同行评审原则，然后收取你一定的同行评审费用，但是它不像商业期刊发表的门槛那么高。所以大家可以有意识地对一些开放获取的期刊进行对比。有的期刊纯粹是为了挣你的版面费的，为了挣你同行评审费用的；有的期刊，像一些权威机构办的期刊，比如说世界上著名的《细胞》（Cell)、《自然》（Nature)、《科学》（Science），这是世界上最权威的三大学术期刊。那么它们也办了相应的开放获取、开放科学的期刊。而这些期刊在学术界目前得到的认可，还有它的排名，每一年都在增加。并且这些学术期刊上，它每年能发表的论文数量是特别大的，基本上是几千篇。假如你是在学术界工作的，你可以优先考虑自己一些没那么重要的论文可以给这些期刊投递，这样的话能够快速扩充你的出版物列表。这是提醒大家的。

刚刚我们会发现，我们给大家介绍的是两个重要的数据库，一个是偏商业付费的，一个是偏免费的。这两个数据库，它都有一个很大的偏颇，主要是针对论文，当然也包括了不少科技图书。但是我们人类世界还有很多并不是科学类的图书，比如像中国古典哲学、中国古典文学，显然像 WOS 这两个数据库都是没有收录的。

那么这些以图书形式为主的信息，我们该去哪里找呢？这里面给大家介绍的是世界上最大的书目数据库，也就是 WorldCat。这个数据库由于特殊原因，在中国依然是不可访问的，这个我们就没办法了。

这个数据库它是 1967 年创办的，目前包括了 170 个国家的 7 万 2 千所图书馆，并且它允许你自己提交图书馆。十多年前，杨老师当时拿自己家建立了一个图书馆。咱们把这个图书馆的名称假设称之为「杨老师的图书馆」。我在这个网站上也发布了自己家里面有一些书目的信息。这样别的常读书者，他可以通过这个网站来了解到杨老师家藏的哪些书，能不能找到自己想要的书，能不能找我来借阅。当然后来由于工作变得越来越繁忙了，这个图书馆的信息也没有仔细更新。未来不太忙的时候，打算抽时间再发布一个新版。

所以大家可以发现，这个数据库实际上收录了全世界 170 个国家的 7 万多个图书馆，并且允许个人提交，把自己家当作一个家庭图书馆提交你自己的藏书。所以它收录的书目信息是越来越齐全的。

很多人有一个错误的认识，他以为查找书目信息只能通过豆瓣，或者通过当当、京东。显然这是错误的，因为像豆瓣、京东、当当这些，它们保存的书目信息是相对有限的，是以新一点的图书为主。比如说我们在豆瓣经常找不到台湾版的一些书，同样的像一些 1949 年之前的书也找不到。但是在 WorldCat 这个书目网站上，这些都能找到。所以 WorldCat 也是杨老师使用非常频繁的一个书目网站。

在信息分析 1.0、信息分析 2.0 时代，整个课程网站设计了一些有意思的考试题目，来考大家，把不少同学给拦住了。当然信息分析课程现在发生了很大的变革，我们不再强调去访问那些由于特殊原因不可访问的网站。所以我们今天不再设计这些技巧了，只是给大家做一个介绍。

### CH0703信息获取的关键操作02

接着我们再看一下，除了刚刚谈到的这些相对通用一点的数据库，其实不同的专业领域都有自己的一些数据库，这是大家众所周知的。我自己是在认知科学、神经科学、心理科学领域工作了 20 多年，那么在这个领域，我基本上每年会给两个数据库去加钱。

第一个数据库是美国心理学会的 APA PsycINFO，这个数据库原本是称之为心理学文献数据库。第二个数据库是麻省理工的认知科学网络数据库。这两个数据库其实都有自己很大的偏颇，给大家做一个简单的介绍。

我们先来看一下美国心理学会的心理学文献数据库。它不仅仅收录了论文，还收录了一些非常独特的东西。比如说 20 年前，当杨老师创业的时候，创办了一家心理测量公司，显然我是要开发一些心理测验的。那么在开发心理测验的时候，我是不是需要做一个信息分析，看一下哪些测验是有科学家已经开发得相对成熟了，哪些心理测验科学家开发得还相对不成熟、还存在信息套利的空间。

所以当时在 APA 这个数据库中，其实是在 10 年之后开始把全世界一些常用的心理测验也收录进来了，就形成了它的一个子数据库。在杨老师创业的年代，它还没有这个子数据库，所以当时我自己建了一个心理测验数据库。那么目前这个工作是不是可以节省我很多时间了？再者，我跟踪全世界其他国家的心理学家开发的心理测验是不是变得更容易了？

比如说，有的心理测验我觉得他开发得非常好，并且不涉及到跨文化的问题，那么杨老师直接跟对方联系，把他的版权买来了。有的心理测验我觉得他开发的实在是糟糕，并且受到跨文化影响比较大，他的很多事物并没有办法得到我们中国人的认可，那么杨老师是不是就自己来开发一套测验？

所以大家可以发现，过去 20 年，我在心理测量领域基本上开发的数百个测验，团队拥有原创知识产权的非常之多。这就是相应这个数据库对我很大的一个帮助。

而另一个对我很大的帮助是什么呢？它还收录了一种非常特殊的数据类型，就是世界上优秀的心理咨询师他们演示做咨询的实际录像，像 DVD、VCD 光盘等等。在 20 多年前，杨老师在心理学领域是一个萌新、小白，那个时候我是不是要快速提高自己的心理咨询能力？这个时候通过观看世界上一些优秀的心理咨询师，他是怎么进行认知行为治疗的、怎么进行家庭治疗的、怎么进行心理动力学治疗的，那么是不是对我来理解心理咨询、提高自己的咨询能力会非常有帮助？

所以这是我 20 年前曾经走过的一些路，这些很多小技巧其实只要是在我团队工作过的同事才知道。过了整整 20 年，它依然没有变成身边非常普遍的一种技巧，这就相当于是经过时间考验的信息套利。

好了，给大家讲讲。那么 APA 这些数据库它还有一个很大的优点是什么呢？它其实收录了非常古老的一些心理学文献，它一直收录到 19 世纪。比如说我们在做一些重要的工作的时候，往往要追溯一些源头，比如在 19 世纪这些心理学家的文献究竟是怎样的。这些文献我们其实在其他地方很难获取到，但是相对而言，美国心理学会因为是世界上最大的心理学工作者组织，他们通过各种各样的手段把这些比较古老的文献也保留得相对比较完整。

这里面各位同学可以设想一下，假设你来写科普和杨老师来写科普，你会发现我们一上来写法就不一样了。杨老师从这些比较古老的文献和最权威的文献中简直是左右逢源，但是你更多是通过微信公众号、百度百科，还有找一些中文出版的书。你觉得你最终掌握的这些信息能够和杨老师这边相提并论吗？显然是不能的。

好的，那么接着我们再来看一下麻省理工的认知科学网络数据库。它收录的数据量就小多了，远远不如 APA 这个数据库，但是它比较特殊，它是世界上相对来说最权威、最大的一个计算机科学和认知科学数据库。比如说在它里面也有一些非常特殊的材料，我之前经常提到麻省理工有一位非常著名的计算认知科学专家，他也是世界上非常著名的认知科学专家，就是 Winston 教授。那么你想阅读他最新的一些演讲，其实在其他地方是读不到的，但是在麻省理工的认知科学网络数据库里面是能读到的，还有他最新的一些材料。

这就是我要提醒大家的。好的，那么只要我们把这个信息习惯推广到其他领域，我们以后来思考，比如说我现在要学习经济学，在经济学领域是不是存在类似的数据库？其实是存在的。一旦你明白了这个原理，你进入到任何一个领域，你相对别人其实往往能获得一个绝对的信息获取优势。你使用了一些专业的数据库，在信息获取的速度和准确度上是远远超过了一些通过百度、通过问答网站、通过微信公众号来获取信息的人。你获取的资料是完全不同的，这是我要提醒大家的。

尤其是随着 21 世纪整个计算机科学领域的发展，这些数据库的功能变得越来越完善了。比如说像 APA 的心理学文献数据库，它甚至精确到什么程度？一篇论文针对的是多大年龄的被试，比如说究竟是针对 0-3 岁的小宝、3-6 岁的大宝，还是针对 6-12 岁的少年，还是针对 12-18 岁更大一点的。它已经精确到这种程度了，年龄段也帮你标注了。

当然是一些相对比较新的研究报告，还帮你标注了这篇论文使用了哪些心理学的测量问卷和测量工具，还帮你标注了使用哪些相对比较独特的心理学研究方法论，比如说究竟是元分析还是普通的结构方程模型，等等。精确到这种程度，显然是你基于这些信息去阅读这些领域中的论文，效率会高很多很多，这是我要特别提醒大家的。

当然还有一个比较常见的功能，就是相应的关联推荐。比如说你阅读这个领域的论文，这些数据库一般来说都会有一些关联推荐的功能。所以这是很多同学他的信息获取习惯不太注意的地方。

而我们看完英文世界之后，我们再来看中文世界，想象中文世界落后太多了。实际上杨老师在认知科学、神经科学、心理学领域，使用中文数据库相对来说没那么频繁。大家可以发现我的绝大多数著作之后的参考文献，基本上都是以英文论文为主，偶尔会涉及到中文论文，一般来讲都是极少数。

好的，那么在常用的中文学术数据库中，给大家推荐哪些呢？

第一个是中国国家图书馆，它也有一个相应的另一个名称，就是中国国家数字图书馆，它们是一回事。中国国家图书馆收录了中文世界最多的图书，尤其是最近几十年以来的一些新书。因为这里面大家知道，在出版行业有一个法律规定，当你出版了一本新书，你必须给国家图书馆提交几本，把你的这本书的书目信息收录进去。所以中国国家图书馆对于最近 30 年以来的新书是保留最完整的，对于中文世界绝大多数图书信息也是保留比较完整的。当然你想寻找 1949 年以前的一些新书，想寻找其他国家写的中文新书，不一定在中国国家图书馆能找到。这个时候你可以通过前面我们讲的世界上最大的那个书目数据库 WorldCat 来进行查找。

好的，我们再看一下跟论文相关的。大家知道在中国，显然使用最多的是 CNKI 知网和万方数据库。20 年前杨老师刚开始工作的时候，那个时候在清华下属的一个单位工作，当时和知网办公室是在二楼，万方数据办公室是在三楼，当时和他们离得蛮近的。

好的，另一个跟知网竞争的是万方数据，目前相对来说是万方数据在产品做得好一些，还有相对收录的数据量大一点，处在一个相对更强势的位置。万方数据它目前也在做一些相应的追赶工作。这是我们在中文世界经常使用的一些学术数据库。

各位同学跟着我再来看看常用的商业数据库。我们同样先来看英文世界，也就是像欧美这些国家为主。第一个比较重要的是彭博终端（Bloomberg Terminal）。彭博终端实际上发明得比较早，它是 1980 年就发明了。它早期甚至是独立的机器，包括了相应的键盘、相应的屏幕。当然到了 21 世纪，它也变成了一个远程服务。

彭博终端最大的优点是，它数据的准确度非常高。第二个大优点是，它的功能非常齐全，差不多包括了一千多个功能。所以你在其他数据库中的一些亮点功能，基本上都被彭博终端包括了。第三个比较大的优点是，彭博终端是整个华尔街金融行业使用最广泛和最普遍的一个数据库。所以现在它慢慢变成了一个社交网络，你会在彭博终端里面看到一些顶尖交易员和一些顶尖金融行业从业者的动态，以及一些灌水、一些梗、一些八卦。这些信息在其他地方其实是看不到的，这也形成了一个相对比较独特的小型社交功能。所以这是彭博终端的三个相对比较明显的优点。它目前在全世界差不多有几十万专业人士在使用。

那么它最大的缺点是什么呢？只有一个字：贵！绝大多数人是用不起的，因为它的收费差不多在两万美金左右。对于华尔街金融行业的人来讲，使用它问题不太大，但是对于绝大多数人是用不起的。当然到了今天，彭博终端也发展出了更灵活的一些定价模型和一些收费方案，成本其实有时候也有一些方法来进行调和，这是它最大的一个缺点。除了贵之外就没有缺点了。

当然我们可以看到，彭博终端更多是以二级市场为主。这里面涉及到商业领域的常用术语，什么叫一级市场、什么叫二级市场。一级市场指的是像我们这些没有上市的公司，对它们进行股权投资。前面我们谈到，一个公司分别会经历一些融资的阶段，最早是种子轮，再是 A 轮、B 轮、C 轮、D 轮，一轮一轮下去，最终上市成功。在一个公司没有上市之前，它发生的股权交易、发生的这些商业行为，其实都统一称之为一级市场。

那么当一个公司上市之后，这时候它变成了一个公众公司，这些股权交易以及一些金融交易行为，一般来讲称之为二级市场。当然到了 21 世纪的发展，目前整个一级市场、二级市场的界限也在相对有一些模糊了。还有整个二级市场已经变得非常庞大了。在过去相对比较经典的关于二级市场的定义往往指的是上市公司，但是今天还包括了更多的金融衍生品，甚至有时候有些人会把期货、很多金融衍生品也包括进来。当然这是不同人有不同的定义。

这里面我们会发现，彭博终端更多是对二级市场这部分的数据收录得最完整、最齐全，更新最及时的。那么对于这些没有上市的公司，我们该看什么数据库呢？这就是杨老师购买的另一个数据库，这个数据库价格一下就便宜很多了，每年差不多几百美金就够了。它是世界上最大的创投数据库。这个数据库其实历史不像彭博终端历史如此悠久，它只有 10 来年历史，是一个相对比较新的产品。

这个数据库收录了大量的创业公司，同样也包括了中国的一些创业公司。它也包括全世界不同国家的创业公司。这个数据库，在我进行一些重大商业决策的时候，我基本上是天天使用。大家都知道杨老师创办了「安人心智」，安人心智下面包括很多子公司，有做安人教育的，有做老年人的，有做成年人的。那么在创办每一家公司之前，我其实会把这个数据库国际上相应的动态会反复看来看去。

比如说最近受疫情的影响，心理健康这个赛道变得非常火。杨老师在 20 年前其实创办了好几家心理健康公司。那么通过这个世界上最大的创投数据库，我就会去观察最近出现了一些什么新的商业模式和一些什么样的新产品形态。

这个数据库它收录数据细致到什么程度呢？它会把新创业公司核心创始人毕业于哪个学校、过去在什么公司工作，在 LinkedIn 这些职场信息网站上有什么信息，还有他有些什么样的主要经历，其实都整理出来了。这是关于这些创始人的。

第二个是关于这些创业公司的产品，它也整理出来了。比如说做的是一个 App 产品，那么它还包括了这些 App 的用户评价，还有相应的在各个应用商店的排名。如果做的不是 App 而是包括了一些智能硬件的，那么这些智能硬件在各个众筹网站是不是出现了。

第三个，还包括了这个商业公司的新闻报道和舆论评价。第四个，还包括了它的这些竞争对手的一些情况。所以它收录的数据是非常非常齐全的，对我做重大商业决策其实帮助非常大。

当然它有缺点，除了需要适当付费，它的费用其实不太贵，所以我基本上每年都在续费。它还有一个缺点是，它整个界面都是英文的，即使是一些中国公司，它也是用英语记录的。所以对于那些英语不够好，以及整个关心中文世界的商业决策来说，也许没那么实用。它收录的中文新闻报道其实不太多。

那么我们看到这些常用的商业数据库，看到英语的，那么我们看一下在中文界最常用的是哪些中文数据库。这个价格一下就变得便宜很多了。中文数据库也是模仿的刚才前面谈的这两个。一个模仿的是彭博终端，目前做得最好的是万得（Wind）这个数据库，它也是市场占有率最大的。另一个是针对创业公司，模仿国外做得最好的是 IT 桔子。IT 桔子这部分收录的创业公司，还有中文的新闻报道也是最多的。

除了 IT 桔子之外，还有做得比较好的像烯牛数据的鲸准，但是像烯牛数据的鲸准，它更多是只向投资机构开放，不怎么向个人开放。所以我们平时使用的时候还是用 IT 桔子。IT 桔子收费也不太贵，每年大家在几百块钱、几千块钱左右这样就能够使用了。

当然像刚刚前面谈的万得这个数据库，它其实也有很多竞品，比如像东方财富等等，也是它的竞品。但是相对来说，它收录的内容会多一些，但是它的会员也是需要你去付费的，并且不一定有个人免费版。假如各位同学没有使用权限，你可以使用东方财富的个人免费版，也是能够达到类似的效果。

这些上市数据库对于我们了解上市公司和一些股市的行情变化会有很大帮助。比如说在前面有序度中，我们谈到咖啡，你想了解咖啡在某一个时间点今天有几个投资者投资了多少，这个比例占了多少股份，然后像散户、个人投资者占了多少比例。你通过证券公司来进行统计会非常麻烦，并且很多证券公司的 App 没有提供声音的功能。但是你通过像东方财富、通过万得来获取声音的数据是非常容易的。

这也是很多股民为什么在炒股的时候特别容易成为韭菜，因为很多股民甚至一辈子从来没使用过刚刚我们谈到的这些数据库。他只是使用这些证券公司给他提供的一些 App。证券公司提供的 App 其实有很多缺点，比如说有一些它该收录的关键数据没有收录；再者，有一些收录的关键数据，它非要你再发额外的费用才能获取。比如说我想了解一个上市公司的机构投资的一些变化情况，像这些功能，不少证券公司把它看成付费功能，其实是用起来没那么方便。

那么这里面假如大家想只是简单地了解一下股市上的一些数据变化，这里面我特别推荐像腾讯的炒股 App。腾讯那个炒股 App 其实对大家来讲有很多优点：

第一个优点是，它收录的数据相对比较完整、比较齐全，它不仅仅包括了一个上市公司的一些重要财务数据，还包括了一些新闻媒体报道，还有一些重大事件的预警。比如说一家公司即将解禁的时候，这个时候它的股价会发生波动，那么相当于腾讯他整理的这些大事件相对比较完整，这是它一个比较好的功能。

另一个比较好的功能，因为腾讯这个 App 使用的股民相对比较多，所以你大概能明白这些散户的心态和一些韭菜的心态。有时候你可以故意跟这些散户和韭菜反其道而行之。比如说当这些韭菜都觉得这个股价会继续暴跌，那么这个时候也许你可以买入；当这些韭菜都觉得即将暴涨，也许你可以卖出。所以可以故意进行一个类似于极限版的股市逆向操作。这是给大家一个小小的介绍。

我们会发现在商业领域，因为它离钱比较近，所以像这些数据库其实是非常多的。除了我们刚刚谈的这些之外，还有一些有捐功的商业数据库也是杨老师直接向大家推荐的。比如说在信息分析 2.0 期间给大家还推荐了一个注册制公司，尤其像新三板公司的死亡名单。死亡名单它和刚刚这些注重数据采集的不太一样，它更多的特色是对一些公司写了一些相对比较文艺、比较幽默的定性研究报告。

这些定性研究报告，各位同学可以把它理解为商业信息分析报告，能够让大家看到一些好的商业信息分析师，他们对于各种事实、新三板公司、上市公司进行各种各样的分析，他们大概有些什么样的角度，经常会重点观察一些什么样的数据。这个 App 和这个网站也是我相对给他推荐的，后来这个是我经常使用的一些常用商用数据库。

当然我介绍的更多是市场占据率最大的、使用最频繁的。各位同学在自己的日常生活中，根据你的需求不同，其实还会有一些更多的。因为杨老师的需求更多，所以在投资房子、投资上市公司，还有自己旗下参股这些公司，所以我关心的点和你关心的点显然会有一些不同，这是提醒大家的。

接着我们再来看一下常用的职业数据库。当然也先来看一下英语世界的。目前英语世界中使用最广泛的是 O*NET 数据库。O*NET 数据库是由美国劳动部创办和维持的一个数据库，它包括了美国职业信息的主要来源，涵盖了整个美国经济的近 1000 个职业，数百个标准方和替代职业的描述。

比如说各位同学经常会碰到一个问题：我现在想从事管理咨询工作，我现在想从事心理咨询工作，那么我是合适还是不合适呢？这个在 O*NET 数据库里面其实都会有一些参考建议。比如说作为一名咨询顾问，你究竟涉及到哪些核心能力的要求，还有什么样的职业兴趣，有些什么样的认知要求，相应的薪资数据，O*NET 数据库有非常详细的统计。

再来，对于我们职业选择、人生发展其实要帮助很大。因为 O*NET 数据库它还会不定期地进行更新，会不断经常收录一些新的职业，这也是一个与时俱进。这是它的第二个大优点。

那么有同学会问，在我们中文世界，在我们中国，存不存在类似的职业数据库呢？非常遗憾，当然是不存在的。20 年前，我一位导师叫史康，他是中科院心理学的一位教授，他也是著名的组织行为学专家。20 年前，他当时申请了一个课题，试图把美国的 O*NET 数据库引入到中国，跟当时的劳动部进行合作。当时这个课题我也参加了，然后我们按照美国 O*NET 数据库的一些要求、一些规范，把它的一些建立职业标准的问卷翻译成中文，根据中国的实际情况进行了大量调整，尝试在中国建立一套中国的职业信息数据库。但是之后由于很多特殊的原因以及一些不能说的原因，这个项目之后没有持续进行下去。

所以到了今天我们会发现，目前我们中国只有一个相对比较简单的职业信息数据库，并且这个职业数据库并没有与时俱进，还没有包括非常详细的一些重要信息，比如说职业兴趣、职业能力的评估和测量。

当时 O*NET 的数据库它进行到什么程度呢？它是按照霍兰德的职业兴趣理论，把人类的职业兴趣分成六种。有的人是喜欢从事事务型的工作，有人喜欢从事艺术型工作。那么它访谈了从事这个职业的很多人，然后得出了一些平均分，作为这种职业的一个重要参考。显然 20 年之后，我们在中国依然没有一个详细到如此地步的数据库。所以我们对于产品经理大概需要一些什么样的职业能力，需要一些什么样的职业兴趣，我们依然是公说公有理、婆说婆有理。所以这是我们很大的遗憾。

那么大家都知道，从信息分析 3.0 开始，杨老师一直在强调，通过各位同学的努力，我们共同来建设一个叫「人类社会关键信息数据库」。那么在这个人类社会关键信息数据库下面，我们能不能借助各位同学的投票，借助各位同学的建议，建立一个中国的职业数据库呢？尤其是杨老师现在对于心理测量的认识更深刻了，他发明了一套人性系统论，比欧莱尔的职业兴趣和职业能力的测量变得更精确了。那么我们能不能更清晰地了解到，比如说从事产品经理的这些人，他大概的大五人格是什么分布，他的常见的人格缺陷和冲突是什么？

虽然我们没办法做到极其庞大的定量研究，因为极其庞大的定量研究需要科研经费。我们今天没有这个条件。20 年前，劳动部给我当时的导师其实已经有不少科研经费了，但是也支撑不了太久。而 20 年之后，虽然杨老师已经变得相对比较有钱了，但是我自己也掏不出这么多的科研经费来支撑一个庞大的定量研究。

但是我们是不是能够形成一些相对比较定性的结论？是不是能够让大家更好地来规避一些职业？有些人其实是特别不适合从事一些职业，那么当我们通过各位同学的努力，通过我们人生发展大师收集的各样数据，其中这个数据库是不是也可能有一天会进程？当然这是我的一个心愿。也希望各位同学把 20 年前杨老师和他的老师没有完成的心愿，我们在 20 年之后，借助大家的智慧、借助各位同学的众包，我们能把这个工作往前稍微推进一步。

我们对常用的学术数据库、常用的商业数据库、常用的职业数据库都进行介绍完了。这里面我们会发现，实际上涉及到三种方法：

第一个是从源头开始，

第二个是搜索引擎，

第三个是专业数据库。

那么这里面还有一种特殊情况是什么呢？市面上已有的信息都满足不了自己的需求，那么该怎么办呢？这个时候我们就没有办法了，只能自己来做一些苦力活了，因为世界上并没有一个现成的信息来满足我们的需求。

这里面给大家介绍过一个例子。在前面谈有趣度的时候，我们介绍了有两个做空机构，一个是浑水研究，一个是香橼研究，他们是怎么来进行访谈和调查的。当时的介绍我们更多是从有趣度的角度来进行介绍的。我们会发现，香橼研究使用的那个信息分析方法它更有趣一些。浑水研究使用的那种做空信息分析方法，说白了完全是砸钱，然后砸的钱更多一些，相对来说没那么有趣。这是前面我们从有趣度的角度来进行介绍的。

那么今天，各位同学要明白，我们也可以从一个访谈或调查的角度来进行理解。我们会发现，浑水研究和香橼研究其实都进行了一些自己独特的访谈和调查，之前不存在现成的信息源能找到这些数据，所以最终就成就了商业历史上非常经典的一个做空案例。

在这个时候，当时我给各位同学做了一个简单的估算。我猜测浑水研究从做空东芝咖啡中，他至少是套利了 3000 万美金；香橼研究差不多是至少套利了 100 万美金。这个钱真的是太容易挣了。跟钱实在是太容易挣了。当然香橼研究为什么挣的钱会少一些？因为他介入的时间比浑水研究介入的晚很多。

具体他们实际套利套了多少钱，实际上是跟他们投入的本金有关系，跟他们使用的杠杆有关系。这个具体的套利数字，他们想必也不会公开。我们只是根据一些蛛丝马迹做了一个简单的推测。

通过这个案例，大家会发现信息分析真的是非常重要，并且信息分析当然是真的能够给你带来巨大无比的收入。那么信息分析开始的第一步、信息获取，其实是决定了你之后面临的一连串事情。比如像浑水研究和香橼研究，假如他们没有这么扎实地做访谈或调查，他们其实之后那几百万美金、几千万美金的投入，他们是不敢砸钱的。但是他们做了这么扎实的研究之后，他们就敢砸钱了，最终就相对比较容易地获取了更多的回报。这就是商业历史上一个相对比较经典的商业案例。

这里面要特别提醒大家的是什么？在我们中国法律规定之下，我们其实是不存在做空机制的。大家会发现做空机制更多是在美股市场上相对比较常见。这是提醒大家的。

### CH0704信息获取的关键操作03

接着我们再看一下，信息获取的第二个关键操作是什么呢？叫快速验证内容是否符合需求。而我们在 21 世纪碰到的绝大多数情况都是信息量过大，而不是信息量过小。当然，一些极其有价值的信息依然是信息量会相对比较小的。

那么这个时候，我们究竟应该如何来快速验证内容是否符合自己的需求呢？最终的一个技巧也许会简单得出乎大家的意料。这个技巧就是叫 Ctrl+F。在 Windows 操作系统下使用的这个快捷键是 Ctrl+F，在苹果操作系统下使用的快捷键是 Command+F。

这个技巧是什么意思呢？它指的是，我们面对屏幕上的任何一个文件，比如说一个网页文件、一个 Word 文件、一个 Markdown 文件，你其实都可以使用 Ctrl+F。这是绝大多数编程界默认的一个快捷键，就是 Ctrl+F 表示查找。

好的，当你 Ctrl+F 之后，然后输入你的关键词，比如说「科学」，你看这个「科学」在这个文档里面有没有，或者说出现了多少次。这能够帮助我们极其快速地验证。

前面我们谈到了，杨老师有大量的信息来源。当我要进行一个信息搜索的时候，我就会打开一个清单，然后把这个清单使用一下 Ctrl+F。比如说我使用这个「认知科学」这个词，好了，它就会跳选到相应的位置。然后我再进一步通过这个源信息源，跳选到相应的数据库或者相应的搜索引擎。所以这个技巧是杨老师使用非常高频的一个技巧。

这个技巧其实也对你的信息整理习惯带来改变。比如说前面大家会发现，杨老师整理的像信息分析工具箱 1.0，还有他整理的《认知科学与心理科学优质资源索引》，所有的这些清单其实只有一页，而不是分页的。有了一页，这个时候使用 Ctrl+F 这个技巧，它给你带来的回报是巨大的。

有些人他就犯傻了，他在信息整理的时候，比如说他整理成特别碎片的清单：清单 1、清单 2、清单 3、清单 4、清单 5，每个清单再分页。其中 Ctrl+F 根本搜索不出什么东西来。这是提醒大家的，看这个 Ctrl+F 这个技巧。

我们也可以做一个延伸，当我们不仅仅是搜索屏幕上的一个文件，而是搜索整个电脑中已经存储好的资料，尤其是一些文本文件做全文搜索的时候，那么这个时候这个技巧就是 Ctrl + 空格。在 Windows 下绝大多数时候是 Ctrl + 空格，在苹果下是 Command + 空格。但是这里我要提醒大家的是什么呢？Windows 使用的文件格式，它本身并不是一种开源的格式，它是自己提出的一些格式。无论是像 FAT32 格式，还是像 NTFS 格式，它的知识产权都是属于微软公司的。所以这些格式其实本身是一个封闭的知识产权，所以对它做全文索引本身稍微有一点难度。另外是，整个开源界对它进行全文索引研究的兴趣其实没那么大。

而苹果，也就是 Unix 操作系统，它是基于 Unix 操作系统。它很多文件格式，包括苹果近几年提出的一些新的文件格式，其实都是在开源界的基础上发展出来的格式。所以你会发现，Unix 操作系统和 Mac OS X 操作系统做全文索引是一件非常容易的事情，并且全文索引的质量是非常高的。

杨老师一直建议各位同学，假如你想成为一名好的创作者，尽早抛弃 Windows 操作系统，尽快投奔 Mac OS X 操作系统或者 Linux 操作系统。其实这个全文索引的方便程度和它的效率程度，其实是一个蛮重要的参考。

当然近十年，微软也不断学习他们，也引入了一些类似的功能。之前在 Windows 操作系统下，你想进行全文索引，只能借助于第三方工具。目前也稍微能借助 Windows 自带的一些功能，当然检索出来的资料质量是非常糟糕的，这是要特别提醒大家的。

并且有时候它做了盘符的区分，比如说分成 C 盘、D 盘、E 盘。但是在 Linux、在 Mac 下绝大多数时候是不太鼓励大家做这种盘符的区分，检索出来的资料质量就高太多了，这是提醒大家的。

好的，通过这个技巧的介绍，我们会发现，我们要快速验证信息是不是自己要的，其实是要解决一个核心难题：如何高效地搜索一个屏幕、一台电脑？这个技巧就是我们在后面的实战课、实操课程、一线查找中有更详细的介绍。各位同学在里面相信会大开眼界，发现原来自己这么傻，怎么还用这么笨的信息获取方法。希望大家通过在开智的信息分析课的学习，能够大大改善自己的信息获取能力。

各位同学接着跟我一起来看看，信息获取的第三个关键操作：调整信息源。假如我们通过前面的方法，我们也找到了相应的信息源，这个时候我们验证之后发现，有的会满足我们的需求，有的不能够满足我们的需求。这个时候我们该怎么办呢？这就是我们关键的操作，你需要找到更多、更好的信息源，这就是调整信息源最重要的两个方向：

- 一个是更多的信息源。比如说关于当前检索的事物你知道得太少了，那么你需要知道更多。

- 另一个调整方向是更好。你当前使用的信息源和你解决的问题两者之间没那么匹配，你需要找到一个更匹配的信息源。

这是我们在调整信息源领域可以做的两个努力。先来看看如何找到更多的信息源。这是我们介绍的重要方法，叫关联推荐。信息过载时代，每个人其实都变成算法努力的对象了。但是我们可以反过来利用这个算法，帮助我们批量找到更多的信息，而不是说总是成为像这些算法的奴隶。这就是我们这个关联推荐的思路。关联推荐只能利用人工智能与大数据获得更多与目标信息相关或类似的信息。

在整个课程中，我给大家总结了最重要的三个关联推荐的技巧：

- 第一个技巧是借助于浏览器插件。

- 第二个技巧是使用人工智能的一些算法，AI 推荐。

- 第三个技巧是借助于一些搜索指数。

好了，大家先跟着我来看一下第一个重要的技巧：使用浏览器的插件 SimilarWeb 来获取关联信息。SimilarWeb 是一个免费提供网站排名和竞争性情报分析的网络平台，它依据很多数据，尤其是网站和 App 的流量数据，还有用户的参与度来进行排名。借助于使用浏览器插件，我们能够更好地获取相似网站的数据。

这里面特别要提醒大家的是，SimilarWeb 这个插件本身不包括低流量的网站或 App。相对而言，月访问量小于 5 万被它界定为低流量，它不包括这部分一些极其小众的、没什么人访问的。你通过这个方法就很难产生作用。

这里面给大家举一个具体的例子。比如说我们现在在访问知网，那么与知网类似的学术数据库究竟有哪些？你通过点击这个插件，你会发现排在前三的有这几个：排第一的是万方，排第二的是小木虫，排第三的是 Sci-Hub.com。万方是前面我们介绍过的，小木虫是学术领域一些信息分析达人经常在一起讨论的一个论坛，Sci-Hub 大家都知道，它是专门用于访问一些付费论文的，这个网站经常被封。我们会发现，访问知网的人经常也访问一些这样的网站。这样我们是不是就获得了更多的信息源？当你在知网没找到相应的结果的时候，我们可以通过这个插件获取到的更多信息源来找到答案。

好了，接着我们再看一下第二个重要的技巧，就是与人工智能算法来找这个关联信息源。一些网站、工具，它是利用了新的人工智能算法而自动收集了很多信息源，这会给我们非常好的启发。

这里面给大家举的是一个例子，这个例子是我经常使用的一个人工智能网站，它是由人工智能专家创办的一个关于学术影响力的网站。这是它的网站名称。那么它这里面统计的是一些什么样的关键信息呢？它统计的是大学排名、教授排名，还有专业排名。它和传统的排名方法不太一样，它主要是基于人工智能来进行统计。

比如说杨老师写了一本谈阅读的书，我在这本书里面就介绍了这个网站，怎么使用这个网站来提高自己的阅读效率。当你开始阅读心理学领域，你是不是不太清楚最经典的心理学家是哪些人？最近 20 年相对比较重要的心理学家是哪些人？那么通过这个网站，其实都能够快速获取到。它对于心理学有一个有史以来最重要的、最有影响力的心理学家的统计，同样地它也把最近 10 年、20 年的心理学家的影响力也有统计。甚至你可以自己任意地去选择一些时间段落，比如说最近 20 年、最近 30 年等等。

在心理学里面，它就细分了认知心理学、人格心理学、儿童心理学等等。这样的话就能够大大改善我们的信息获取项目。好了，这里面我们看的是它关于心理学家的排名。同样地，它不仅仅有心理学家的排名，它还有相应学科最好的研究机构的排名。比如说世界上最好的儿童发展心理学研究机构，把一些它这里面其实也是有统计的。当然对于我们学习，这有一个很大的参考价值。

大家可以发现，杨老师经常会进入到一些他没那么擅长的领域。他是一个化学背景相对比较强的人，认知科学、神经科学、心理科学是他的根据地。但是他偶尔也会进入到像经济学这样的领域学习。对于自己没那么擅长的领域，像经济学，其实我们可以借助这个网站快速定位到相应的关键经济学家、相应细分的经济学研究领域最好的研究机构。这样就能够提高我们的学习效率，这是这个网站很大的优点。

这里面我要提醒大家的是，它也有它的缺点。它目前收录、处理的数据，绝大多数是基于英语世界的信息。我们像中国经典的一些学科，比如像文史学、中国古典文学、中国古典史学和中国古典哲学，它这部分完全是没有收录的。所以它处理出来的学科差异性比较大。当你探索的学科，英语和中文有较大差异的时候，那么这个网站它处理的这些信息的偏差就相对比较明显了。所以这是要提醒大家的。

那么除了像这种专业的、具体的人工智能算法网站，提醒大家的是，它是基于全世界最大的图书网站提到的所有图书，把这些所有图书，人工智能专家通过一定的算法把它聚集起来，然后之后形成一个动态更新的网站。像这种专门对一些特定领域的数据进行处理的人工智能网站，现在与日俱增，变得越来越多了，这是我们非常好的一个找到关联信息源的技巧。

除了通过这种特定的网站之外，我们其实还会通过一些相应的搜索引擎、相应的数据库，它们往往有算法推荐，然后给你推荐了更多的信息源，这也是一个相对靠谱的方法。

好了，这就是第三个方法，就是借助搜索指数找到关联信息源。这个方法相对来说是比较容易理解的。搜索指数，它是以网民的搜索行为为基础的一个数据分析平台。例如我们可以利用百度指数中的需求图谱分析，找到更多的关联信息。上升的词说明搜索需求上升，下降的则为下降。大家可以通过这个词需求图谱，可以找到一个关键词更多的关联关键词。当你在一个领域没找到相应的信息的时候，也许你可以通过它的关联词找到更多的这个领域。

目前最常用的搜索指数工具，一个是百度指数和前面介绍过的微信指数，另一个是英语世界中网上使用最多的 Google Trends。这是提醒大家的，通过这些都能够找到更多关联信息源。

我们接着再来谈谈怎么找到更好的信息源。其实前面我们介绍了信息源大概有几种类型：

- 第一种是源信息源和开源信息源，

- 第二种是搜索引擎，

- 第三种是专业数据库，

- 第四种是访谈或调查。

这是我们在日常生活中使用相对最高频的四种信息源。很多时候，当你使用一种信息源的时候，你发现不一定能解决你的问题。这个时候你可以换一种信息源。比如说你发现使用搜索引擎找出来的这些信息太多了，太泛滥了，太不相关了，那么这个时候你换成专业数据库，它就能够大大改善你的信息获取质量，从而能够大大提高自己快速找到需要的东西。

当我们通过搜索引擎、通过专业数据库都找不到的时候，那么也许你可以去问身边最了解这个领域的人。比如说像我的很多好朋友，他们碰到认知科学、神经科学、心理科学领域，他们关心的某一个学说、某一个数据观点或者某一本书，如果他们自己实在是搞不定的时候，他们往往会来问我一下。这样实际上是采取了一种类似于访谈或调查的方法来帮助自己解决这个问题，这是提醒大家的。

当我们一条路跑不通的时候，我们要及时掉头，换一种信息源，能够帮助我们更快速地获得更好的信息获取质量。

### CH0705信息获取的关键操作04

接着大家跟我一起来看看，信息获取的第四个关键操作：保存到本地。保存到本地实际上涉及到两个重要的环节或者说两个重要的方向，第一个是偏向下载，第二个是智能获取。

随着互联网的发展，网上的资源日益丰富。有时候我们面临这样的情况：为了写一篇论文，我们在网上检索了数百篇相关的文献需要下载阅读；为了做一个文案，我们需要下载几十幅图片进行对比选择。而很多同学采取的是一篇一篇论文下载的方法、一张一张图片下载的方法。难道在 21 世纪面对海量的数据，我们只能采取如此笨拙的方法吗？答案显然是否定的。

我们更好的方法是使用批量下载，利用批量下载保存到本地。批量下载指的是利用浏览器插件、软件将数字化资源如原始数据、报告、文件和视频等批量保存在本地，用于下一步信息分析。

我们在网上获取的文件常常有三类：

- 第一类是文件，相当于 PDF、报告等等，这是我们最常见的。

- 第二类是图片，这也是我们说的比较常见的。

- 第三类是音频、视频文件，它相对来说尺寸会大一点。

对于这些文件本身，我们也许没那么关心，我们更关心的是文件背后的一些原始数据和重要信息。比如说我们怎么获取书目的原始数据？怎么获取论文的原始数据？我们怎么获取到一部电影的原始数据？我们怎么获取到像美团还有一些点评的原始数据？这些有时候是我们相对来说更关心的。

所以在我们这个批量下载的具体实操中，给大家重点介绍了两个技巧：

- 第一个技巧是利用 Zotero 来批量获取原始数据，这是我之前的文章中介绍过的一个案例。我在豆瓣上有一个比较受欢迎的书单叫《杨老师正典》，它收录了一百多本好书。有的同学也许是把它一条一条打开，再去看，显然这是一种低效率的做法，非常辛苦。这个时候我们可以借助于 Zotero 来批量获取这些原始数据。我们可以把它一键保存到 Zotero 里面。保存之后，我们下一步就可以进行继续的信息整理。我们可以看到，杨老师列出的这一百多本书普遍出版于哪一年？普遍聚集在哪些关键词上？这就是我们下一步信息整理可以做的工作。当然我们可以看到，这一百多本书在豆瓣的评分各自是什么样的。这是不是可以帮助自己更好地确定这一百本书我先读哪一本、后读哪一本？我们在下一步的信息整理、信息提炼的时候，我们是不是又对杨老师介绍的这些书会形成相应的心得？这些心得或者感想，我们是不是又可以写成一些读书笔记？但是假如你是东一条读书笔记、西一条读书笔记，你之后进行全文检索是不是又会非常困难？你会发现 Zotero 其实相应的功能都已经具备了。所以这也是我们为什么把它做成一个比较重要的信息管理工具的原因。

- 好了，接着我们再来看一下第二个技巧：使用插件下载网页文件。有时候不仅是需要剥离原始数据，我们还要把文件本身下载下来。我们在网上下载最频繁的无非是 PDF 文件、图片这样的文件，还有音频文件、视频文件，这四个文件类型是我们下载最频繁的。不同类型的文件都有对应的批量下载工具，但是对于多数情况之下，我们是不是可以用一个通用的方法来提高我们批量下载的效率？这就是给大家介绍的浏览器插件「一键下载」。这个插件能够大大提高你的效率，并且能够支持很多下载规则。

比如说这是我之前举过的一个例子。诺维奇是一位著名的认知科学家，他在自己的个人官网上把自己所有论文的 PDF 全文都给大家提供了。那么你一篇一篇去下载，你差不多要点击几百次。这个时候我们使用一键下载这个插件，我们先是选择一下所有的 PDF，好了，那就一键保存了。保存之后，我们下一步的信息整理、信息加工依然是可以导入到 Zotero，也可以不导入到 Zotero，我们可以用各种各样的方法来进行继续的信息整理、信息加工。

好了，这就是给大家介绍的实战课中批量下载的内容。更详细的内容在我们的实战课里面有很多介绍，各位同学可以在那里面继续学习。

我们在这个网上还会碰到一种情况：没有现成的文件可以下载，怎么办呢？绝大多数时候我们其实没有那么幸运，别人帮你已经准备好现成的文件。像诺维奇这么好心的人其实是少数，绝大多数学者并不会把自己所有的论文都找到，然后再整理成一个列表给你一键下载。还有一些比较特殊的信息，比如说我们现在想找一份工作，比如说找的是出版社编辑这份工作。我们现在想了解一下，出版社编辑工作在过去一个月到三个月，它的平均薪资和它招聘的城市都分布在哪些城市？它的平均薪资大概是多少？还有哪些机构招聘的比较多？显然这种时效性相对强、个性化相对强的信息，并没有人有兴趣去整理。

那么这种时候，我们也需要自己掌握一定的方法，把这些对自己的人生发展非常有价值的信息整理出来。那么我们假设把这些信息抓取下来之后，形成一个 Excel 表格。我们统计出来之后，我们假设发现，原来编辑的工作在这个时候北京比较多，薪资普遍不太高。最近有这几个出版社招聘比较多，比如像卢健波老师的古籍出版社、华语教学出版社、后浪出版社，还有一些国有出版社，比如像中信出版社、电子工业出版社、人民邮电出版社、机械工业出版社，这些都是咱们开智文库的合作出版社。那么你会发现，这些出版社招聘相对比较多。这些关键信息的结论是不是对你求职、对你找工作会起到关键的价值？

这个时候我们就需要使用两种技术。第一种技术就是爬虫技术。什么是爬虫技术呢？它指的是网络爬虫或者网络蜘蛛，通过编程的方式自动从网上提取、下载数据。爬虫抓取数据的速度有时候非常庞大，甚至可以达到几千万、上亿的数据。比如说前面我们谈到的通用搜索引擎百度、Google、Bing，这些都是大规模采取了爬虫技术，这样才能够把大量的信息汇总在一起。

在这里，开智团队给大家整理了世界上主流的爬虫软件。第一个是使用最广泛的开源软件 Scrapy，这也是在我们信息分析 2.0 时代介绍为主的一个开源软件。这个开源软件可以借助于相应的浏览器插件，然后帮助我们去做一些爬虫工作。这一部分在信息分析 2.0 时代，我当时觉得这个软件是非常容易掌握的。当时我有点高估各位同学的技术实力了，最终掌握得好的同学其实数量没那么多。所以这部分我们从信息分析 3.0 开始，更多作为一个彩蛋。我们把信息分析 2.0 录制的这些演示视频依然给大家保留，但是各位同学需要注意，技术发展速度比较快，有一些细节的操作，实际上随着版本的不同、抓取对象的不同，它都会发生变化。所以这部分对各位同学来说是仅供参考。

我们在信息分析 3.0 时代，我们降低了学习难度，更多是让大家重点掌握像商业爬虫工具当时提供的免费版。目前相对比较主流的爬虫工具有八爪鱼、后羿采集器。相对来说，八爪鱼是一个相对比较老牌的，再加上他们最近几年又拿到新的几轮风险投资，短期之内这个东西很难倒闭，甚至未来会发展得越来越好。所以在我们整个课程的实操课程中，我们更多演示的是八爪鱼了。

当然大家要明白，通过它去抓取一些数据，接着就是第三类，一个叫云爬虫。中国目前云爬虫受到一些政策的影响逐步都开始下降了。在英语世界，使用最广泛的是 ScrapingHub 云爬虫软件。各位感兴趣的同学可以通过它去研究。这个公司目前规模也变得越来越大了，它的云爬虫也变得非常成熟了。它可以帮助各位同学解决大量的技术难点，因为云爬虫有时候很容易被对方封掉，当你连续访问次数过多的时候就被封掉了。云爬虫对于这类问题解决得非常好。这是我们最推荐的一个云爬虫。

好的，大家可以看到，爬虫技术它始终有一些缺点。第一个缺点是，它稍微有一点学习门槛。第二个缺点是，针对不同领域的抓取需要写不同的规则。第三个缺点是，爬虫很容易被抓取的网站封掉，甚至把你的 IP 锁掉。第四个缺点是，爬虫技术有时候往往会涉及到不同国家的法律政策。在欧洲，它有数据安全保护相应的法规和条款。我们中国近几年也出台了相应的个人信息保护条款。有的人滥用爬虫，然后对方的网站明明是禁止使用爬虫，他依然是去抓取，最后就很容易触犯一些法律条款。

所以从信息分析 3.0 时代开始，我们开始推荐一种新的技术，这是最近一两年五年变得越来越成熟的技术，也就是 RPA 技术。RPA 是什么呢？它是 Robotic Process Automation（机器流程自动化）三个英文字母的简写。它是一种基于隐喻工具、机器人或人工智能数字工作者的业务流程智能化技术。最通俗的理解，你得把它想象成数字机器人。这些数字机器人能够帮我们干很多很多活，比如帮我们复制粘贴数据、提取网页、打开关闭等等，并且可以按照一定的规则进行重复操作。

显然，通过关于 RPA 技术的介绍，我们会发现，在我们信息分析的四个流程中，它都会派上用场。所以从我们信息分析 3.0 时代开始，我们现在开始铺设这个人工智能时代的信息分析。我们开始在每一个地方引入相应的知识点，比如怎么进行智能获取？怎么进行智能整理？怎么进行智能加工？怎么进行智能报告？这就是信息分析 3.0 时代一个大的变化，也让各位同学开始初步接触一些更前沿的技术。这些前沿技术掌握的难度没有大家想象的那么大，它的上手其实都是非常容易的。

当然在我们整个课程设计的信息分析 3.0 中，它是分成通识课和专业课。我们在通识课里面，受限于学习的时长，我们没办法把它特别详细地展开进行介绍。未来更多的内容关于 RPA 技术的更多内容，我们是放在商业信息分析中进行介绍，这是提醒各位同学的。

好了，现在大家跟着我一起来看看主流的 RPA 工具。这是最近几年发展起来的一些还不错的公司。其中国际上最好的 RPA 公司是 UiPath。这家公司基本上现在大量的人在抄袭它，它相当于算是整个行业的源头、最原创、最有影响力的一家公司。这家公司应该即将上市了，当然目前规模已经做得非常大了。

国内这是一个新兴的行业，目前国内做得最好的有两家，一个是红旗说明书，一个是宏基。其中宏基是杨老师我们开智的有好几位大家非常熟悉的同学在这家公司工作。

好了，那么宏基这家公司，他也开发了相应的面向小商家和个人使用的版本。这个版本都是咱们开智的一些同学在负责，并且这个项目上线不到半年，所以各位同学都是第一批能稍微感受一下了。当然也相应地还不够成熟，它目前只有 Windows 版本。假如像杨老师和开发团队这种经常使用 Mac 的，我们暂时就有些体验不了了。但是随着时间的发展，它会变得速度越来越快、越来越成熟。

红旗说明书在信息获取这部分做得不算特别成熟、特别令人使用。那么另一个国内的它的竞争对手叫做来也（Laiye），来也在数据获取、信息获取这部分做得就更成熟一些。所以不同公司的这些产品，我们到时候会放在不同的课程进行介绍。当然这部分我们更多只是一个简单的介绍，然后让大家头脑中有这个概念。我们明白了，在我们 21 世纪，我们不应该成为算法的努力对象，我们也不应该整天从事这些枯燥无聊的工作。我们应该把自己解放出来，那么应该让 RPA 工具对我们完成一些枯燥、繁琐、无聊的工作，它还是蛮有帮助的。这是杨老师给大家一个小小的提醒。

好了，到了最后，我们可以看一下，在智能获取这部分，我们重点介绍的是两类技术：一类是爬虫技术，一类是 RPA 技术。那么这两类技术，它们有什么相同的，有什么不同的？

爬虫技术，它们使用的开发逻辑是发送请求获取网页资源，这是它们使用的最频繁的逻辑。适用的场景往往是数据采集。爬虫技术最大的缺点是，它采集的局限性大，设计复杂场景，比如说事项内的条件筛选采集，都是面临挑战，它难以实现。这是它表现的缺点。

那么爬虫技术相对比较表现的优点是什么呢？第一，爬虫技术已经不算是一个新的技术了，无论是开源的实现、商业公司的实现，还是云端服务的实现，它都是非常成熟了。相应的教程、相应的插件、相应的文章是非常之多的，还有相应的规则也是非常之多的。所以各位同学上手爬虫技术一般来讲没什么难度。

RPA 技术，我们看一下它的技术原理。它其实是通过人工智能模拟人的动作，去模拟。它特别适用的场景是重复性操作，比如数据抓取、登录网站、进行计算等等。它的适用场景其实比爬虫技术要多很多很多。

那么 RPA 技术最大的一个缺点是什么呢？它的技术复杂度其实稍微有一点高。目前业界通用的 RPA 技术往往会涉及到三个环境：

- 第一个环境是设计器，你需要设计一个规则，究竟是什么样的规则。

- 第二个是，设计出来的规则你要去执行，这个是执行器。

- 第三个是管理器。一般来讲我们不太可能只跑一个机器人，多数时候我们是很多机器人同时在跑，帮我们完成不同的需求。那么我们对于机器人与机器人之间会进行调度、进行管理，哪个机器人先干活、哪个机器人后干活。

所以你会发现，RPA 技术涉及到设计器、执行器和管理器，它的技术复杂度其实是远远高过爬虫技术的。另外，它涉及到人工智能，而不是基于规则对重复操作进行计算，这使得很多时候人工智能它只是一个相对的精确而不是一个绝对的精确。所以有时候对一些枯燥的工作，它往往会出现一些特例，这些特例有时候也麻烦我们处理。所以这是 RPA 技术它的一些比较大的缺点。

当然还有一个缺点，因为它的技术复杂度比较高，所以导致它有相应的学习门槛，这是它第三个缺点。第四个缺点是，RPA 技术因为它的技术复杂度比较高又有学习门槛，所以它目前更多是在像世界 500 强，还有像这些银行、这些大型机构中使用得相对开始广泛一点了。比如说在银行中，我们怎么进行票据的核查？我们怎么进行发票的整理？这些财务工作它经常会涉及到 RPA 技术。但是对于一些创业型的工作怎么使用这些 RPA 技术，相应的工具、相应的东西其实都还没有出现。整个开源界成熟的 RPA 的开源工具目前也还不够。所以这是它的一些缺点。

到了我相信时间的发展，未来这些缺点都会像当年的爬虫技术一样都会逐步解决。未来会出现越来越廉价的 RPA 技术的付费方式，也会出现免费的开源的 RPA 技术相对比较成熟的软件包。这是杨老师做了一个判断，我相信随着这些开源件的发展，这些问题都能很快解决。所以从信息分析 3.0 开始，我们就正式开始尝试初步引入 RPA 技术。当然这只是一个简单的介绍，只是一个初步，更专业的知识、更多的内容，未来我们也会邀请开智这些在 RPA 技术公司工作的同学给大家做详细的分享，给大家做一些更多的实操。这就是我们进一步学习的时间策略。

智能获取最后我们简单小结一下。我们前面谈到，信息获取有四个关键的操作。这四个关键的操作它实际上涉及到很多技巧、很多方法。有的技巧、有的方法相对来说是比较容易学习的，你知道之后马上就会去做、马上会用。有的技巧方法它相对来说有一点难度。有的技巧和方法它有一点专业性，甚至涉及到一些新兴的技术、一些前沿的技术。

所以我们在实战课这部分，我们总结了三个最最最关键的妙招：

- 第一个是一键查找，

- 第二个是批量下载，

- 第三个是智能获取。

我们总结的这些妙招都是按照一个统一的逻辑：

- 先是第一个妙招，它包含了我们通过人力的大脑就能够记住的知识点。像一键查找，它最关键的知识点和操作细节其实就是 Ctrl+F，以及在自己的电脑上 Ctrl + 空格。在苹果下我们是 Command+F、Command + 空格。所以这就是我们通过人力的大脑马上就记住的妙招。这就相当于是解决的是一个信息过载，如何快速定位信息的问题。

- 第二个妙招是批量下载。那么它就需要稍微借助浏览器的插件、借助于特定的专业工具才能够帮助我们更好地完成妙招的操作流程。浏览器插件我们主要介绍的是「一键下载」这种插件。专业工具我们主要介绍的是 Zotero，它帮助我们完成的任务是如何将已有的文件批量下载到本地。

- 第三个妙招是智能获取，它就变得更难一些了。它的专业性就更强了，技术含量也变得更高了，当然价值也变得更大了。所以这是一个由浅入深的过程，从简单到复杂的过程。智能获取的部分我们主要介绍了爬虫技术和相应的爬虫软件，还有 RPA 技术和相应的 RPA 软件。它帮助我们解决了实操中的问题：网络上始终有一些零散信息，那么我们如何将它们整理成可下载的文件呢？

再来说，我们接下来实战课、实操课这部分，整个课程设计的逻辑正好就是：各位同学需要记住，你用人力大脑需要记住的最重要的一个知识点是什么？接着你再借助于浏览器插件或者说是比较容易学会的一些专业软件，最重要的技巧是什么？接着你还想挑战自己，你想未来成为一名信息分析专家，或者说在自己工作中想更频繁地应用一些专业的信息分析技术，那么这个时候你可以挑战第三个妙招。第三个妙招由于时间的关系，我们在这次信息分析 3.0 中给大家介绍了相对基础的内容。未来我们会有更多的通过各种各样的形式，让大家在专业课还有通过其他同学的讲座掌握得更详细。这就是我们实战课整个课程设计的逻辑。

最后给大家做一个简单的小结。信息获取是信息加工的第一步，它的质量决定了之后信息整理、信息加工与信息报告的质量。希望今天的课程对各位同学提高自己的信息获取能力有所启发。大家有一点感觉了吗？我们下一节课再见。