## 0501. 推理成为博学者

### 提炼

1、尽可能用英文写提示词。因为语料库的原因，GPT 对那些在论文、书籍、维基百科中被充分训练的算法有很好的处理能力。许多专业的算法并没有翻译成中文，即使翻译成中文，也可能没法准确地翻译回去。

2、GPT 在学习上的三大核心能力：对比能力、列举能力和模拟能力（如果...那么...）。

### 5.0 开场白

现在正式开始进入今天晚上的主题讨论，即我们的第五讲。在课程开始之初，我定下的标题是「推理：成为博学者」。然而，当我完成了整个讲义的编写后，我发现「推理」这个词并不能完全概括所要讲述的「学习」内容。这里的「学习」，尤其是 GPT 的学习方式，它与以往的学习方式有所不同，这个我会在后续讲述。所以，第五讲我们就正式将标题更改为「学习：成为博学者」。今晚我们将有四节核心内容，希望大家有所收获。

在第一节，我们会讨论 AI 新时代，特别是以 2023 年 3 月 15 号作为划分时间的版本。当然，有的人也会选择 2022 年 12 月 1 号或者 11 月 30 号 —— 即 GPT 上线的那一天作为划分标志。这都是可以的。我更倾向于使用 2023 年 3 月 15 号，即 GPT 正式对外发布的那一天作为一个划分标志。

可见，在 AI 新时代之前，我们的学习有一套流程。然而，AI 新时代对我们整个的学习流程产生了巨大的冲击。这就构成了我们今晚讲义的逻辑架构。

在 5.1 部分，我将与大家分享 AI 新时代对我们学习逻辑的冲击，以及它引发的新挑战。

在 5.2 部分，我将提出一种新的学习方法论，告诉大家如何去应对 AI 新时代的挑战。

在 5.3 部分，我们会像之前的讲解一样，给出 4 个原则，说明我们如何更好地利用 GPT 来学习。

最后的 5.4 部分，我们将提供一种工具模板，总结出 16 个经典的聪明学习的模板。

### 5.1 人人都是达芬奇

#### 5.1.1 博学者 VS 专家

我们从 5.1 部分开始，主题是「人人都是达芬奇」，这代表了在 AI 新时代即将来临的一种现象。

让我们来看一下什么是博学者。历史学家彼得·伯克（Peter Burke），一位著名的英国历史学家，主要研究方向为文化史。他撰写了一本我之前在公众号和知识星球推荐过的书，名为《博学者与他们的时代》。在这本书中，他将博学者定义为掌握多个学科、对知识有百科全书般热情的人。西方最典型的博学者即达芬奇，他既是工程师，也是画家，更是生物学家和植物学家。达芬奇的许多操作和成就为我们证明了他的博学。

追溯到中国的明末清初，我们同样有一位博学者方以智。方以智出生于安徽，精通多个学科，历史学家称他是具备百科全书性质的人。关于方以智更具体的资料和生平，我在公众号上有过详细描述，在此就不再赘述。

这两位都是西方和中国博学者的典型代表。转眼到人工智能时代，我们会发现大语言模型 GPT 的工作方式，它恰如博学者的学习方式。

之前阳老师在讲解中提到了语言模型的演化历史。在阳老师几年前研究语言模型时，我们首先需要准备常用字词组合之间的关系，同时也需要准备几千条甚至几万条错别字的规则。

当时阳老师的团队开发出了大约几百万条错别字规则，并基于语料库生成几千万字词组合关系。

然而，我们发现这样的机制很像专家，它是一个能高效准确识别错别字的专家，但当阳老师想要提供翻译功能给用户时，然而这种错别字识别专家的能力就无法发挥作用了。

如果团队需要重新建立一个新的模型，这个新模型可能就是又出现了一个与翻译相关的模型。例如，当阳老师的团队在当年研发时，他们建立了约 15 个小模型，这些源自不同领域，包括统计、标注、原话语、错别字、敏感词、关键词、摘要和生存等。

当年他们用于生成的是 gbti，但生成效果有些一般。除了前 8 个已经列出的小模型外，还有生成、改写和替换等模型。

接下来第十一个是搜索模型，第十二个是知识图谱，第十三个是句法分析，如果要叫第十四个，那就没有 ocr 模型。在这个工作机制中，我们发现为了特定领域的特定任务，我们需要训练很多特定的小模型，这有点像一个专家的工作方式。

但是进入 GPT 时代，它所采取的逻辑完全不同。不再是针对特定领域训练模型或者制定语料或错别字的规则。他首先找到高质量的语料，然后进行充分的训练，有点像爆炒。例如，GPT 让 GPU 全力运行，好像在爆炒一样，虽然这容易「炒糊」，即在一维空间把符号混淆，让生成的符号和符号之间的概率连接关系变得很容易重复且没有意义。但是在对语料进行预处理的时候，实际上他会把它「爆炒」成一个纤维的空间，生成无数的连接方式。

当我们人类在谈论我们自己的感觉方式时，我们通常储存的是 5 种感觉，比如对某一个符号的嗅觉特征，某一个符号的听觉特征，和某一个符号的视觉特征。但是在大模型进行预处理数据时，他会对每一个符号存储一个纤维的特征，这些纤维特征远超我们人类的心理词典，也就是说包含了视觉、听觉等等。

因此，所有可能出现的关系可能都已经储存在其中了。

那么，接下来该做什么呢？在大型模型训练完后，下一步我们的目标是让这个大型模型具备识别错别字的能力、翻译的能力、对话的能力。如果我们提供超过 300 条以上的指令示范，这些示范如果是多个指令，那么就会构成一轮轮的对话。这个指令集合和对话集合，构成了大型模型的能力，也就是 GPT 的能力。

昨天，阳老师和团队整理了可能是中文领域最大的指令集合，它总共拥有 261 万条中英双语的指令，我们拥有了 261 万种可能性。然而，这样的结果带来的代价是什么呢？代价就是，大型模型的能力可能过强，导致其训练的成本非常高。工程师告诉我，昨天晚上训练了整整 12 个小时，到今天下午的时候训练的进度还不到 7%，这显示了指令集合对于模型训练的重要性。

当我们希望大型模型具备一种新的能力时，我们就会编写一种新的指令集合。团队采取了非常聪明的方法，利用他们强大的信息分析能力，找到了市面上所有的指令集合，进行数据整理，最终形成了 261 万条的指令集合。这可能是目前中文领域最大的，英文领域也应该没有这么大的指令集。现在，我们开始让大型模型具备各种能力，这就是大模型工作机制。

我们发现出现了一个有趣的问题：这种工作方式并不像专家的工作方式，反而更像博学者的工作方式，并向我们带来了两个巨大的挑战。

第一个挑战是每个人都需要迅速成为博学者，否则就会被善于使用 GPT 的人打败。

举例来说，阳老师曾认为，心理咨询这个行业因为需要反复与人打交道，所以是最难被 GPT 替代的行业。然而，自从我和团队开始研发大型模型后，我现在的看法是，心理咨询行业反而可能是被 GPT 迭代最快的行业。

为什么会这样呢？众所周知，心理咨询师的成本非常高，而训练过程又非常长。一个优秀的心理咨询师可能需要花费十年时间才能培养出来。如果你在北京寻找这样的咨询师，可能一周只能咨询一到两个小时，而你需要为这一到两个小时付出的成本，极有可能在 1000 到 2000 元之间。一年下来，你可能就需要花费一两万块钱，并且你还不能 24 小时获得咨询师的指导。

然而，像阳老师这样的大语言模型，可以更好地完成人们需要的情绪安抚功能。

在未来，这些大模型将具备巨大的可能性。在星期天的人生发展咨询师集体培训上，我给参训的咨询师们布置了一个任务，那就是集体合作撰写一份人生发展咨询师的专用指令集合。假设这些指令集合有 420 条，当我们完成撰写之后，初级人生发展咨询师的工作可能会被这些大模型取代。

我们需要明白，在任何领域，只要你掌握了写指令的方法，例如，如果你能编写这 420 条来自各种实践经验升华和工作流程总结的指令，则大模型会初步具备专业领域的能力。这对我们的世界将造成极大的影响。

无数以符号语言为主的职业，如心理咨询师，甚至可以说是以书面语言为主的众多职业，将面临这样的冲击。只需要一个大模型和 420 条指令，就可以开始掌握某个领域的基本能力。

所以我们的整个学习方法论，要面临的是一个无比巨大的挑战。

那么第二个大的挑战是什么呢？那就是大模型 GPT。在掌握了 420 条心理咨询的指令之后，大模型实际上很容易取代初级的心理咨询师，比如那种接受电话热线的咨询师。你会发现，未来大模型做心理咨询的效果，必定会比利用心理热线电话的效果更好。然而，其效果无法与顶尖级别的咨询师，比如拥有几十年经验的阳老师相媲美。这就是我们在 GPT 时代面临的第二个巨大挑战，就是如何在大模型的冲击之下，让大模型本身具备专家级别的深度和洞察力。有人可能会觉得这是做不到的，但阳老师今天所示范的学习方法论告诉你，大模型是可以做到的。其实，大模型不仅能实现电话心理热线的水准，它甚至能做到一些非常高级的事情。这就是阳老师今天为什么会说，错过这个讲座的同学可能错过了一个亿，这些都是阳老师的一些独特见解。

好，这就是我们接下来要分享的。接着我们来看看大模型如何实现这些高阶的技能，这实际上是基于它的底层能力。

那么大模型最关键的底层能力与学习相关是什么呢？其实这里有三个关键的能力。在讲这三个能力之前，我们先要谈一下在 GPT 时代，为什么说博学者对专家更有利，为什么博学者比专家更有优势？

实际上，我们的标题最早叫做推理，而不是学习。人类的学习其实存在两种模式，第一种是推理式的学习，它是非常经典的学习现卖的模式。大模型就是走的这种路径，你需要给它提供一些示范的数据，这些详细的数据能让 GPT 生成的质量非常高。所以，阳老师称之为推理式的学习，它就是立即学然后立即用。但是在 GPT 时代，我们人类的学习方式又是什么呢？

我们的学习方式实际上是即时的学习，而且以死记硬背为主。在 GPT 前的时代，在 AI 还未出现的时代，即 2023 年 3 月 15 号之前，专家之所以能够征服非专家，其实就是因为他们对这一领域熟练掌握了大量的硬知识，这些知识成为了他们的库存记忆。

在上一节课中，我们介绍了一部分知识，被我们称为「长时工作记忆」。一个专家在某一个领域工作时间很长，他的大脑中，就像在黑质液旁边，存储了成千上万的信息，可以方便被提取。

我们可以借用电脑来理解，这就如同电脑的缓存，可以在第一时间从缓存中加载到内存条中。这种学习方式就是专家依赖的记忆式学习，偏向长时工作记忆。但值得注意的是，在 21 世纪 GPT 时代，记忆式学习似乎失去了它的意义。因为目前 GPT 所具备的长时工作记忆能力、短时记忆能力和工作记忆能力都不强。这个问题在 GPT-5.0、GPT-6.0、GPT-7.0 的版本更新中得到了解决。

事实上，GPT 现在最强大的能力并不是记忆式学习，而是推理式学习。也就是说，它能够在实时对话中，逐步生成出我们想要的答案，帮助我们更快速地去学习。

因此，这种学习模式反而更有利于博学者。博学者能很容易判断信息的真实性，而一个依赖记忆的专家却不太容易做出判断。这点我相信大家已经明白了。

我希望大家一定要购买阳老师的那本书，因为这本书总结了 100 个学科，这是我们所说的无缝岔路广告。这也相当于是 GPT 时代的一个精神象征。

#### 5.1.2 GPT 在学习上的三大核心能力

推理式的学习是以推理能力为基础的。阳老师在他的人性系统论中总结了这三种能力。我们人类通过一系列的感知符号，进行以下三个操作。

第一个操作叫做「对比」 ，比如，这个是不是黑色，而是白色。这就是对比。

我们人类通过对比，学会了大量的概念。任何一个概念都是建立在对比的基础上的。如果不理解什么是白色，那么就无法理解黑色的概念；如果不理解粗糙，就无法理解精致的概念。

如果不了解白天的概念，就无法理解黑夜的概念。这是第一种操作。

我们在进行推理的时候，第二种操作是什么？它叫做穷举，亦称列举。举例来说，我们所知道的一周有 7 天，包含了第一天、第二天、第三天、第四天、第五天、第六天以及第七天。再例如我们手中的手掌，有 1 到 5 五个指头，这些基本的列举操作也是我们人类底层的能力。

第一种操作和第二种操作相对容易理解。

第三个操作，也许会让一些人觉得难以理解。那么，第三个操作是什么？它就是反事实推理，也就是我们常说的「如果… 那么」。

你会发现，第一种和第二种操作其实是脱离了情景的，没有嵌入太多的上下文信息。而我们人类生活在时间中，活在空间中，是寻求意义的动物。我们受到自己的情绪影响，我们是受到他人的人际关系给我们带来困扰的，我们是容易感到烦躁的有血有肉的机器人。

那么，这一操作过程在我们的大脑中是如何完成的呢？那种最小的操作又是如何嵌入到我们人类的情景信息中的呢？实际上，这个过程就是反事实推理。

反事实推理是我们人类三大基础操作之一。我们通过模拟世界，预测如果在某种情景下，我会有怎样的行为，这就很好理解了。

基于此，我们可以看到 GPT 在学习上的三大核心能力，并非强调死记硬背，而是强调现学现用。这三大能力，即对比能力、列举能力和模拟能力，是建立在人类三大推理基本操作之上的。我们将会重点介绍这三种能力的特性以及其原理限制。

对于各类事物的比较，大语言模型 GPT 的能力大致上可以打 80 分，准确度相当高，仅次于我们前一课程讨论的文本统计能力。GPT 的比较能力之所以强大，根源在于其本质上是一个向量矩阵。这个向量矩阵是通过经过数千万次的推理操作生成的。在这些推理操作中，大多数都是执行对比操作。所以，GPT 的对比能力非常强大，准确度极高。

人类对比实质是对概念背后的本质进行比较。但是，GPT 的比较方式和人类的不同。例如，我们人类在比较一位男老师和一位女学生时，我们会基于性别，年龄，外貌等面向去做比较。然而，这些比较是基于人类现实生活的全面思维。相对应的，GPT 的比较则在一种完全利用人类未发现的微妙关系的向量空间中进行，甚至能够比较出科幻小说中的前生、现生和来生之间的关系，这使得 GPT 的对比能力相当强大，并且会产生非常神奇的影响。

在实际应用中，GPT 对比事物能力可以高达 90 分，无论是对比概念，对比人物，对比事件，对比文学作品，还是对比艺术作品等等。然而，GPT 在对比能力上也有一些限制。首先，它有知识更新限制和数据偏见，同时，缺乏基于常识的推理能力。其次，一旦需要处理的文本变长，GPT 就可能因其较差的记忆能力，使得最终的比较结果变得不那么准确。

因此，尽量让 GPT 在其工作范围内进行对比。例如，如果你希望得到一个重要的答案，尽可能地让 GPT 在四步内得出答案；如果超过四步，未来的视觉结构可能会受到稍微的影响。

好的，我们现在继续。GPT 的枚举或列举能力实际上与其数据集有关。因为 GPT 已经拥有了整个互联网上 20% 左右的关键知识，这 20% 的关键知识除了包括人们欣赏的文学作品外，还包含了一些我们日常很难掌握的知识载体。

比如说，GPT 拥有 GitHub 上的所有代码，如果你是个编程新手，查看 GitHub 上的代码可能会让你感到困惑。类似地，如果你对音乐一无所知，你可能也会觉得阅读乐谱很困难。然而，GPT 不仅拥有 GitHub 上所有的代码库，也拥有世界上最主要的音乐网站的曲谱以及歌词库。此外，它还拥有大量的文学作品，许多书籍，以及众多学术论文库。这些信息已经通过重复的计算形成了一个庞大的知识矩阵。

在这个知识矩阵中，如果一个人想要快速生成新的列表或清单，受限于他们已有的知识结构，这将会非常困难。然而对于 GPT 来讲，这只是一个简单的符号搜索过程，因此它生成的结果极为理想。

例如，我们可以给 GPT 一个指令，让其列举出某个年代美国的名人。这对我们来说需要经历很多步骤，但 GPT 可以做到，而且准确度大约达到 80-90%。

此外，比如我们要出数学题，以往我们需要花很多时间设计题目，但用 GPT，我们可以直接给出指令，比如请编出一套由易到难的数学题，并需符合初二学生的学习水平。这在一定程度上实现了个性化教学。传统的个性化教学通常是使用预先准备好的题库，但现在，你可以让 GPT 为初二学生生成 10 道数学题，然后让你的孩子去做。做完后，你可以告诉 GPT，他生成的题目难度过大或过小。这样就能根据反馈来调节题目的难易度，进一步提升个性化教学的效果。

我的孩子在初二，他做题的表现并不理想，特别集中在某几道题目上。我想要你能生成 10 道比他做的题目稍难，以及 10 道稍易的题目来提升他的成绩。在这样的请求下，我们在实现一种超越传统教辅老师的方式。这就体现了对比能力。

此外，对比能力还包括解决一些算法和密码问题，这是我们人类相对较弱的能力。人类通常不擅长处理感性之外的符号，例如代码、数学、算法和密码，这些理性的能力在人类中不常见。

我们有一群被称为数学家的专门参加数学奥赛的人，有一批专门从事算法的人，他们被称为算法工程师或算法专家，我们也有专门研究密码的密码学家，他们帮助我们解决一些复杂的问题。然而，在我们的日常生活中，我们也大量使用数学、算法和密码等。在这部分，GPT 可以帮我们无限地列举和组合，这是他的强大之处。但仍受到计算资源和非专业部分算法的限制，尤其是一些极小众的问题。

让我们记住一点，GPT 对那些在论文、书籍、维基百科中被充分训练的算法有很好的处理能力。因此，我们最好尽可能地用英文向它提问，因为许多专业的算法并未翻译成中文，即使翻译成了中文，也可能无法准确地翻译回去。

许多算法，甚至包括一些特殊符号，在使用中文进行提问时，效果可能并不理想。如果你向它提问：「请给我列举人工智能领域的一个算法」，实际得到的结果可能比较一般。如果你用英文询问：「请列举自然语言处理中，经常用于将字词转换为向量的 10 种算法」，你会发现它的回答会更为精确和理想。

让我们首先理解大语言模型 GPT 的一些限制。它无法处理大规模的问题，会表现出不一致性，并且对于问题的理解存在一定的局限。

再来看它的第三项能力 —— 模拟能力，这项能力大约是 70 分水平。我们的介绍会按能力的强弱进行，首先是强大的对比能力，其次是较强的列举能力。

但是，当涉及到 GPT 作为一个人工智能的模拟能力时，它的表现就没有那么强大了，但已经达到了我们人类可以很好地使用的程度，大约是 70 分水平。

以设想性任务为例，例如，让它设想某个历史事件的可能结果，设想它成为文学作品中的主角，设想它实施某项经济政策，进行某项理论假设或进行人际关系分析等等，这些都是它的模拟能力，与前面的能力有很多相似之处。

接下来，我们来了解 GPT 模型在学习方面的三大核心能力，其中 GPT 最擅长的是推理式学习，这种学习方式赋予了它像学者一样强大的理解和推理能力。

我们将推理学习和 GPT 的功能结合起来，把它总结为对比能力、列举能力和模拟能力三大部分，它们背后实际上都是 GPT 的三种符号基本操作：对比操作、列举操作和反事实推理操作。

在 GPT4.0 版本之前，GPT 在这三大方面的能力都只能说一般，无法与人类相比，特别是在反事实推理能力（模拟能力）方面。但是，进化到 GPT4.0 版本后，大多数时间内，它已经达到了一个大学本科生的水平。虽然还不能达到像莎士比亚那样的推理水平，但通常已经能胜任一个大学本科生的推理任务了。

至此，我们第一部分的内容结束了。我们今晚的重点非常多，但这只是我们整个主题的一部分，如果写成书稿，可能会有 3 万字的内容。接下来，我们将会进一步让大家意识到在 21 世纪，传统的专家式学习受到了 GPT 的巨大挑战。我们每个人或许都需要像阳老师一样适应这种变化，成为一个终生的学习者。

### 5.2 成为博学者：一种新的学习方法论

#### 5.2.1 如何从专家到博学者

在第二节课，我们正式提出了一种新的学习方法论。在 21 世纪的 2023 年 3 月 15 日，我们探讨如何更快、更好、更高效地成为一名博学者，这就是我们的新学习方法论。接着在第一节课中，我们回顾了上一节我们介绍的 actor 框架，我们首先用心理学和 actor 的框架来理解心理学专家。同时，阳老师在前面的课程中也给大家介绍了心理咨询师的特定技能集合，是为我们理解这些专业人士的特质提供了指导。

无论是心理咨询师、人生发展咨询师，还是计算机科学专家，各个领域的专家都会使用书面语言和符号语言。阳老师已经很明确地向大家解释过，如果我们想让大模型，例如 GPT，具备心理咨询师的某些能力，我们需要将其整理成一个包含 420 个指令的集合。按照这一方式，我们的大模型就会初步具备心理咨询师的能力。

在整理模型的过程中，我们可以使用 actor 的框架来帮助我们，这是整理过程的最关键、最微妙的一步。如果你不太了解 actor 框架，你可能会认为它平平无奇，但实际上，这个框架是阳老师的一项重要发明。它用来帮助我们理解一个专家在某个领域的知识结构和内容。

在心理咨询中，一位心理咨询师所持有的内隐知识，我们并没有办法清晰地展现出来，这是一项我们暂时无法做到的任务。

作为阳老师，于 2023 年 3 月 15 日宣称，训练人生发展咨询师是一项非常复杂且具挑战性的任务。我甚至需要邀请他们来我家吃饭，每个月参加我的聚会，以便更深入地观察和学习我的咨询方法。然而，我深知，这种对内隐知识的传递过程，以人工智能的视角来看，是一个非常低效且漫长的过程。

我曾告诉每一位咨询师，你们必须跟着我学习，这个过程可能会持续 3 年，甚至在 3 年学习后，你可能还需要自行深度学习 10 年，才能成为一名优秀的咨询师。我们人类的一些高级知识难以掌握，原因在于它们大多依赖于上下文和特定情景，很多细节是无法通过语言来完整传达的。

在 GPT 的时代，我们遭遇了一次颠覆性的革命。GPT 并不关注咨询师具备何种专业知识，而是专注于对话过程。这种一轮一轮的对话过程，实际上将咨询师脑中的内隐知识逐渐曝光，这也是为什么我如此重视 42 这个网站。

在一次会议中，我被一些中国顶尖的认知科学家邀请参加，但由于时间原因，我无法参加，因此我将网站的链接发给他们查看。但由于该网站目前流量过大，一度无法正常访问，这也提醒我需要为服务器增加更多的流量以应对日益增长的访问量。

在与 GPT 模型对话的过程中，我们其实都是在逐步揭示我们的思考过程。当这些初步揭露的思考过程被外显，对认知科学家来说，他们就能更清晰地理解以往的那些内隐知识、思考和认知已经转变成了外显的形态。

我们会发现，每个人在对话过程中的逻辑都是有所不同的。例如……

一位同学可能更喜欢一种对话的方式，而另一位同学可能更喜欢另一种对话方式。在这个情况下，我们需要对不同的对话方式进行统一的编码，这样作为认知科学家，我们可以进一步发现其内在规律。这个统一编码的框架就是由阳老师发明的 actor 框架。

你会发现无论什么证据，比如一句话和它的答案，都可以被我们的 actor 框架兼容，这提供了一个统一的编码框架。这对从专业人士到博学者非常关键，其中的逻辑是将传统专家的内隐知识化为人与人的互动。现在我们做了一个技巧，我们将人与人的互动替换为人机互动。

这样，专家的内隐知识就不再是人与人的互动，而是专家与大型模型（如 GPT）的对话过程。这是非常关键的第一步。实现了这一步后，无论是专家还是机器人，我们都采取了统一的编码框架，这个框架就是由阳老师发明的 actor 框架。比如，一个心理咨询师把他所有的心理咨询流程都用人机对话的方式输出，然后把他做了 100 个个案的所有对话流程输入，再用 actor 框架整理，其结果能够整理得非常清晰。

这就是第二步。非常关键的第三步是要慢慢的把专家的知识变成大模型能够初步拥有的知识。

更关键的是，当我们具备了心理学专家的知识后，我们发现他拥有的这些专业知识和内容知识可以总结为 420 条指令集合。这一发现在认知科学和人工智能领域被称为「方法推理」，最关键地方来了，我们把它所有的内容知识编码成 420 条指令集合，然后发现这些指令在上下文任务中可以重复使用，且无需任何改动。

1『目前对「一个领域 420 条指令」全覆盖的理解：每条指令在 GPT 内创建一个特定情景的上下文，这 420 个情景（上下文）可以覆盖掉该领域所有的知识点。最关键的是，这 420 条指令可以不断迁移到不同的领域。（2023-10-11）』

在此过程中，我们只需要对角色进行轻微的替换。比如，我们之前设定的是一名心理咨询师对文本进行分析总结，现在我们可以做一个非常微妙的替换，我们只需要把这个角色替换成一名计算机科学家。

如果你现在需要分析文本得出结论，你能理解吗？这就是大语言模型最神奇的地方。

其实，它的能力并不局限在你所提供的 420 条心理学领域的指令，它具备非常强大的推理能力。这种推理能力需要以昂贵的 GPU 算力作为代价。这就意味着，它突然之间就获得了计算机领域的能力。比如说，作为一名心理咨询师，我仅提供的是关于心理咨询的对话语料，而作为一名计算机科学家，我提供的是计算机代码，但这个大模型会自然而然地具备推理能力。你们理解了吗？所以，最神奇的事情正在发生。

然后，当这种事情发生后，我们不确定是怎么发生的，学术界并没有一个非常清晰的答案。泛化推理是怎么来的？现在我们看到的大模型就像魔法一样，突然间拥有了强大的泛化推理能力。

学术界对这个问题各有各的解释，这部分我就不详细介绍了。对于我们学习者来说，我们刚开始介绍的大模型时代，对我们的学习过程有着巨大的影响。实际上，我们普通的学习者和大模型所做的工作十分相似，我们都是从专家向博学者的转变。

比如说，作为一名心理咨询师，你需要将你十年的工作经验按照 actor 框架整理成 420 条指令。

然后我们该怎么变成博学者呢？我们可以看一下这 420 条指令，有些可以非常容易地嵌入到计算机领域。比如说从一名心理咨询师，突然变成一个一流的计算机专家，你会发现 420 条指令中有一部分可以非常容易地迁移过去，这些指令通常都与元认知相关。有些则不那么容易迁移过去，这就需要我们做一些处理。

一方面，我们需要对传统的心理咨询领域的知识集合进行深度加工，进行二次加工，让它逐渐变成更接近元认知的知识模型，这样更有利于知识的迁移。

另一方面，由于无法让它达到完美，我们干脆将其作为一个例子，作为一种特例。因此，我们悄然发现，我们已经具备了计算机编程的能力，非常神奇。从一位拥有心理咨询指令集合的心理咨询师，我们突然间变身为博学者。我们可以用自己的 420 份指令集合，复用到经济学领域，复用到计算机领域，以及赋予律师领域和营养学领域。

那么这是何种原理呢？

其一就是逻辑。它与传统逻辑的真正关键差异是什么？阳老师给我们引导的新的学习方法论，实际上是应对两个关键的挑战。有的人非常狂热，比如某某，他建议你将已经拥有的任何经验全部抛弃，然后直接使用 GPT。但这种做法实际上相当于把你过去学习中获取的专家能力抛弃了。这种看似无底线的学习方法实际上基于一种逻辑，即我们使用自身已有的辨识能力和某一专家领域的能力为基础，提炼出了相符合的框架，然后再替换不同的要素。

大多数情况下，对于一些非常通用的元认知级别的指令，我们只需要替换角色就好了。有时候，仅替换角色不够，我们还需要进行一些修正，如替换任务，成为新的上下文，最后我们就具备了计算机领域的能力。

希望所有聪明的同学都能理解这里的学习方法论。对于那些没有听懂的同学，希望聪明的同学能以简单易懂的方式向他们解释。这是今天最神奇的部分，也是阳老师颠覆性的学习方法论。

下面内容是关于大语言模型、如何从人工学习过渡到机器学习，以及如何解决在各领域迁移知识的相关问题。相信聪明的同学已经理解我们现在已经从传统的个体学习转向了人机互动式学习。现在的一个主要任务就是，如何能让我们快速地具备无数领域的专业能力？

这些能力，的确是以你在一个特定领域的专业能力为基础。例如，我们可以把它看作是一个可以复制的模板，可以用在各个不同的领域。比如，你本身是心理咨询师，但如果你想把已有的知识和能力迁移到经济学领域，这就可能会遇到知识迁移过程中的损失问题。可能并不能够在经济学领域能够完全成功迁移。在大模型中，我们称之为知识迁移或推理放大。

很多时候，我们不能完全成功的迁移知识，这就需要我们做一些额外的工作。我们需要做什么呢？其实主要是两件事情：

一是如何帮助我们把已经掌握的专业知识迁移至新的领域。比如，我们现在是一名心理咨询师，我们需要把专业知识迁移至经济学领域。若将 420 条指令迁移过去，可能只有 42 条能用，显然损失太大。

我们下一步要解决的关键难点就是用何种方法或技巧降低迁移的损失，即把从一个领域到另一个领域的知识迁移的成本降到最低。直到我们能让原本的 420 条指令迁移过去后，能快速把经济学领域这个 80% 的指令用起来，并逐渐达到专家级水平，这大约需要 300 多条指令。

要解决的关键难题，一方面是如何发现一个新领域的关键知识。我们作为心理学领域的专家，对于心理学领域的专业知识确实是了然于心，但是我们现在在经济学领域，我们是新手，这个时候我们是否很容易被 GPT 等专业知识搞混，不得而知，这是我们面对的第一个难题。

关于大语言模型（例如 GPT）的使用，我想提出两个主要的挑战。第一个挑战是「关键知识的发现」，而第二个挑战就是「关键知识的组织」。

比如以心理学为例，经过十几年的学习和研究，我们已经能理解心理学的学术脉络和知识组织结构。但是，如果试图应用语言模型在经济学领域，我们如何快速理解并掌握经济学的知识组织结构？理解各学科的关键知识组织是我们面临的第二个挑战。

#### 5.2.2 如何更好地发现新领域中的关键知识

那么，如何在新领域中发现关键知识呢？我的建议是，先从易于验证的知识开始，避免过早地陷入复杂的验证任务中。例如，我们作为心理学专家，如果需要学习经济学，诸如基本概念、重要人物和事实信息这些内容是容易验证的。这个方法应该为你提供一个可行的方式来处理这一挑战。

然而，一般同学可能会从复杂的问题入手，如投资和炒股，尽管它们都是非常复杂且难以处理的问题。对于这种情况，我建议从更容易验证的信息入手。比如，让语言模型列举经济学中使用的关键数据或关键指标。一旦列出这些指标，你就可以从你已经知道的指标开始，例如，你可以要求模型列出增长率最高的十家上市公司。这种信息是我们可以很容易获取和验证的。

总的来说，使用大语言模型时，识别并理解关键知识是一大挑战，而我们可以通过从易于验证的信息入手、逐步深入到复杂的知识区域的方法来解决这个挑战。

首先，通过列举并进行初步验证，你可以使用我们之前提到的对话技巧来确保你的答案是正确的。例如，你可以询问，「我的答案是根据什么算出来的？」可以请求对方注明他的计算方式。

其次，你可以进一步提问：「哪家美国上市公司的市场增加速度最快？」然后，请求他告诉你，「这十家增长最快的公司中，哪些被媒体如纽约时报、华盛顿邮报等主流媒体报导最少？」这些被主流媒体低调报导的公司是如何被发现的？

这类公司的市场增长速度快，但又被媒体报道少。那意味着你应该马上投资这些美股。这正是我在信息分析中所讲的趣味性。你可能会问，我是如何得出这个问题的呢？实际上，我是通过前置的问题得出的，第一个问题即是「请告诉我美国上市公司的市值中位数是多少？」这个问题是绝对准确的，然后我会问「市值大于该中位数的公司有哪些？」这是第二个问题。

接下来，第三个问题你会问，「这些市值较大的公司在过去三年的增长率是如何的？哪几家公司增长最快？」然后你再问，「增长最快的这些公司，哪些被媒体报道最少？」尤其是像 GPT 语言模型训练的数据，包括 Twitter 的数据。而联系到自马斯克与欧盟公司争执后，他们不再拥有 Twitter 数据，不过他们在早期是拥有 Twitter 数据的。所以你可以问，「在 Twitter 上被提及最少的公司是哪些？」

如果发现某个公司不被大家关注，且该公司市值大，市场增长快，那这家公司可能存在重大的套利空间，大家明白这个逻辑吗？

所以，这个领域新知识的发现，我们应当遵从一个原则，从容易验证的事项到不容易验证的事项。如果你直接问，「神灯，请告诉我，哪三支股票最具价值」。你会发现这个问题是不容易验证的，只会得出不准确的结论，大家明白了吗？希望这个步骤可以帮助你认识到如何有效地发现和利用新领域知识。

好的，现在我们继续讨论下一个话题，这个话题是关于元反空的监测，但实际上，我们一再提及的是元反空的二阶操作。我们知道，GPT 的理解和操作能力极强，准确率在 70% 以上。对于模拟能力，准确率是 80% 左右，列举能力的准确率接近 90%，还有比较好的对比能力。但是，人类大脑最神奇的地方是什么呢？

我们人类能够产生无穷无尽的复杂能力，并不是因为我们的大脑拥有高度复杂的机器构造。我们人类的大脑以及神经元所进行的计算，和 GPT 的计算方式是一模一样的，因为他们都是基于神经网络。其中，人类的神经网络是基于化学机理，神经元主要依赖血液和神经递质；而 GPT 是基于硅芯片，主要依赖 GPU 的计算能力。虽然神经元无法进行高度复杂的操作，我们却可以通过他们发展出极其复杂的能力，比如我们有时将这些能力称之为爱情，真理或是善良。

然而初级审计员对于这些复杂能力可能一无所知，也同样地，GPT 为何具备如此强大的能力？原来，都是因为神经元具备卓越的递归机制。这种递归机制以单一操作为基础，经过一层一层的组合与复制，最终变得极其复杂。

所以，我们需要明了，GPT 本质上是一台推理引擎，最擅长的是从现有的知识启动并进行推理式学习，而不擅长于死记硬背式的记忆式学习。因此，我们应该尽力让它进行更多的复杂操作，其中一个显著的操作就是二阶操作，这是我将在后面为大家详细讲解的一个重要内容。

当然，现在我们无需为了理解而深挖每一个细节，过多的信息可能会使理解变得复杂。我们将在后面适时进一步讲解相关概念。

理解了这些后，我们现在让它升级为二阶操作。这个二阶操作究竟是什么呢？在后面的讲解中，我会引用一个人生发展咨询师培训的例子来进一步讲解这个二阶操作，这个例子是一个非常典型的二阶操作。好的，让我们继续往后看。

#### 5.2.3 如何组织关键知识

接下来我们将会探讨如何组织关键知识。首先我们要解决的是一阶操作，即头部结构的建立，接着考察的是更深层次的要素结构、步骤结构，这二者相当于我们步入新的领域，例如经济学领域，在此领域中，我们需要回答三个问题。第一，关键知识的组织方式。比如在组织经济知识时，我们可以按照最重要的经济学家，最有影响力的经济学家，最反常识的经济学家，最不为人知的经济学家，或者是最小众的经济学知识等方法去组织，这种组织方式我们称之为头部结构。

接下来，第二大类是要素结构，具体就是研究经济学可以分成什么样的层次。例如经济学可以分为微观经济学和宏观经济学，再进一步，微观经济学又可以分成什么样的层次？不断地去追问，用这种方式去理清经济学的层次架构。

例如，我们可以利用这种方法去衡量像 GPT 这样的大语言模型是不是在胡说八道，以及帮助我们更清楚地理解经济学的层次。要素也是一样，就是我们需要去弄清楚某个目标是由什么构成的。

另外一种方式就是步骤，例如我们要通过经济学的研究生考试，或者通过经济学的博士考试，或者发布一篇经济学论文，那么这个过程中的最佳步骤是什么？我们应该先做什么，后做什么？然后我们可以结合之前讨论的各种技巧进行进一步的深入探讨。

例如，有一种技巧叫重复控制指令，就是我们可以通过让 GPT 重复三次相同的命令来强调或是检测它的理解和推理能力。

此外，我们还可以通过实例来应用我们的知识和技巧，比如请 GPT 给出伟大的经济学家的实例，或者询问有多少 20 岁就发表了伟大的经济论文的人。然而，20 岁发表伟大的经济论文的人其实是非常少的，对于大多数人来说，这是一个非常具有挑战性的任务。

扩宽年龄限制到 24 岁，估计可以列举出极少数发表过极其杰出的经济学论文的人，可能不到 10 个。但是你作为一名本科生，你的经济学知识显然不足以与这样一位 24 岁的经济学专家相提并论。

然后我们可能会去请教一个才华横溢的年轻人，他是如何做到的，是先做什么再做什么，还有哪些领域更适合 18-24 岁的年轻人发表在顶级期刊的高级学术论文？这些步骤，你们理解了吗？

接下来我们讨论高级的策略，这种策略要求我们对关键知识进行组织。那么，我们从传统的心理学领域转向经济学领域，其实比那些依然使用传统的学习方法和思路逐步学习经济学的人要更高效，而且我们更容易产出一些伟大的作品。

在人类历史上，能够在极其年轻的时候发表非常优秀的顶级期刊的论文的人其实是少数，但是这些论文反而是最容易模仿的，因为它并不需要大量的科研经费，也不需要特别深奥的数学知识，也不需要经过漫长的经济学训练。你们明白了吗？这就是为什么今天的内容被认为是千金难求的珍贵信息。

有了前面的理解，步骤明确了，复合其实非常容易理解。复合就是对前面的这三个主题进行二阶或三阶操作，那么，一个复合结构是不是可以变成一个二阶？这个二阶结构是不是又可以变成三阶？三阶结构又能变成四阶吗？你会发现这就像一个无尽的套娃。

无尽的套娃下去，GPT 其实是一个非常强大的推理引擎。我们在日常生活中永远不可能有一个如此耐心的经济学家陪你玩这种游戏，我们也永远不会遇到掌握如此多信息的经济学家，能 24 小时与你对话。但现在，你只需花费 20 美元每月，就可以享受到这一切。

所以这是一个极其伟大的发明，你在经济学领域有了一个只需 20 美元的大师级经济学家陪练。你们明白了吗？

这个观点确实颠覆了许多传统的学习理论，但是有趣的是，老师之前提倡的学习方法并未被颠覆。这是因为这些学习方法并非源自表面浅显的观念，而是从非常底层出发。因此，我预计未来我那本书《聪明的学习者》的内容将会格外精彩，比《聪明的阅读者》这本书写得更深入。

好的，希望大家已经理解了这部分内容。接下来我们要了解更多的实用信息。前面的部分我相信大家已经理解了，接下来我们要面对的是从心理学领域延伸到经济学领域的一些难题。我们面临的主要两个难点是：如何在经济学领域中发现比较靠谱的知识，以及如何优雅地将这些知识组织在一起，形成自己的作品。这两个问题我们已经都详细讨论过。

### 5.3 如何更好的利用 GPT 学习

#### 5.3.1 已知大于未知

接下来我们要讨论的第三个主要难题是如何更好地利用 GPT 进行学习。下面是四个重要的原则，这四个原则实际上非常有趣。先看一下第一个原则，即「已知大于未知」，这是什么意思呢？

假如你是一名心理学专家，你已经学习了心理学 10 年，现在你想变成一个经济学专家或者计算机专家。那么你会发现心理学与计算机科学或经济学领域之间始终存在交集，例如心理学与行为经济学，以及心理学与认知心理学。因此，你刚开始的时候首选的应该是找到这些交集，从行为经济学领域切入，这样你更能准确地判断这个通过大语言模型 GPT 获取的知识是否准确，因为你已经有丰富的心理学知识，为何不利用它呢？

同样的，作为一名认知心理学专家，你可以判断 GPT 给你的计算机科学知识哪些是准确的，哪些不是，因为你已经拥有了 10 年的心理学研究经验和丰富的知识库。

再如，我们现在谈论的交集 —— 认知心理学，虽然知识体量会变小，但这并不重要。关键是，它是一个高质量的知识集，相比于 GPT 这样的大模型，质量比数量更重要。这些小的知识生成了 42 个新的指令，在计算机科学领域生成了 42 个新的指令，这 42 个指令可以逐渐占领计算机领域更大的地盘，比如在认知心理学领域。

关于大型计算机模型，如 GPT，其主题与交互设计与人工智能等学科有着极其密切的关系。伴随着对认知心理学的理解，再移步到交互设计的领域，我们可以轻松地判断对错。接下来向人工智能过渡，这里的知识判断同样不困难。并且，计算语言学与人工智能也有着紧密联系。计算机科学的专家系统与认知心理学的关系也是密不可分。在深度研究计算机科学后，我们的知识体系扩大了，大约占到知识总量的 50-60%。

随着我们对计算机领域的研究不断深入，我们会掌握越来越多的知识。对于阳老师而言，这就是过去 20 年间他在这些不同领域学习的方式。但在 2023 年 3 月 15 日 GPT-4 的诞生之后，我们的整个学习过程加速了，并且学习过程逐渐可视化，我们可以清晰地通过指令集合将我们的传统学习过程显现出来。

#### 5.3.2 开放性原则

至于其神奇之处，首先是原则。另一个面向开放的原则可能稍有难理解。我们需要明白大模型是由上千亿个符号组成，构筑出一个矩阵。让我们以特征向量值的概念来解读，其中包括了不同符号。在模型训练结束后，我们通常将结果称为模型的权重，即每个符号在矩阵中的权重。

这就好像我们从计算机科学的角度定义一个模型的训练结果，类似于训练出一个装载了符号权重的模型。

因此，我们会发现我们人类对学科的分类，如将计算机科学、经济学、心理学等划分开来，对于 GPT 来说并没有任何意义。这是因为这种分类侧重于人类的逻辑，而非机器的逻辑。如果我们强行将各学科划分为计算机科学和经济学等不同专业，这只是我们人类的主观观念，而不是机器的分类方式。

在模型权重的领域，计算机科学与心理学的距离也许比你们想象的要近很多，这都是因为人类具有区分性 —— 我们人类为什么要将计算机科学和经济学分开呢？

这其实起源于大学的校园布局，你会发现计算机系位于二楼，经济学系则在另一个楼，二者被物理空间分隔开，各自属于独立的实体。计算机系有自己的大楼，经济学系也有属于自己的大楼，他们分别有各自专业的教授。然而，对于 GPT 模型来讲，这些只是平等的符号，这些符号在 GPT 模型中只起到标识作用，模型权重不同，带有的象征特征也会不同。

因此，在 2023 年 3 月 15 日以后，我们所有的知识体系实际上都需要重新构建，我们不再是从人类视角出发，而是从 GPT 模型赋予的视角出发，我们不能受以往知识体系的束缚，所以阳老师将这称为 GPT 时代学习的第二个重要原则，即开放性原则。

#### 5.3.3 高阶大于低阶

我们接下来来看第三个重要的原则，即高阶大于低阶。这其实是表明，虽然我们人类以及 GPT 模型中的神经网络执行的一些操作其实都是简单的如比对、列举等，但我们人类拥有的迷人的心智则是源于一层一层的叠加、递归与组合，最终冒现出极其复杂而迷人的性质。同样的，GPT 在一线操作其能力并不突出，但在 2 阶、3 阶、4 阶、5 阶、6 阶、7 阶、8 阶、9 阶时，它所展现出的能力会极其惊人。举个例子，我在上个星期的人生发展咨询师的培训中就提到这一点。

我们现在想要增强我们的咨询能力，我们的策略是，比如说我建立了一个人生发展咨询师体系。这个体系之所以被建立，源自世界上第一个将自己的咨询对话实录总结出来的人。大家知道这个人是谁吗？

在人性大师课上，阳老师向我们回述了罗杰斯在上个世纪五十年代，即录音设备刚刚发明的时期，如何首度使用录音设备，记录他的心理咨询过程。罗杰斯将所有的记录汇总，形成了一份历史经典文献，名为《罗杰斯咨询对话实录》。

那么对于我们这些刚入行的咨询师，如何靠近这位伟大的心理咨询师呢？方法其实很简单，我们先进行一阶操作，就是学习。例如，我给你罗杰斯的咨询文本中的 40 段（假设）来学习，完成后，从这 40 段话中，列举你认为最好的 10 段。这就是我们所说的基本操作，就是列举。

完成列举 10 段最好的内容后，再进一步告诉我，你认为最差的 10 段是什么？这样，我们就为 GPT 准备好了 40 段逻辑咨询对话输入，分别理出 10 段最好和 10 段最差的部分。

第二阶段的操作是什么呢？我们策划的第二个步骤实际上是，基于这些最好和最差的列表，对罗杰斯的咨询方法进行深刻的学习和理解，找出其中最重要的特征。最后，借助这些关键特征，GPT 就能快速地整理和重组信息了。

首先，我们要给四个特征分别赋予 25 分。然后，我们要评估在最好和最差的对话时段中，GPT 模型的表现。请注意，数学操作是 GPT 模型的一个基本能力。与我们人类相比，它显得更加强大，因为它不仅掌握了自然语言，还熟悉各种如数学语言、编程语言、符号语言等多元语言。

在评分完毕之后，下一步，你需要将你的咨询语料输入到模型中。假设我是一名咨询师，今天我就做了一段咨询。这是我和来访者的一个交流过程。请根据你刚刚设定的评分标准，对我们的对话进行打分。

做完评分之后，我想请你告诉我，现在离卡尔·罗杰斯的水平还有多远。这其实是一个对比过程。然后，我会再问你，假设我是罗杰斯，并且我想提高我的咨询对话能力，我应该怎么做？你会发现这个操作开始变得更具指导性。接着，我们继续提升到二阶，三阶，甚至可以提升到 3000 或 4000。

二阶后，你会发现它已经变得非常实用。你会有一个 24 小时陪练的咨询师。他可以是罗杰斯，也可以是米卢沁（家庭治疗的奠基者），还可以是阳老师，等等。只要是历史上将自己的咨询对话实录公开的咨询师，GPT 模型都可以模仿。罗杰斯和米卢沁的咨询对话实录是我训练人生发展咨询师常用的素材。

那么，二阶操作完成后，你会发现 GPT 模型已经变得非常生动，与我们原意的咨询实战训练有了显著不同。它真的能帮助你进行训练，真的能改善你的咨询能力，并且它可以一直持续工作，只会消耗你的 API 容量。

神奇的是，我们还可以引入更高阶的操作，即三阶操作。此阶段，我们可以开始引入更复杂的任务。例如，我们需要用到刚才讨论的逻辑式框架去评估我们的咨询对话。然后，你需要模仿罗杰斯的框架，然后在这个框架的基础上，列出 10 个类似的框架，并在这些框架中进行咨询能力的训练。每个框架训练的能力都是不同的，这确实是一个挑战。

再使用这 10 个不同的框架对咨询对话实录进行评分，这就变成了 3 阶，即 3000 个不同的评分。在训练了这 10 个框架后，你可以将这些框架应用于向量工作。这是一个罗杰斯的过程。在这个过程中，你可以继续进行此种操作。

如果你认为这 10 个框架合并为一个的话，那么请问它会是怎样的一个框架？这个时候就又进入了升阶的过程。升阶后，请使用这个新框架对现有商品进行改良，大家明白吗？

还有一种情况被称作「套娃游戏」。你会发现其中一个游戏甚至已经远超人类的智慧。现在的 GPT-4 已经具备 3.5 阶到 4.5 阶的推理能力，而绝大多数人类所使用的推理能力主要是基于假设。在 GPT 的时代，我们所学习的概念是高阶的理解胜于低阶，这是它的含义。

我知道这个例子有些复杂，但我相信聪明的同学一定理解了。如果有同学不理解，你可以在群里让其他同学用更简单的例子解释给你。聪明的同学的标志就是智商大于 130，比如高考数学分数达到 130、135 分以上的同学基本已经理解了。

#### 5.3.4 自主推理大于受限思维

接下来，我们来看第四个关键点，即自主推理大于受限思维。人类拥有大量的先进知识，但我们必须明白，GPT 的工作原理与我们不同。我们所了解的知识，对于 GPT 来说可能是一种干扰。

我们人类经常进行一种操作。例如，我们会设计一个创造力思维测试，经常会问实验对象，例如一些大学生，一些问题，比如针头有多少种摆法和用途？

我们人类的思维是受到自身经验的限制，很难列举出一个物品（例如砖头）的所有用途，我们很难列举出 100 种、200 种、300 种、400 种、500 种、600 种的用途。在人性系统论课上，我们做过一个练习，用 100 个关键词去形容自己是一个什么样的人。你会发现很多同学在形容到第 40 个关键词以上时，就开始不知道该怎么形容了，最后基本上就变成了同义词的重复。

但是，大家知道吗？GPT 和我们人类的能力是完全不同的，它不受思维的限制，也不会受到经验的局限。GPT 没有所谓的经验，它只有权重，这些权重是通过耗费大量计算力，大约相当于 1,000 亿美元的 GPU 才算出来的。

GPT 只有这种训练好的权重模型，在这个模型中，并没有我们人类的经验。这些权重存在于向量空间，可以进行无数种组合，因此我们必须明白 GPT 的学习方式。在我们的推理学习中，实际上 GPT 有种自主推理的能力，相较于我们人类从经验出发的推理，GPT 更具创造力和强大。我们千万不要将我们的经验思维、贝叶斯思维的局限性对 GPT 的生产力产生影响。否则你反而会因为太过关注小处而忽视了大局。

在这里，我给大家举一个非常实际的例子。这个例子，也是阳老师在周日的人生发展咨询师课程中提到的。我们知道，有一个完整的心理系统理论，这个理论主要对个人的问题分成个人情绪和情境两个方面。此外，情绪又会被进一步细分，最微妙的地方是什么呢？

比如你的客户写了一份自我介绍，按照心理系统理论的格式或者说心理学的传统观念去对情绪进行分类，结果往往只会如何？大多数情况下，我们根据心理学的现有成果对情绪进行分类，最后可能得到的分类结果可能是比较主观的。

接着，我们将这个文本交给 GPT，请求它帮忙提炼出所有的情绪词汇。提炼出来之后，我们请 GPT 将这些情绪词汇按照积极情绪和消极情绪进行分类。大多数时候，人类可能就会这样处理，但做这个时候，你可能就出错了，大家明白吗？

我们通常将情绪分类为积极情绪和消极情绪，这是人类心理学家通常的分类方式，也是我们社会关于情绪的普遍共识。然而，大语言模型 GPT 可能不会受此共识的影响，因为它完全根据访问者的文本来分析，它所分类的是能够最好地代表访问者最个性化的概念化框架，也就是最能代表访问者对情绪的分类框架。

比如，GPT 可能会将某种情绪同时归为积极和消极，这种情绪在日本人中非常常见，且日本语的词汇表达了大量这样的情绪，而中文中这类词汇并不多。这就是说，GPT 甚至可能会找出我们从未考虑过的情绪分类，但这种分类方式可能最能代表访问者的真实情绪。

因此，作为一名人生发展咨询师，我们应该尝试理解并顺应访问者最真实的想法和情绪分类框架进行沟通。另外，GPT 在学习机制上和我们人类的主要不同在于它并不拥有那些所谓的先验知识，比如将人分为男性和女性。这些都只是人类的知识，并不是机器人的知识。机器人并不清楚所谓的男性、女性，积极情绪以及消极情绪，它仅仅是从符号的向量特征值出发，进行组合。这种组合通常能代表一种更正确，更先进，更前沿的知识。

关于 GPT 的应用，有一个神奇的案例。它涉及到一位获得过图灵奖的学者，他写了两本书，一本名为《为什么？》，一本名为《因果论》。他的名字叫 Judea Pearl，可以透露的是，这个案例发生在 2015 年左右。

人类的思维能力与推理能力可以被划分为三阶：第一阶为基本操作，第二阶为计算能力，第三阶为反事实推理。这个分类框架是由布尔提出的。有人向大语言模型 GPT-4 提出询问，基于这个分类框架，请推导出到第十阶的推理能力。令人惊讶的是，GPT-4 实际上做到了该推论，这个轶事在微博上由一个名为梦瑶的用户提出发表。

直观上，布尔作为该理论的提出者，可能并未预见到在逆向推理的背后，还存在着第四阶、第五阶、第六阶，甚至直至第九阶的推理过程。然而，大家发现，GPT-4 推导出的这些阶次都非常合理，并且符合科学发展的规律。这代表了人工智能时代，人工智能与人类之间共存的关系。

在 21 世纪，我们需要一种全新的思维方式。我们不能再被人类既有的经验知识所局限，而要尽可能降低对它们的依赖。阳老师曾在关于文本生成的讨论中提出，文本统计的一些结果其实非常重要，我们在生成文本的时候，尽量少使用文本统计的结果，因为完全套用这些结果产生的效果反而不好。

当我们减少对 GPT 的限制时，我们可以告诉它，你如何分类情绪都可以，只要你能给我分出十种二十种情绪，并且你在此基础上进行二级操作。也就是说，你需要判断哪些情绪是你自认为分得最好的，哪些情绪是你认为分得最差的？

然后我们在找出最好和最差的基础上，可以进行更深一步的提炼操作。这才是我们在 21 世纪更聪明地使用 GPT 的一个非常重要的原则。我们不能在已有的知识中局限自己，情绪也许存在另一种全新的可能性。这样能帮助我们人类快速填补科学知识的空白区域。

因此，大语言模型 GPT 作为一种强大的生产力工具，其重要性无与伦比。

### 5.4 聪明学习的模板

#### 5.4.1 通用学习指令

#### 5.4.1 与对比相关的指令

#### 5.4.1 与列举相关的指令


#### 5.4.1 与模拟相关的指令


### 5.5 小结

首先，对于博学者和科学家来讲，我们讨论了四个原则，这部分内容十分精彩。然后，由于时间关系，我们简要学习了通用学习模板，包括了指令示范推理，决策的决策等内容。大家对这部分先简单看一下，不用着急。在示范推理中，我看到的内容和阳老师的书稿基本是一样的，主要是一些列举推理的示例。

我们看到，这部分内容包括了与列举相关的概念，例如类比，同义词，反义词等。其中也涉及了问题拆解，组合罗列，路径归来，多维度分析，预测等具体的推理技巧。在此基础上，也讨论了如何模拟相关的反思和推理，如何进行创新性思维等内容。

回顾今天的学习，我们主要的目标是了解如何更智能地操作那些用来表示人类世界的符号。通过使用各种推理技巧来进行比较，挖掘更深层次的知识，进行反事实推理，并在反复的循环迭代中逐步升阶，从既有的领域跨越到一个又一个新的领域。这就是在 AI 新时代成为一位博学者所需的技能。

### 问答

小结完毕后，我和大家进行了答疑。我发现大家对于机器中的指令重复很感兴趣。关于这一点，这不仅是为了生成更多的答案，而是用来激活我们人类的知识储备。人类的知识储备非常强大，但如果你只看到一条信息，那么你的大脑基本上不会被激活。相反，如果你看到三条信息，你的大脑会立刻计算并识别出它的模式。所以，重复指令实际上使我们人类的大脑更活跃。希望大家能明白这一点。

好的，现在让我们探讨第二个问题：我们对各个领域的知识需要掌握到何种深度？在你自己的专业领域，掌握最重要的 20% 的知识显然是不够的，例如如果你是心理学专家。然而，我们是博学者，我们的知识不仅限于自己的核心领域，而是涵盖其它领域。你应该首先把握最关键的 20%，然后逐步扩展到 40% 到 60%。今天我们应该已经讲清楚了逻辑层面，比如阳老师提供的心理学和计算机科学的例子。

关于 42 个指令，你可以在哪里看到这 42 个指令？现如今不再有那么多具体的指令，原本的具体名词已经被归纳成大类，等同于最终会编写到书中相应的 16x4 段落，最终会减少到大约 64 个大指令，因为以前的指令写得太细碎。

假设我们的教学网站已经上线了 200 多个指令，你们可以在上面查看。但如果没有相应的知识，你该怎么确定二级推理指令是正确的？在这里，我们其实是想让大家更多地了解推理的过程。

如果没有对某个领域有较深入的研究，是不是应该先选择一个领域深入学习一段时间？

肯定的，我们一定要在一个领域达到比较精通的程度，只有这样，才能谈到扩展到更多的领域。

谈到人脑记忆的必要性，它非常重要。我们很多人都会低估功人类的记忆能力。今天我谈到了大语言模型 GPT，擅长推理式学习，但是我们人类硬背硬记的能力比你想象的要强大。我们的大脑存储空间大约在 770TB，这是一个巨大的数字，大约是 GPT 的几千万倍。因此，如果你拥有这么强大的记忆能力却不去使用，而是什么东西都要查资料，实际上会让你的操作步骤变得十分缓慢。

关于人的性别，GPT 会犯一些基础错误。网络上的内容对 GPT 的准确度有一些影响，这是因为原始的语料会形成一些训练的路径依赖。

在大多数情况下，GPT 的推理能力在 3.5 阶到 4.5 阶范围内，而 9 阶在很少情况下会出现，这是一种极限的能力。与我们人类的情况类似，只有少数人具有这种超强的能力。我的意思是，大多数情况下 GPT 的推理能力只在极少数情况下才会出现超强的推理能力。至于如何在日常生活中应用 GPT，我们可以从莎士比亚的 420 个指令中进行学习。

生活就像一个大拼图，由无数领域的知识构成。可能在这个过程中，你对每个领域都只有皮毛的了解，但会有那种既能成为工作中的优秀专才，又能扮演家庭生活的专家，乃至处理好两性关系的杰出人物。

关于先前提到 GPT 的所有论述，并未对它的市值或者与前三大美股公司的上涨速度作全面的判断。我举的例子需要经过更多的交叉验证，才能得出结论。比如我提到如何高效提炼自己擅长领域的成千上万条指令，是成为领域专家的第一步。需要明白，在这个过程中，人类的模仿能力是无可比拟的。只要有人在一个专业领域中提炼并整理出一系列的有效指令，其他人很快就能模仿并学会，即使无法达到百分之百的效果，但达到百分之六七十的效果已十分可观。

因此，我相信未来这种学习方法会变得越来越流行，越来越普遍。在不久的将来，比如说 2023 年的 3 月 15 日之后，可能会有人专门开发出一款软件，将领域知识快速地转化为指令。这也将是我们课程的一部分。

首批大模型应用级专家需要深入研究，如何制定出更高效的方法。如何用 GPT 写本书，将书里的知识整理出来，以便在把版权风险降到最低的同时，也能展示出人类的创造力和重构能力。

至于 GPT 是否真的能完成这些原理，这需要我们实践去探索和验证。

概念、技术等信息性工作快速增加了对直接手感、体感、品位、实战历练、句型认知的需求。这些都是人类战役的东西而非机器人战役的东西，而这些都是大语言模型 GPT 无法提供的。不过，我们发现 GPT 的写作风格其实是有品位的，那它是如何设置的呢？它是特别借鉴了一个机构叫纽约时报，还有一个人叫 E.B. 怀特的写作风格。这样，你会发现 GPT 其实是有一种典型的写作风格。不过要注意，机器的品味和我们人类的品味可能并非同一种形式，这些都是人类的概念。

还有一个误区是，我们曾经认为心理咨询师会被 GPT 取代的速度会非常慢，但当我深入研究大模型之后，我发现心理咨询师恐怕会被它迅速超越。因为心理咨询师无法做到 24 小时在线，而 GPT 可以。相比之下，成本压力就非常明显了。想象一下，你可能要花一年 1 万块钱请心理咨询师，并且只能沟通 10 次，每次 1 小时，也就是 600 分钟。但是相对的，GPT 一年只需要大约 100 元，所以这完全是一种高效的攻击。

所以，专家的直接手感、笔触品味、实战历练、以及语料证明，这些都是可以通过大量语料训练得出来的，远没你想的那么复杂。这些，未来 GPT 都能交付。如果你用英文提问，难道不可以让 GPT 也用英文回答吗？其实很简单，你只需在指令上加上请用中文回复，你也可以让他先回复英文，回复完后再翻译成中文，这不是很常见的一种控制指令么？

对，有一个建议是在向 GPT 提问时，尽量采用低歧义性的指令，这样可以避免不必要的误解。也就是说，聪明的提问方式其实是逐层深入，逐渐提升问题的难度，而不是一开始就问一个极其复杂如「美股最有投资价值的三个公司」这种问题，影响 GPT 的回答质量。

今天的分享就到这里，希望对各位有所启发。