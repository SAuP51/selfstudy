## 20240207AI时代CH04AI时代如何开启

### PPT

P01 —— Ch04 学习目标

理解 AI 时代从哪里来。本讲的课程内容包括：

1、如何阅读《深度学习革命》？

2、深度学习的技术变革。

3、辛顿想法的转变。

P02

如何阅读《深度学习革命》

《深度学习革命》的特点：1）长篇纪实，章节之间有明显先后顺序。2）叙事感突出，文笔简练。

P03 —— 文本细读《深度学习革命》

从人物切入（辛顿）

进一步理解事件和冲突（辛顿和明斯基符号人工智能和神经网络）

厘清作者的叙事结构（围绕个人成就）

寻找他者评论（寻找领域的权威谢诺夫斯基《深度学习：智能时代的核心驱动力量》）

抽样阅读《深度学习革命》

P04 —— 深度学习的里程碑

1960 年，罗森布拉特的单层感知机。（引入了单个神经元）

1986 年，辛顿的多层神经网络。（引入了多层神经元）

2010 年之后，辛顿和学生的深度学习。（在语音识别、图片识别和语言模型上的突破）

P05 —— 深度学习历史上的三篇关键论文

1、1986 年，辛顿、鲁梅尔哈特、威廉姆斯发表了关于《通过误差反向传播算法的学习表示》。

2、2012 年，萨特斯基弗和克里哲夫斯基发表了 AlexNet 论文《深度卷积神经网络下的 ImageNet 分类》。

3、2017 年，谷歌大脑发表了《Attention is all you need》，论文中，神经网络应用了 Transformer 架构，实现了长文本模型的突破。

P06 —— 辛顿想法的转变

随着公司改进他们的人工智能。辛顿认为，系统变得越来越危险。「看看五年前的情况和现在的情况，

「有些人相信这些东西实际上可以变得比人更聪明，" 我以为还需要 30 年到 50 年，甚至更久。显然，我不再这么想了。」

2023 年，辛顿辞去了在谷歌十多年的工作，他可以自由地谈论人工智能的风险。他说，他的一部分现在对自己一生的工作感到后悔。他用正常的借口安慰自己：如果我没有这样做，其他人也会这样做。

### 音频转录

今天是过年前的最后一天，然后今天的课程内容以故事为主，但是在故事中应该会穿插一些大家对人工智能时代一些深层次的理解。所以正好是带着大家、大家带着一个轻松愉悦的心情，开始今天的 AI 时代一个过往的讲解。

今天 AI 时代在 2 月份差不多也是有三讲，这三讲是怎么分布的呢？其实整个的知识思考设计是要回答时代大问题。那么对于 AI 时代，最基本的一个问题就是这个时代是怎么来的？这个时代如何产生？还有一个基本的问题就是这个时代现在发展如何？这个时代将往何处去？

当然还有一个 how 的问题就是，我们知道了这个时代是什么 (what), 我们知道这个世界怎么来的，我们知道了 why, 但是你知道了 what 和 why, 对于每一个个体那有什么帮助呢？所以每一个个体你还是要落实到 how 的地步。How 的地方如果你学了一大堆知识，你没有落实到 how 这个层面的话，那你学的这些知识、学的一大堆的概念、学的一大堆理念，所谓的 what 和 why, 其实它是没有什么实际价值的。

所以回答大问题，回答我们在 AI 时代的大问题，你要明白 AI 时代是从哪来的？AI 时代它是如何发生的？我们同时还要明白 AI 时代现在它见证到的什么程度？还要知道大体这个 AI 时代是往哪去？我们更要去理解在这个新的时代下，作为个体的自己如何在这个时代自处？作为个体的自己如何深入的参与到其中？因为每一个个体在时代面前你其实是很无力的，我们能做的其实只是拥抱。

所以这其实是我们在二月份的三个核心大问题:

第一个大问题就是 AI 时代从哪来？

第二个问题就是 AI 时代现状发展如何？该往何处去？可能会往何处去？

第三个大问题就是在 AI 时代，作为每一个个体的求知者如何在 AI 时代自处？如何去拥抱这个新的时代？

所以这是我们在二月份重点所关注的三个大问题。那么今天呢主要围绕第一个大问题，就是 AI 时代从哪来？这个时代是怎么来的？我们最开始是怎么感知 AI 时代的？

其实大家可以回顾一下过往，基本上我们开始去对 "人工智能" 这四个字有点感觉的，其实大部分应该是在 16 年开始。16 年之后，16 年之前零零散散的会有一点新闻出来，但是真正让 "人工智能"、"深度学习"、"神经网络" 这些词活起来的其实是 16 年之后。为什么是 16 年之后呢？因为 16 年出了一个事，就是 AlphaGo 对决围棋李世石，胜利了。所以一下子在这个新闻就引爆了。

但是大家会发现，你用百度指数去搜这三个词:"人工智能"、"神经网络" 和 "深度学习", 你会明显发现这三个词在 16 年之后它的热度和 16 年之前的一个热度有一个非常明显的分水岭。但是在 16 年之前也是有一些零星事件的。你比如 14 年的时候，为什么突然爆了一下？因为当时霍金说人工智能盲目的发展可能会导致人类的灭亡。这是新闻很喜欢这种噱头，一下子也在网络上引爆了一下。然后之后 14 年底的时候，又有一个公司融资了一下，而这个公司本身就是做深度学习的。所以当时 "深度学习" 又稍微浮现了一下。但这都是小水花啊。

所以当时可能浮现的只是新闻的某个标题出来了，你可能偶尔晃了一眼。但真正人工智能相关的一大堆热词开始进入到你自己的生活中，是从什么时候开始的？其实大家可以想一下，其实是从 16 年之后的。如果你自己是做人工智能相关的从业者的话，那基本上你是在 14 年、15 年、16 年、17 年这几年时间里面，你其实是... 如果你是一个大学生的话，其实你是开始去关注人工智能的相关的算法。

我们可能会发现，你在... 如果你是一个做计算机学科的一个大学生，或者你是做一个电子相关的一个大学生，你想去找工作的话，你在 16 年 17 年那会儿之前，你可能主要刷的都是一些算法题，怎么怎么... 就是常规的一些系统算法题。但是你在 16 年 17 年之后，你需要对人工智能的一些特定的算法有些深层次的了解。比如我们今天会提到的感知机算法，感知机这种算法是一种非常古老的算法，但是在 16 年 17 年，如果你是一个人工智能专业的大学生的话，你在面试题的时候就会考感知机这个算法，让你现场面试的时候向你现场进行手工的推导。所以它其实的一个分水岭也是在 16、17 年。

但是 16、17 年你会发现，它离现在其实并不远，只是 6、7 年的光景。但是在 2023 年你会发现，突然觉得怎么 AI 发现什么都能干了？2023 年 GPT-4、航空初始之后，你发现 AI 的能力太强了，甭管是翻译、甭管是写作、甭管是日常生活中方方面面，它都能帮你去极大的提高你的生产力。仅仅是 6 年的时间，可能在 6 年... 在去年之前，你只是感觉到这个词很热，只是觉得新闻上这么说。但是在去年之后你会发现，一下子这个能力怎么变得这么厉害？

所以一方面你感觉 AI 时代才刚刚开始，可是你又感觉 AI 突然发现它变得无所不能。这种很大的割裂感，是怎么来的？其实你可以通过阅读我们二月份所推荐这本书《深度学习革命》来弥合这种割裂感。你能够从历史的角度去理解，AI 时代其实并不是最近这十年才起来的，AI 时代其实经历了漫长的几十年的水面下的一个各种科学家、各种商人的一个奋斗的一个历程。

所以这是我们读这本书你首先应该具备的一个巨大的感知，就是我们不再对 AI 时代有一种很恍惚的割裂感，而是我们开始知道 AI 时代其实离我们并不... 它的起点其实并不近，它其实也是经过了几十年的奋斗，只是在最近几年它突然以新闻的形式涌现在了我们的生活中。

所以这是我们读《深度学习革命》这本书很大的一个价值。那么本讲的... 我们围绕着《深度学习革命》, 重点从三个方面来讲解《深度学习革命》:

第一个，我们该如何去阅读这本书？

第二个，深度学习它到底这几十年它是怎么演变过来的？它的技术变革是如何的？如果大家仔细地阅读了《深度学习革命》这本书的话，其实这本书它的故事叙事性特别强，你读完之后基本上你整个的历史会有一个大概的感知。那么我今天关于深度学习这个技术变革这个历史的讲解，和这个书中有个很很大的一个区别，就是我从书中把一些关键的节点给大家提一张气领提了出来。换句话说，你读完这本书之后再听我的讲解，你会对深度学习整个历史、历史感，它中间的一些关键节点有一个其实更深层次的一个感知。

同时呢，如果你没有听过、你没有读过这本书，你直接听我讲的话，你也会大体感觉到，原来 AI 时代其实这几个节点就是这么多科学家、这么多商人一步步摸索过来的。

最后呢，我补充一个关于新顿在 2023 年它整体的一个想法的一个转变。所以我们围绕这三部分来进行讲解。

首先我们来进入到第一部分：如何阅读《深度学习革命》这本书。我们先来看一下作者，这个作者其实就是一个记者，就是一个知名的一个杂志的一个记者。但是这本书呢，他是这个记者呢，他长达了 8 年时间对这么多人的一个采访。而且他专门围绕这本书进行了 100 多次采访。所以这个书里边其实他详尽介绍了整个人工智能背后的各种各样的参与者，包括了各种的科学家、包括了各种各样的大型的巨头公司、包括了各种各样的企业家，他们的经历和他们的故事。

那么《深度学习革命》这本书，它是个什么类型的书呢？其实你如果... 其实你首先拿到这本书之后，你要看这个名的话，你还以为这是一个技术的科普书。但是如果你读完它的序言、读完它的书风书面、读完它的前序的序言，你整体的感觉其实它是一篇偏叙事型的一个... 类似于故事型的一个长篇记事类的一个书籍。所以它是按时间线展开的，章节之间它有明显的一个先后的顺序，而且你读完之后你会画面感很强，它有非常强的一个叙事的冲突感。而且作者的其实文笔还是不错的，所以整个读完这本书你基本上会对 AI 时代的一个历史有一个大概的一个理解。

那么我们该如何去阅读《深度学习革命》这本书呢？它是一个长篇记事，如果大家之前你阅读过杨老师的《聪明阅读者》这本书，或者上过阅读大法相关的课的话，大家会知道，读小说类的书基本上是按照文本细读、抽样阅读、结构阅读、再主题阅读、再去读。其实长篇计事和小说都是类似的，都是个人专注类在叙事文本下的一个分类。所以你读这种长篇纪实类的和小说类，它们的顺序是一致的。所以上来拿到这本书的话，我们会首先采用文本系读去读，就是你从头翻到尾。因为这是... 它的章节是前后... 这个又是很明显的一个先后顺序的。

第二个呢，第二部分，你读整体读完之后呢，你还可以来一个抽样阅读，就是你可能对某一部分特别感兴趣，或者说你对某一部分觉得没有理解，就觉得这个时间线怎么这么乱呢，你可以再抽样把这部分单独给拎出来读一读。所以按照这个顺序，这里主要给大家演示了文本细读和抽样阅读。结构阅读和主题阅读这里并不对《深度学习革命》进行一个深一步的阅读。

但这里给大家提一下，比如为什么不进一步的阅读... 其实这本书它的... 还称不上是一个非常厉害的杰作。所以你基本上你通过这种文本细度和抽样阅读，基本上这本书的一个大概的思想一边、那些核心的细节你都能盖得到了。你没必要再反复阅读它了。所以这里面主要以文本系统和抽样阅读来来演示这本书的阅读。

但是如果大家去以结构阅读来读的话，大家会怎么读呢？其实结构阅读，在阅读大法的时候其实给大家主要介绍过。阅读结构阅读和文本系统是一个互为表里的一个过程。文本系统是一个文本形式，而文本形式以下其实是这个作者的认知方式。比如记者他其实最采用、最常采用的认知方式是什么？最常采用的认知方式就是故事叙事，就是有很强的叙事感，叙事里边他有很强的冲突感。所以你采用这种方式，你知道他的认知方式是这个样子了，那么你基于这种认知方式你就可以去仔细的向作者提问。你比如这个作者他描述人物的时候他是怎么描述的？他这个叙事写事件的时候，他怎么... 他出出了哪些冲突？这就是结构阅读。

然后主题阅读是干嘛的？你围绕这本书，然后你看一看它是描述的 AI 时代的过去，它描述了这几十年 AI 时代的发展的脉络。那么围绕着这个脉络，是不是也有一些其他的一些人写的相关的脉络？你看一看其他人怎么写的。这是这个作者写的，然后这个作者只是个记者，有没有科学家写 AI 时代相关的书呢？也是有的。而且科学家本身就是一个亲历者，他可能写的事实、可能写的角度更不一样。所以这就是主题阅读，你能够从多本书去阅读同一个事物。

这里呢我主要给大家演示文本细读和抽样阅读。你通... 你这个大家知道他认识方式故事叙事啊，然后你... 你这个拿到这本书之后呢，你哪怕不知道他认识方式，你从头到尾把它读了一遍。那么文本细读我们该怎么去读这种啊长篇纪实类的一个、一个、一种书籍？其实还是围绕着词、句、断篇来去切入。词的话其实就是对于这种纪实类的、小说类的，就是人物，就是人物。所以你读这种书你一定要抓住它的关键人物。它的里边的细节特别多，但是你抓住它关键人物的话，其实脉络就特别多。但是你抓住它的关键人物的话，其实脉络就比较清晰了。

第二个呢，你突出它理解它的从这个词句、从这个句段这个角度的话，就是理解它的事件和冲突，然后整理看作者的偏向结构，就是你看这本书它的叙事的主题是什么呢？它叙事的结构是、叙事的基调是如何的呢？其实你发现《深度学习革命》它这本书就是围绕着这些科学家在几十年取得的一些成就围绕着这个点子展开的。

它大事件和冲突，既然围绕着 AI 时代的一些关键的成就，那科学家之间就可能会相互的掐架，相互的... 可能是一个科学家发现了一个算法，另一个科学家觉得那个算法没前途，相互的攻击。所以这就引出了从句段这个层面的话，你要理解这种事件和冲突是怎么演变的。

最终你可以寻找一些他人的评论。比如我们这里推荐了一个谢诺夫斯基，他也是在《深度学习革命》这本书中所出现的一个科学家。他和我们之后也会提到他，他其实和辛顿一起发明了这个布尔兹曼机。所以这个科学家他也写了一本书叫《深度学习：智能时代的核心驱动力量》。所以你可以去读这本书，然后再去、再去结合起来这个... 这个结合这个《深度学习革命》这本书，然后去仔细的去理解这个 AI 时代。

所以这是从词句段篇，也就是从人物切入，去进一步理解事件冲突，然后从作者的叙事结构，再到他者评论，整体这个文本细读，再去理解这个《深度学习革命》。

但是在阅读的过程中大家要记得写卡片，就是你围绕这个人物，卡可以写人物卡。你围绕这个事件和冲突，你可以写事件卡。

第二个呢就是抽样阅读，其实抽样阅读的话，刚才给大家说了，就是你文本系读完之后呢，你觉得哪一篇、哪一个章节更感兴趣，或者哪个章节没有理解清楚，你可以再去抽样阅读相关的部分。

但是如果我们直接拿到这本书之后，你怎么... 你刚开始其实你可以，因为它分了四部分，我们可以大体看一下它四部分的相关的页数。我大体发现其实第一部分它页数最多了，112 页。所以我们可以抽样阅读就直接去阅读第一部分，然后如果你时间很少，你就直接阅读第一部分就可以了。然后当你仔细阅读完之后，其实你发现作者这本书它也是第一部分、第二部分前边写的还是挺扎实的，又到后边其实就写的很水。所以它也是一个前后的一个很明显的对比。

所以写完阅读这块给大家启示就是，你如果实在是没时间，你可以通过四部分的页数来看看哪部分的页数多，然后重点去抽取那部分来去读。所以这部分你会发现作者着重笔墨最多的其实就是第一部分，第一部分也是他写的最精彩的一个部分。

然后读完之后呢，你会发现这本书里边它涉及了很多公司，也涉及了很多人。它涉及了很多公司，这块呢你会发现它有大家所熟知的谷歌呀、有 DeepMind、Facebook、百度啊、微软啊、OpenAI 公司。这些公司我给大家注重关注两点:

第一点就是你读完之后你会发现，其实即使在 AI 时代，它是一个新的时代，但是在人工智能的一个竞赛平台之上相互角力的公司还是巨头公司，还是以谷歌和微软为主。

第二个就是在这些巨头公司之间，其实我们发现了中国公司的影子，而且里面最明显的一个影子就是百度这个公司。所以百度这个公司，如果你之前... 你可能在十年以前，十年以前百度这家公司其实在 BAT 和阿里巴巴、腾讯，包括后期新的有产生的美团、今日头条等等一些公司角力的时候，其实百度是非常入于下风的，基本上它错失了好几个机遇。但是你会发现在人工... 在 AI 时代，这个世界大舞台角力的其实反倒是百度这家公司，它在仔细的部署它的 AI, 仔细部署它的... 希望它自己能够抓住下一个时代的一个机会。

但对... 这里呢我给大家提示的其实就是，我们如果你通过各种角度去分析一家公司的话，其实你不会给一家公司... 你会给一家公司一些更客观的一些评价。所以这是给大家两点的一个提醒。

所以整个这个《深度学习革命》这本书读的话，其实我们最主要采用的方法其实就是文本细读，就是你从头读到尾，这种很笨的办法。但是这种方法呢，对于这种长篇记事、小说类，其实是蛮直接... 其实反倒是效用最好的一种方式。

好，那么这就整个... 以上了就是关于深入这个《学习革命》这本书我们到底该采用什么方法去读，以及我们读完之后会有什么感觉。今天的今天讲解的一个重心其实是放在了第二部分，也就是深度学习的一个技术变革。然后给大家把整个的 AI 时代过往给大家梳理一下，看看我们 AI 时代这几十年到底是怎么演变过来的。然后这里给大家列了几个里程碑、生动讯息的 AI 时代的里程碑。关键节点非常的多，里面有各种... 每个科学家可能发明了一个算法，那就算一个小的节点。但是如果我们跳出来看... 其中一个节点一个节点给它砍掉，我们跳出来看其中一个节点一个节点给它砍掉，我们只保留最关键的三个节点的话，其实我们把它列出来，其实第一个节点就是罗森布拉特他的单层感知机，他引入了单个的神经元。第二个就是 86 年新顿的多层感知机，多层感知机可以... 就是多层神经网络，它引入了多层的神经元。然后下一个就是 10 年左右辛顿和他学生的一个深度学习，就是他在多层神经元... 引入多层神经网络这个基础上，然后因为在叠加了这几十年的一个计算机算力的提升，然后有一系列的一个科技的一个突破，所以这其实是最明显的一个三层... 最明显的一个三个节点。

然后大家可以会发现，其实从单层感知机然后到多层网络，然后到深度学习，基本上就是三四十年，基本上就会有一个很大的变革。然后基本上在三四十年之间又会有一个很大的变革。然后基本上在三四十年之间又会有一个比较大的一个寒冬。基本上就是这个整体的一个感觉。所以你会发现其实 AI 时代其实它最早其实都可以追溯到很早的一个 1928 年，那么很早的一个年代。所以它虽然是最近 16 年之后它以热词的形式、以新闻的形式涌现在我们的生活中，但是它其实历史很悠久，它其实算法在互联网诞生之前，在互联网诞生之前就已经在进行了神经网络，在进行了 AI 相关的算法的研究了。所以这是一个非常非常反常的事情，很多人以为研究 AI 智能算法只是最近 10 年 20 年的事情，其实远远不是，它是在互联网诞生之前就已经在研究相关的算法。

我们逐个来看。首先我们来看一下罗森布拉特的感知机。罗森布拉特他最开始这个感知机呢，他其实没想去去解决什么问题。他就想去看一看大脑是怎么工作的，他想去解开大脑的奥秘。他搭了这么一个感知机，然后这个感知机他顺便可以解决一些问题。不是因为他刚开始就是奔着解决问题去的。所以这是两个目的：第一个目的他主要目的是为了探究原理；然后他顺便解决了问题。

这感知机是个什么东西呢？他其实感知机就是一个单个神经元，他就模仿了单个神经元搭了一个数字的算法系统。他搭了一个数字系统发现这个效果还挺不错的。然后当时就引起了一个轰动。而且罗森布拉特这个人他本身也是有很强的信念。我们今天会发现，包括辛顿、包括反对他的明斯基这帮人，这帮科学家他们都是信念先行。他们不是结果先行，他们是信念先行。他们都是先坚信某一个东西是一定可以做的，哪怕你反对他... 那个明斯基他都最后... 最后人工智能发展这么好，但是他直到他去世，他一直在坚信其实神经网络其实是不可能去... 这个这种方式是不可能去完全模拟人的大脑。

所以你会发现这些科学家他们都是信念先行。包括罗森波拉特他也是信念先行，他也是相信... 相信这种神经网络这种方式是可以去解开大脑的奥秘的。但是当他把这个感知机搭出来之后，然后之后这个明斯基反对他。因为他为什么反对他呢？其实这个罗森波拉特他这个当时搭了这个感知机之后，效果还不错。效果还不错、效果还不错，就申请了一些经费。申请了一些经费，他就来回的个人生活就丰富了很多，因为他有钱了，然后个人的生活买豪车什么... 各种... 在科学家这种生活就丰富了很多。所以明里暗里肯定会引起很多人、其他人的妒忌。所以当然科学家打嘴炮，这种生活就丰富了很多。所以明里暗里呢肯定会引起很多人、其他人的妒忌啊。所以这个... 当然我们当然科学家打嘴炮，他不是说就是骂大街这种啊，他直接就是直接去攻击你的算法啊。所以他也这也是可能他成为一个靶子的也是一部分原因啊。

所以再回到历史长河，回到那个当时那个切身场景中，其实你会发现他不是说只是简简单单科学家... 他科学家也是人，只要是人他所有的行为就是得符合人性的需求，符合了每一个人的动机。所以不是很单纯的就算法论算法的，其实当时也是有很复杂的一些一些具体的一些场景。

但是罗森伯拉特他是在 1971 年去世的。但是他去世的时候蛮遗憾的，就是他去世的时候仍然是人们在一度的反对感知机。为什么反对呢？虽然他取得很好笑，我在后边我会提到，就是因为敏斯基这个人他也觉得这个罗森搭了一个感知机，然后他申请了很多算是经费，然后这个他自己呢也是一个比较张... 相对来说比较张扬的人，所以也是引起了很多... 可以说是一个反对。

这里呢我仔细给大家提一下这个感知机是干嘛的。其实感知机就是一个单向的、单个神经元的一个演变，就是如果... 其实你可以把它理解成一个简单的一个二元的判断，就是如果它满足、符合满足我的要求，它符合正确答案，它就是对的，它就是一；如果答案不正确，答案它就是对的，它就是一；如果答案不正确，它就是零。很简单的一个二元的判断。

你比如这里举了一个例子，比如我找对象，可能找了两个条件去判断：一个就是学历高，一个家境好。对方学历高但家境很穷，那也行；学历不行、学历不好，但家境好，那也行；两个都好，那也行。但是如果两个都不好，那就不行。这种就典型的是一个二元的判断，结果只有好和不好，结果只有成还是不成。这种二元的判断，其实感知机就很常处理这种二元分类的问题。

那么二元分类完了之后，你会发现这种... 它就是线性可分。所谓线性可分就是，你把这些点画到一个二维平面上，你能拿一条直线把两边给它分开。你比如我们这里边分了四个点，分了四个点之后拿一条线可以把两边给它完全的分开，这就是线性可分的问题。所以它是一个很简单的二元分离。

但是大家知道，只要你二元分类但是大家知道，只要你二元分类是可以了，那基本上多元分类问题也是可以做的。因为多分类问题就是由二分类问题不断的叠加去解决的。所以虽然你感知机你比较小看它，它虽然只是一个简单的二分类问题，但是它如果只是能把二分类问题很好地解决了，那基本上多分类问题那也是能很好地解决的。所以感知机它最大的功能，它就是能解决了一个线性可分的问题。

你会发现，然后罗森·巴拉特这个人他搭了一个神经元，他就能解决线性可分的问题。那你说如果我多搭几个神经元，或者我不搭一层，我还多搭几层神经元，你说这些解决的问题是不是就更多了呢？的确是。

这是一个很直接的想法，就是一个神经元把它扩展到多个、多层神经元，行不行？这里边就碰到了一个很大的阻碍，就是马文明斯基。明斯基他被称为人工智能之父，因为他是最早在达特毛斯学院当时成立一个会，最早提出了一个人工智能的概念。所以他的江湖地位比较大、比较高，是大老级人物。

然后在卢森·布拉特他造了感知机之后，马文明斯基和帕普托两个人，他就出版了一本《感知机》的这本书。这本书中他就明确写了说，感知机这种算法它并不能扩展到多层感知机。所以直接就给他判了死刑了，直接就给他把这条路给堵死了。

你说他是不是盲目判别呢？其实他也不是盲目判别的，其实感知... 他在这本书里边对感知进行了详细的一个数学的推导。他其实比人家罗森·波拉特比创始人能更精确的描述感知机的问题。所以当然他本身也是一种江湖大佬，他自己的学术能力也是有的。所以他自然... 他这个这本书里边这本书出来之后，他得到了很多人的信奉。

而且当时在大家注意，一定要回到当时那个情景，其实当时的计算机能力也是很弱的，计算机的算力也是很弱的。所以这种硬件条件是这个样子，然后它本身的江湖地位在这放着呢，所以大家很自然就信奉了这个明斯基说的，感知计算法是不能扩展到多层感知机的。但是大家注意，这只是他的认为，就是感知计算法它并不能扩展到多层感知机，这是他自己凭经验的一个感知的一个直接的一个判断。这不是说这个... 不是说他用数学算法推导出来，他只是用数学算法推导出了感知机、单层感知机是怎么去解决问题的，单层感知机他的确信是什么，这是有非常坚决的数学推导的。但是多层感知机到底行不行靠谱，注意这他是没有数学推导的，这只是他凭经验的一个判断。

但是因为他单层感知机描述太好了，而且他本人的经验、江湖地位特别高，所以他多层感知机这个结果出来之后，基本上就给神经网络这条路给判了个死刑。然后第二年他就获得了图灵奖，基本上江湖大佬的地位就一下子有... 确定... 而且明斯基其实直到他去世的时候，他依然在坚信神经网络无法实现通用人工智能。所以你会发现这些科学家基本都是信念先行的。

他一手也创建了麻省理工的人工智能实验室。那么明思基这个人他在《感知机》这本书里边，他是怎么去精确的描述感知机呢？他发现感知机只能解决线性可分问题，他没法解决异化问题。什么是异化问题，就是线性不可分问题。

你比如还是来刚才举例子，比如学历不高、家庭一般，当然找对象是不成的。但是如果说我自己衡量了一下，我自己的条件说我自己其实条件也不是那么好，所以我还是得找个想找一个门当户对的。所以如果找来了一个人，家境又特别好、学历又特别高，我总觉得我配不上，如果成了的话总感觉他会分手。所以这样的话我干脆找对象的时候，对那种家境好、学历高的干脆就 pass, 我就只找那种学历高、家境一般，或者学家境好、学历一般的，就找这种人。

那么成和不成这二元的一个分类，大家在图上一标出来，你会发现黑点就是成的，红点就不成的。但是你会发现，无论在二位评别上你画哪条线，黑点和红点你都没法把它完整的区分开。就这条线的一边是能成的，另一边是不成的。为什么呢？因为这两条线一连线，它有焦点。只要有焦点，你就很难去找到那么一条线。

所以感知机，它这本书中有精确的数学推导，它就描述了这种... 罗森伯拉特他所发明的感知机，它是可以解决线性可问问题的，但是它是解决不了异或问题的，就是线性不可问问题。所以这是它这本书的一个非常大的一个贡献。他非常把这种感知机它本身那个缺陷用数学的推导非常精确的描述了出来。这也是为之后星盾进一步去改良它提供了一个很大的一个引导。

所以我们不是说明斯基他虽然误导了科学家说这个多程感知机行不通，但是大家注意，科学家当时信念先行的不是因为他误导了。科学家当时信念先行的不是因为他误导了他，我们就说这个人不行，而是他用非常精细的数学语言去描述了他的缺陷。那么也为后来人进一步去改良他提供了一定的支撑。那么这本书也是有一方面是他的贡献，另一方面也是他的错误引导的。

就是在这本书的结尾部分明斯基表达了这样的观点，说他感知这种算法他不能扩展到多层的感知器。他为什么会读出这样的结论呢？他其实是一个经验的判断。他觉得神经元连接数量太多了，你单个神经元连接还好，你每多那么一个神经元，那基本上神经元和神经元之间的连接它基本上会成... 这个会急剧膨胀。急剧膨胀以当时的算力条件，那完全是不可能支撑的。而且呢，你单层这个神经元的话，你算这个权重，这个权重好分配。你比如两个选项，一个你就无非是首填两个选项首填就好了。但是你如果说这个神经元数量特别多，那么这个权重你要填，那个权重数量也特别多。那你要首填的话，这得填到何时呢？所以这种很经验的、直接的判断其实觉得在当时这个条件下，他会觉得这种多层感知机其实是比较费劲的，是做不到的。

然后因为他的这种... 刚才说了，因为他的江湖地位比较高，然后他写这本书的确写的也是可以的，所以大家都默认他说的就是正确的。

然后那么明斯基他认为这种神经网络这条路行不通，那他认为哪条路能行得通呢？他认为走符号人工智能这条路能行得通。所谓符号人工智能是干嘛的，就是我们用逻辑语言、用规则语、用规则语言、规则语言去描述我们这个世界的运行规律，然后我们把这种逻辑规则语言告诉给计算机，让计算机仿照着我们人类认识这个世界的规则规律来去搭建一个人工智能。所以把这种方式成为符号人工智能。

所以明斯基为什么会有这种想法，就是因为他受罗素的影响比较深。他认为逻辑才是人类通用智能的一个核心的底层。所以用逻辑产生的规则，那就应该... 这种方式才能去实现通用人工智能。所以这是他的一个信念的一个底层的一个信念。

所以在明斯基的带领下，当时大部分人就接受了这种符号人工智能。所以当时呢以这种符号规则为主导的研究呢，在当时 70 年代就占据了一个主导地位。因为当时这种符号人工智能它是基于这种专家的职业经验，所以呢这种这套系统也被称为专家系统。

然后我们举个例子呢，就是这种 CYC 这个项目，就是 CYC 这个项目。CYC 这个项目大家去网上搜一搜，其实这个网站它还是有历史记录的。你去这个网站看一看其实你会发现，它这个网站是干嘛的？它这个项目是干嘛的？这个项目就是想的是，我每天去记录一些基本的一些规则，然后把这些规则逐年累积起来。这样的话，经过那么几世纪的累积，或者是几百年、几个世纪的几代人的累积，那是不是可以把这个世界上所有的规则给它穷尽了呢？然后把这些规则再告诉给计算机，然后这样计算机是不是就能实现这种通用人工智能了呢？这就是当时做这个项目的这帮子人在明思基的这种符号人工智能的这种引领下这种很直接的想法。

这种规则是什么呢？这种规则就是我们日常生活中常见的一些规则。你比如什么... 每一个人不能同时出现在两个地方，比如我们喝水的时候必须背口朝上，就这些日常生活中你是司空见惯的。但是这种... 我们需要把用语言来描述出来的规则，每天记录那么几条，然后逐层去累积。所以这是这套打法。

那么这套打法有没有用呢？其实是有点用的，其实就有点用。你比如你今天记了几个规则，明天又记了几个规则，然后你随着规则的记得越来越多，那个人基于这种规则的这种机器，他的判断力是不是就相对来说就强了一些、就越强了一些啊。

所以和这个... 和这个... 这个符号人工智能和当时的那种连接主义啊，也就是刚才神经网络相对应的那个连接主义相比呢，他的... 他可以通过不断的细化这种规则来来那种逐步的进步啊。因为但是当时那个计算力、算力是非常有限的，然后算法也没有找到合适的算法去分配相关的权重。所以连接主义这种神经网络其实是处于一个非常滞后的一个... 停滞不前的地方。一方面是停滞不前，另一方面符号主义... 符号人工智能它是可以通过不断细化规则来够逐步进步的。虽然它进步的慢，但是它是在进步的。

但是进步的慢，是进步的慢。虽然在进步，但是符号人工智能迟迟没有突破。你每天在记录各种规则，一直在累积，但是累积完之后把这种规则告诉给计算机，计算机它所实现的效果，虽然还是在不断的改良，但是每天改良只是那么一点点，真正是一种突破性的进展它是没有的。所以符合人工智能迟迟没有突破，而人神经网络呢，被这个明思基判了死刑之后，大家都不愿意研究了，然后处于一种停滞不前的地方。那么人工智能就一下子就进入到了第一次寒冬。本来就两条路径，一条路迟迟突破不了，一条路就判死刑了，当然这个人工智能就进入寒冬了。

所以就像 1971 年英国政府所写的那样子，"迄今为止在该领域任何地方取得的成果都没有实现它当初承诺的重大影响", 因为这两条路它都没走通。所以就进入到了人工智能的第一次寒冻。那么第一次寒冻是怎么走出来呢？这里边就必须提到一个关键人物，就是辛顿，这个人杰弗里辛顿。

这个人在提杰弗里辛顿这个人之前，我们得先说一下他的家族。杰弗里辛顿他这个人的家族还是很厉害的。他的曾曾祖父就是我们所说大家耳熟能详的乔治布尔，也就是大家... 只要大家如果学计算机相关的科学的话，你肯定会学一门数学叫布尔代数。布尔代数这个创始人就是他曾曾祖父。他的曾祖父是数学家，他的父亲是昆虫学家。而且他曾外祖父也是数学家，他的外祖父是植物学家。他们一家子全是各种家，所以他是生于一个文化世家。所以他们这个家族其实这种学术能力是蛮强的，而且每个人智商也是挺高的，要不然也不可能成为各种家。

但是大家其实可以重点关注一下最开始乔治布尔，就是他曾曾祖父。《思维规律的研究》这本书，他当时乔治布尔他奠定布尔代数其实就是靠着《思维规律研究》这本书的。但这本书他其实是以研究逻辑而闻名的。我们最常用的计算机最底层的布尔代数，01 的那种判断逻辑，什么 "且"、"亦"、"或" 什么、"且" 呀、"或" 呀、"非" 呀、"亦或" 呀，这种运算的都是来自于这本书的，都是来自于布尔代数的。所以这本书它是以研究逻辑而分明的。

但其实这本书除了研究逻辑以外呢，它还研究了概率。这本书中它还探讨了概率的问题。所以其实这本书有个很有意思的感觉，就是这本书它所探讨的这个逻辑和概率，恰好就是实现通用人工智能刚才所指的那两条路径。一条路径是符号人工智能，它是非常重逻辑、非常重规则的，它就是乔治布尔在这本书中所主要探讨的问题。还有一条路就是神经网络，就是连接主义。这条路呢，就是神经网络。就是连接主义这条路呢，其实你在后期，他们把这种概率演进的... 其中呢，才得到了一种非常大的进一步的一个提升、一个质的一个变化。所以你会发现乔尔布尔在这本书中所重点探讨的这两个问题，分别是一个逻辑、一个概率呢，反... 这个在这种... 在这种... 这种... 这种很... 很很很糊糊之间，没想到直接就是对应的是实现通用人工智能的这两条路。所以这就是他的家族是很厉害的。

那么我们转回到杰弗里辛顿这个人身上。他们的家族很厉害，按理说他这个人刚开始应该是从小立大志，从小立大志，然后这个... 这个一路呢一路的这个立了很多志，然后一路呢披荆斩棘，一路呢遇到困难去克服困难，然后逐步的去实现自己的这个学术成就。但其实新论在早期的时候，他还是不是那么志向很明确的。虽然他在刚开始这个... 因为他在读中学的时候，因为他和他身边他很厉害的一个同学探讨大脑的问题，他当时探讨他觉得大脑是种全息地图这种感觉，就一下子吸引了他对这种大脑的关注。但是这种... 但是这个种子其实并没有刚开始就一直... 刚开始这个种子播下去之后并没有刚开始就一直... 刚开始这个种子播下去之后并没有说连续的就把它发苗、茁壮成长，而是其实它也是中间走了很多弯路的。

它刚开始其实读的是个心理学，然后读完心理学之后，其实它最早的其实不是读了心理学，是物理学。读物理学... 读物理学它这个... 物理学它这个退学了。它学这个感觉学的没什么兴趣，然后他又去读了心理学啊。但是读了心理学其实兴趣不是特别大，然后考试呢然后考试呢就是这个... 经常挂科啊。然后这个... 但是他还是拿到学位了啊，拿到学位之后呢，他毕业去做了一年的木匠。就做了一年的木匠。按理说他们家族整个都是都是这种学术士奖啊，但是他去做了一年的木匠。然后他那个... 他父亲呢对他整个都是一种学术士奖，但是他去做了一年的木奖。然后他父亲对他其实学术成绩也不抱什么特别大的期待了，都当木奖去了。没想到他之后就是进入到了爱丁堡大学去做人工智能相关的研究了。

做相关智能研究的时候，他其实遇到了一个导师。这个导师... 但是这个导师，他所信奉的那个路子是符号人工智能那条路，他不是连接主义那条路。相关证的研究的时候呢，他其实遇到了一个导师啊。这个导师呢，但是这个... 但是这个导师呢，他所信奉的那个路子呢，是这个符号人工智能那条路啊，他不是这个连接主义那条路。所以呢，因为那个... 因为他导师读了明斯基的书啊，所以他还是明斯基的一个坚定的一个一个一个一个拥部者啊、一个坚定的一个追踪者啊。

所以但是杰弗里辛特这个人呢，他在最开始的时候他其实啊就已经坚定了这种神经网络、神经网络这个... 这个就是可以能是理解大脑更好的一种方式这种信念。你会发现他们都是信念先行。他们都是信念先行。所以你会发现杰弗里辛特这个人，他就刚开始他就有这种信念，他觉得这种简单的处理单元构成的网络是理解这种认知比较好的方式。所以他就和他导师天天干架，基本上就是一直在打架。辛顿这个导师每天在劝他改方向，然后辛顿他就说... 每次他就说再给我六个月时间、再给我半年时间，我去证明这个方法其实是有效的。所以每次都这么说。就是他们相互之间在拉扯。那为什么要拉扯呢？其实都是信念。他们科学家脑袋里边的信念其实是打架的。

那么虽然是信念先行，但是有没有成果呢？其实是有成果的。在之后辛顿和希诺夫斯基研究出了布尔兹曼机。这也是神经网络在第一次寒冬之后的一个临界的转折点。它整出这个布尔兹曼机呢是干嘛呢？这个布尔兹曼机其实和刚开始的那个感知机有什么区别呢？就是这个布尔兹曼机啊，它是有隐藏层的。它和那个感知机相比，它有多层。它中间是有隐藏层的。所以它在输入层和输入层之间它多了一个隐藏单元。而多了一个隐藏单元呢，它就会发现多了有隐藏层的。所以它在输入层和输入层之间它多了一个隐藏单元。而多了一个隐藏单元，它就会发现多了一个隐藏单元，多了一个层，形成一个多层的神经网络之后，那么每一层向下一层进一步去提供信息，它就会发现这样所训练出的那种感知机，它其实是可以解决刚才说的那种线性不可分问题的。其实可以解决这种异或问题的。

它为什么能解决这种异或问题？其实它为什么能解决这种异或问题的，其实从数学推导上我发现，它可以... 它在二维层面上其实是线性不可分的，对吧？但是你在二维层面上不可分，是不是可以拉到三维？拉到三维之后，其实你拿一个平面去给它分的话，其实有可能就可能线性可分了。所以它引入了这种隐藏层，引入了隐藏层，那么神经网络其实就有一种生为的感觉。所以他是能起这种异或问题的。

所以这是一个很大的转折点，就是他引入了布尔兹曼... 他自己造了一个布尔兹曼机，造了布尔兹曼机发现这个异或问题其实是能解决的。大家看这张图片，左边就是希诺夫斯基，然后右边是辛敦，就发现当时他们还是特别特别年轻的。

第二个转折点也是辛顿带来的。他整了一个反向传播算法。刚开始我说这个传感知机的时候，他其实明斯基之所以反对他，其实两个原因嘛：第一个就是他需要算的太多了；第二个就是这个权重不好分配。你这个权重该怎么写这个权重呢？权重这么多我不可能手一个一个去填吧。但是呢，这个辛顿呢和当时这个... 他在圣迭厄分校也是他做这个博后之后的一个学校，他去整的一个... 找到了这个分配一个权重的这个反向传播算法。

这篇论文发现他其实可以... 正着不好分，我是不是可以倒着来？我倒着来、我倒着来，我倒着怎么来呢？倒着... 我是不是我最后，反正你总是要判断成还是不成，对吧？虽然成还是不成，但是成的话最终神经网络是不是总会有一个结果，这个结果和我真实的一个预期的一个结果就是成或者不成之间总会有一个误差，对吧？总会有一个误差。比如吧，总会有一个误差。比如成是 1, 不成是 0, 但是这个神经网络算了半天算了个 0.6。那么 0.6 和它的预期结果，本来是假设是 1, 那么 0.6 和 1 之间总会有个差距 0.4, 对吧？这个 0.4 呢，它就把这个 0.4 这个误差逐层的往后退，然后通过这种算法呢，它就把这种权重的这种方法就给定了。就是我可以通过简单的一个误差反向传播的一个方法给定了。我可以通过简单的误差反向传播的方法给定神经网络的每一层的权重。

所以他就把权重给的问题就给解决了。所以这篇论文其实也是个划时代论文。那么这篇论文出来之后，引用次数就超过了 4 万次。当时是一个引用次数非常高的一篇论文。

所以这两个... 所以这两个转折点，一个是布尔兹曼机，一个是反向传播算法，这两个诞生之后呢，把这个神经网络就从寒冬就给拉回来了，就会让神经网络进入到了一个乐观和进步的一个时代。与之诞生的就是这个 NIPS 这个会议。这个会议呢，就是这两个单元之后，大家都在神经网络这块其实看到了一点曙光。所以大家会... 大家觉得其实这块还是能做出点东西来的。然后大家就整了一个会议，NIPS 会议。

这个会议是干嘛呢？这个会议你看这个名字全称叫神经信息处理系统。它就是鼓励研究人员去探索各类神经网络。这个神经各类神经网络这个... 各类神经网络包含什么呢？各类神经网络不仅包含人工造的，就是人工的神经网络，还包含生物，我们每个大脑实体的神经网络。而且他们的主席团都是一批杰出的科学家和工程师。

那么这个会议来了之后，它就引导了多学科的融合。因为它是研究神经网络的，神经网络一方面有人工神经网络，还有生物神经网络。而生物神经网络一般情况下只是生物学来研究的。但是当时也是有一个技术就是核磁共振技术，就是 fMRI 核磁共振技术。这个技术当时已经出来了。这个技术出来... 这个 fMRI 这个和磁共振技术这个技术当时其实当时已经出来了。这个技术出来之后呢，就发现科学家就可以发现通过这种成像技术、成像技术就可以研究人的这个人的这个大脑的这个这个认知了呀，研究人的大脑的记忆了，研究人的这个大脑的这个这个各种各样的这个认知过程了。

所以这一下子就把这个认知科学、这个认知神经科学这个领域把认知科学、认知神经科学这个领域就给创建了。认知神经科学这个领域是怎么创建的？其实很大程度上就是因为磁共振技术的一个发展。而认知神经网络它也是研究... 它也是研究神经网络的。它也是研究神经网络的，那么认知神经科学它是研究人怎么去认知这个世界的。那么它天然的、天然的什么呢？它天然的又把那些其他的一些学科就给融进去了。比如这个什么社会心理学啊、经济学啊，因为你在... 它就认识怎么认识这个世界的。那么心理学它也在干这个事，对吧，那么经济学呢它也在探究这个决策这种问题。

所以它一下子通过认知神经科学的桥梁又把其他的这种学科也给打包过来了。所以 NIPS 这个会议虽然最开始是以研究神经网络为秋点，但是它后边慢慢慢慢的，它慢慢把各个学科都给融合起来了。那么各个学科之间相互融合，它其实进一步去促进了人工神经网络的发展。因为人工神经网络和生物神经网络本质上都是研究神经网络的，一个无非是一个是人造的，一个是天然的。但是它们的机制其实可以相互借鉴。那么生物神经网络我们对它的机制研究的相互进一步清楚了，那么是不是可以更好的促进我们人工神经网络相关的研究、相关的一种算法的研究？

所以你会发现这种人工神经网络和生物神经网络，这种生物学和深度学习之间，它其实是一种是一种共生关系，是一种相得益彰的共生关系。所以它就进一步促进了神经网络的一个研究。所以它当时就出现了一些很不错的一些结果。比如这个 87 年波默洛他整的这套、这套系统，ALVINN 这套系统。这套系统它就已经实现了可以自动驾驶，虽然这套系统它只能在这个自家的这个路或者是这个高速公路上去实现自动驾驶，但是这已经是一个非常大的一个突破了。就这个系统它其实已经做到了明斯基他刚开始所断言的说神经网络做不到的事情。所以这套系统它已经能做到了。

还有一个就是这个谢诺夫斯基，就是发明波尔兹曼机和星沟一起整波尔兹曼机的科学家，他当时也整了一个 NetTalk。所以它可以进行发音，它可以运用神经网络进行发音、模拟人的声音进行发出。

所以当时已经取得了一定的效果之后，又有一个大脑就是一个大佬加入了。这个人叫杨立坤。杨立坤这个人其实是新顿的一个博士后。博士后你会发现，科学家这个... 科学家依然也是信念先行。他在刚开始的时候他就认为，我一定... 我一直认为我绝对是正确的。而且他相信神经网络是一个路径，是通向人类这种通用人工智能非常真实、非常有用的技术。所以他们都是信念先行。在这个信念技术之上，然后他就搞研究，发现的确这个是... 结果是可以的。

然后他... 他这个很重要的一个贡献就是他提出了卷积神经网络。卷积神经网络其实它是仿照人的人类的视觉系统所构建的一套算法。所以你会发现我刚才说，生物网络、生物的神经网络和人的神经网络虽然一个是天然的，一个是人造的，但是它们的算法是可以相互借鉴的。它们原理是相互借鉴的。

所以随着人对人类的神经网络的进一步的认知，尤其是当时对人类视觉系统的进一步的认知，当时做了一个青蛙实验，就发现人的眼睛它不是只是观测信息，其实人的眼睛背后的神经元的连接它同时也有处理信息的神经元。

所以你看这个启发，一下子启发杨立坤，杨立坤就整出了一个卷积神经网络。所以卷积神经网络它也是多层。那么多层，它每一层它不只是说只是把这个信息提取出来，它中间那种层它还可以进一步的对前面获得的信息进一步去进行去分析、进一步去处理。那么多层处理就... 前面的信息给后边的信息、后边的信息给再后边的信息，一层层的处理，那这样的话它就成了一个卷积神经网络。

那么它除了做这个卷积神经网络之后，它还做了一个东西，就是它做了一个 ANNA 芯片。它是博士后结构之后它加入了贝尔实验室，它进入贝尔实验室它就开发了一套识别手写数字的叫 NET-Talk 系统。而且它专门为这套系统... 而且呢它专门为这套系统呢设计了一个叫 ANNA 的一个芯片、一个这个... 这个芯片。

所以你会发现杨立坤呢，它实现了这个能手写数字的这套系统，它是怎么实现的呢？它当时呢应用了这个全美国的当时的那个手写支票，把那些当数据进行处理，然后能够识别的这种手写数字。所以第二，它自己又去开发了一个选进神经网络的算法。第三，它自己又造了一个 ANNA 的芯片。

所以当时其实杨立坤有意无意的，其实它推动了神经网络三要素的深入发展，直到我们现在依然... 我们把它称之为 AN 时代的三要素。一个是数据，一个是算法，一个是算力。杨立坤的数据它采用的全美超过 10% 的手机支票；算法它采用的是卷积时间网络；算力它采用的是专用的 AN 芯片。

所以它有意无意的推动了这三个的发展。其实在当时的条件下，其实大家都是没有... 都是没有意识到数据和算力能有多重要的。其实大家当时都是意识到算法很重要，但是基于当时硬件条件，大家都没有意识到数据和算力很重要。但是杨立坤当时创造的系统，它有意无意的用了一些数据，有意无意的造了一个芯片，造了一个 ANA 芯片。所以它促成了这三要素的一个生存发展。

但其实当时大家是没有意识到算力和数据其实是很重要的，而且它需要的量其实也是很大的。就像这个先顿刚开始先顿在这个时候所说的说，这个其实没有人在这个时候会问，所以如果一个算法需要 100 万倍的计算能力会是什么样子。当时没有人想这个问题，只是有意无意的发现有这个数据、有这个算力。

所以虽然星盾它整了这套反向传播算法，然后它也整了一个布尔茨曼机，找了一些算法，但是呢... 而且神经网络也迎来了一个复苏，成立了一个 NIPS 会议。然后呢杨丽珀也整了很多系统，然后当时的贤多夫斯基也整了一套系统，然后也整了一个自动驾驶的车。波普洛也整了一个自动驾驶车。其实神经网络当时也取得了一定的复苏。

但是当时的计算机算力不行，效果很有限。虽然波摩洛可以自动驾驶，但是它只能在自驾道路上和高速公路上行驶。虽然邪龙富斯基 Network 它可以大声朗读语音，但是对人们日常生活也没什么帮助。那无非只是在派对上当一个把戏把玩而已。虽然杨立坤银行扫描仪它可以去识别手写数字，但是当时其实也是有其他方法可以能读取的。所以它神经网络在当时它其实并没有对人们的日常生活有那么那么大的一个突破性的一个帮助。

所以当时受限于这种计算机算力，效果有限。然后而计算机算力它也不是说一时八会就提升上来了。所以人工智能就是这个神经网络的条件又进入到了漫长的寒冬。

那么之后怎么突破呢？就得提一下摩尔定律。大家会看到我红花所框的，从 90 年代 1990 年一直到 2010 年，这 20 年时间，从 20 世纪的末一直到 21 世纪的第一个十年，这 20 年时间计算机算力其实得到了一个飞速的一个提升提升提升。

摩尔当时呢，它是认为是每 12 个月翻一番，之后它修成了修订为了每两年翻一番。那个每 18 个月翻一番那其实那基本上都是后边的误传。摩尔它本人说的话其实是每 12 个月，后边修订为了两年。但是它修订完了之后呢，基本上它是也是完全按照摩尔定律这个方向在发展。然后这 20 年正好就是计算机算力得到巨大提升的这 20 年。

所以因为随着算力的不断提升，神经网络终于迎来了一些关系性的突破。那么最早的一个突破就是神经网络在语音识别上的突破。然后 2007 年的辛顿在当时在 NIPS 会议上发表了一个演讲，它当时把神经网络、人工智能这条路、连接主义这条路改了个词叫 "深度学习"。有点新瓶装旧酒的感觉，有点品牌重塑的感觉，有点旧东西卖新人的感觉。所以它当时兴起这个词就叫 "深度学习"。其实和之前连接主义、神经网络其实是一个东西，无非是它更想有点划时代的感觉，重新包装一下、重新起了个词。然后当时它正是有 "深度学义" 这个词正式出来了。

然后 09 年它就受邓丽的邀请就去微软去进行相关的一些它当时算法的一些部署、去试验了。然后它当时也是... 当时 09 年它在进行语音识别突破的时候，它首次引入了 GPU。首次引入 GPU 发现 GPU 这种芯片它比 CPU 这种芯片它这种在那种神经网络上的效果是更好的。所以这是一次小小的突破。

但是这次小小的突破其实有点连锁反应。辛诺这个人本人也是很善于运用影响力的一个人。所以微软这家公司突破了之后，其他各家公司就开始后续跟上了。你比如谷歌、比如 IBM 这种公司就开始后续跟上了，都开始邀请辛顿和它的同学生去它们那家公司去把这种算力去部署。这是一个人工智能的一个小的一个转折点。

但是还不算一个特别大的真正的一个关键转折点。但是还不算一个特别大的真正的一个关键转折点其实是在 12 年。辛顿和它的两个学生，一个是萨特斯基夫和一个克里哲夫斯基，参加了一个竞赛就是这个 Imagine Net 这个竞赛。这个竞赛呢得了一个非常非常好的成绩。这个一下子就引爆了... 引爆了当时的当时所有做 AI 相关的公司、所有做相关 AI 的科学家。

当时算法它应用的是卷积时间网络，但是它的精度特别高，它基本达到了第二名的两倍。第二名是谁呢？第二名就是谷歌。第二名就是谷歌这家公司。但是大家要注意的是，星盾和他两个学生只是三个人，而且他们当时只是用了四颗的 GPU。但是效果就已经是谷歌的两倍了。而谷歌当时是一个团队在做，而且当时他们用了 16000 颗 CPU。16000 颗 CPU, 一个团队用了 16000 个 CPU, 最终达到了效果和三个人用了 4 颗 GPU 达到的效果相比，第一名是第二名的两倍。所以这种震撼是非常大的。

所以当时这个结果出来之后，紧接着他的两个学生就发布了一个论文。这个论文就直接是一个跨时代的论文。所以这个论文就被引用了 6 万多次。所以这就是相对于刚才的反向传播算法之后的又一篇巨棒的一个论文。所以这是一个 12 年之后跨时代的一个深度卷积网络的一个论文。

那么这篇论文之后大家就会发现，大家发现这个卷积神经网络这种算法呢在这种图像处理上效果特别好。然后之后呢就引爆了一波的商业创业的浪潮。而且当时呢也让神经这两个字重回了 NIPS 会议。因为 NIPS 这个会议本来就叫做什么神经什么大会，它本来就是研究神经网络的。但是因为当时长达 20 年的寒冬，所以大家都在觉得连接主义无望了。但是新的这帮人靠着信念真的是信念先行，然后逐步的把这条路给坚守下来了，一直到了计算算力能够支撑他这种算法，然后一下子在这种图像识别这种大赛上得到了一个非常大的、非常好的效果，一下子就把这个引爆了。

所以 2012 年也是神经这两个字重新回到了神经信息处理系统... 当时这个系统上，NIPS 这个会议所接受的论文，只要你提神经两个字，重新回到了神经信息处理系统... 当时这个系统上这个会议，NIPS 这个会议所接受的论文，只要你提神经两个字，基本就是 pass 的，基本就是拒刊的。但是 2012 年之后，当时大家你再用这两个字的话，就不是那么拒了。所以当时杨立坤他当时发了一个卷积神经网络，他单独还把神经两个字去了，叫卷积网络，就是因为... 很漫长的寒冬。第二次很漫长的寒冬让大家其实已经很忘了，但是依然是这帮人坚持下来了。

那么新顿在两个月之后，他一下子这个算法不是引爆了吗，那么他在两个月之后在世界计算机试验大会上，他就详细介绍了算法的细节。他把这个算法细节介绍完之后，他就一下子收到了很多公司的开价。很多商业公司就觉得这个新顿这个公司... 这个算法是非常有前景的，就收到了很多公司的报价。然后他这三个人就临时不得不临时成立了一家公司叫 DNN Research, 这家公司。那么成立这家公司干嘛呢？就是报价。其实你说这家公司就是三个人，家公司干嘛呢？就是报价。其实你说这家公司就是三个人，发布了一套算法，然后在这个比赛上获了个奖，就成了一个公司，然后其他公司给他报价去收购这家公司。你说收购这家公司收购什么呢？其实本质上其实本来就是收购这三个人的知识产权，就是收购这三个人在算法上那些很关键的突破的那些知识产权，以及这三个人在之后在你要求可以在我这个公司里面工作一段时间。其实就是收购这个事。

那么当时这家公司开始拍卖之后，有四家公司参与了竞拍，分别是百度、微软、谷歌、还有 DeepMind。所以你会发现其实百度的嗅觉还是很灵敏的。然后当时因为 DeepMind 这家公司其实也是刚刚信息不久，所以他也没那么多钱，他就以自己的公司的股份报价。所以他就很快退出了。那外云微软他在 2200 万每个时候退出了。最后百度和谷歌一直交着，最后新顿其实百度可以报更高的价，但是新顿最后选了谷歌，就是因为他自己的腰间盘突出，腰间盘很脆弱，他以这个借口说他就没法来中国，所以他以这个借口进入到了谷歌。

所以这是一个非常大的转折。这个之后基本上引领了一波的商业浪潮。不仅是美国远在美国有谷歌微软，其实在我们中国，在亚洲这块也是有很多浪潮。不仅是美国远在美国有谷歌微软，其实在我们中国，在亚洲这块也是有很多浪潮的。你比如最典型的就是我们大家所熟知的人工智能的四小龙，比如商汤、比如旷视、云从、依图这些公司，就是在这波浪潮之后... 就是卷积时间网络这个算法出来之后，大家发现图像识别能力太好了，就引爆了这波浪潮。

所以这也是我们国内其实在这波浪潮上其实并没有落后太多，我们并没有落后太多。我们和西方和角力 AI 的时候，其实我们依然是处于领先，依然是其实其实持平位置，并没有落后很多。

那么这是一个第二个比较大的一个突破，就是图像、图像视频领域。那么还有一个很大的领域的突破就是 17 年，17 年神经网络在语言模型上的突破。你看刚才我说的在语音上的突破，第二个是在图像视频上的突破。那么第三个就是在语言模型上的突破。那么这个突破也是一篇很关键的论文，就是在 17 年辛顿他读到谷歌大脑。因为当时辛顿他被谷歌公司被谷歌收购了，然后他就去谷歌工作了。然后谷歌当时在谷歌之前文达他们已经成立了谷歌大脑。然后之后就辛顿加入了其中了。那么谷歌大脑... 在谷歌之前这个文达他们已经成立了一个谷歌大脑，然后之后就新论加入了其中了。那么谷歌大脑就发表了这篇很重磅级的一个论文。

这个论文它里面应用了一个架构就是 Transformer 架构。Transformer 架构它和之前的卷积神经网络相比，它引入了自注意力的这种机制。那么引入这种机制，它就可以处理一种长文本模型了。大家注意，这种图片识别、图片识别你不需要是长、不需要有那么长度的限制，就比如你只需要单张图片识别就可以了。但是语言模型可不是这样子，语言模型比如你输入一个很长的文本、很长的文本，那就需要我在识别这个文本的时候，第一个字和... 比如一篇一百万字的小说，那么第一个字一直到一百万字这么长的文本他都得去处理它。那么这个模型其实之前的那种卷积神经网络是很难处理这种的。因为它是仿照卷积神经网络之所以造成是仿照我们人类的视觉系统造的，它就不是为了应用... 它就不是为了应用这个... 它就不是为了解决这种长文本的问题造的。

所以这个 17 年这篇论文，它引用了 Transformer 结构，它解决了这个长文本的问题、长文本模型的问题。所以它引爆了语言模型。所以你看这篇论文一下子就引用次数操作过 10 万多次。所以之后的谷歌的 BERT 模型，包括 OpenAI 的 GPT 模型，它都叫大语言模型，是语言模型，它们都是在 Transformer 架构之上搭建的语言模型。

所以一下子引到了我们现在的 OpenAI 这家公司。所以就和我们现在我们感知到的就连接上了。这家公司怎么来的？其实就是因为 17 年的 Transformer 架构这篇论文实现了一个非常大的突破。

当然除了在我刚才所说的语音、图片、语言模型上以外，我们还有在其他的一些领域的突破。我们很重要的两个领域，一个是游戏领域的突破。我们很重要的两个领域，一个是游戏领域，DeepMind 大家所说的 AlphaGo 击败了李世石。而游戏领域其实是神经网络最常应用的一个领域，因为游戏领域它是规则非常明确的。规则非常明确的，所以符号人工智能那一派它也经常在游戏领域这一派去验证。所以神经网络、连接主义这一派它在 16 年他基本上造了一个阿尔夫购，就把这个李世石击败了。所以这也是在游戏领域一个非常大的一个突破，因为是在围棋领域，而围棋是在... 是所有游戏中最复杂的。

第二个领域就是医药领域，就是神经网络它不断的突破了蛋白质的彻底的难题。这个难题其实直到现在还依然没有彻底的解决，没有被彻底的解决，只是它的性能不断的在被改良。如果有一天蛋白质折叠这个难题被神经网络彻底的解决了，那么很多疾病的卡点就没了。因为蛋白质大家注意，蛋白质它是刚出来的时候它就被折叠了，它就折叠了，就一下子就塌缩了。就塌缩了、塌缩完这个过程特别短，所以很难被捕捉。折叠了一下子就塌缩了、塌缩完这个过程特别短，所以很难被捕捉。折叠完之后你很难知道折叠完之后蛋白质里边每个氨基酸的 XYZ 时空坐标。而蛋白质折叠的外观它决定了蛋白质的功能。所以如果你能够知道，你能够通过某种算法能够知道蛋白质是怎么折叠的，那么你就知道了蛋白质是怎么折叠的，那么你就知道了这个蛋白质是什么功能。那么你自然你在医药研发的时候你就可以定向的去造相关的药。所以只要蛋白质折叠这个问题就解决了，那么医药很多卡点就解决了。

但是当目前为止蛋白质折叠这个谜题就是一个难题，它在不断的攻克、在不断的攻克。所以这也是一个非常非常大的突破。它比之前呢，之前其实是没有在这个领域去应用这个神经网络的。所以这也是一个非常... 在医药领域也是一个很大的突破。

所以你会发现到现在为止的神经网络基本上遍地开花，基本上哪一个领域都能用神经网络重新来一遍。尤其是现在的大模型、大模型。那么大模型我们相关的讲解呢我们会放到下一节课进行仔细的讲解。大模型那么大模型我们相关的讲解，我们会放到下一节课进行仔细的讲解。大模型相关的基于 Transformer 架构的 AlphaGo, 基于 Transformer 架构的大模型，它们之间... 它们应用神经网络，它们是怎么应用的？它们的难题是什么、难题是什么？我们会放到下一堂课... 下一节课的重点讲 AI 时代的当今的发展和它未来会怎么演化。

那么到现在为止基本上我就给大家把深度学习，也就是人工智能 AI 时代从最开始感知机、第一代感知机一直到现在，其中关键的起点给大家罗列了一遍。然后其中的一些关键论文也给大家呈现。所以非常提纲气灵的给大家呈现。所以大家如果听完我今天的讲解之后，你再去读《深度学习革命》这本书，你应该会有一个非常一个整体性的认识。所以到现在为止大家会发现连接主义压过了符号主义。

但是非常有意思的是什么呢？虽然我们用的是神经网络，但是你驱动神经网络的算法，这个底层模型你这个代码是怎么编的，你依然是用程序符号编的。这是非常有意思的。所以我们不是说符号主义不好，符号主义它是基于逻辑的、基于规则的，它能够非常清晰简洁的表达。但是对于这种自然语言处理、图像识别，这种神经网络它是一种模糊的表达，它的可解释性很弱。它的可解释性很弱，但为什么神经网络最开始在算力没有那么强的时候，大家都不觉得它能走得通？大家都不觉得神经网络能走得通、大家都没有神经网络能走得通这个信念，其实很大一个程度上就是因为符号主义它是非常清晰的、简洁的、逻辑的。而只有清晰的、简洁的、逻辑的，你搭出了一套系统，它最后产生的效果你就改良它的时候你才知道我该怎么改良，然后它做出的效果你才知道它的原因是什么。

但是连接主义神经网络它是模糊的，你搭了很多层神经网络之后，我改了改效果好了，我改了改参数、改了改权重效果好了。它为什么改了改权重、它的效果就好了呢？它的可解释性是很弱的，它是模糊的。所以这个我们会重点放在下一期课会重点讲解这个。

所以大家千万不要把连接主义和符号主义进行一个非常强烈的一个、一个、一个非此即彼的一个比较。所以就这两个... 这两个其实是一个... 这两个其实是各有... 各有去公用的。大家去理解它的话，其实只是要去理解它的路线是有纷争的，但是这两种方法是我们在如今的 AI 时代是都要去应用的。连接主义这种神经网络它提供了一种模糊性的智能，模糊性的智能它可以去解决那种非常复杂的... 能力它可以去解决非常复杂的问题。但是符号主义它提供了一种非常简洁的表达，非常简洁的程序，它能够让我们不仅能够知其然，还能够知其所以然。所以两者一定要结合的。

所以你会发现我们连接主义的这种神经网络的算法的代码，它依然是用程序符号编写的。所以这是给大家的一个启示。

所以第二节主要就讲了深度学习、AI 时代它是怎么演变的，它的过去是怎么发展的。那么第三部分给大家补充一个，是这是在这本书中没有提到，但是这也是辛顿这个人在去年 2023 年一个非常非常大的转变。也是辛顿这个人在去年 2023 年一个非常非常大的转变，就是辛顿想法。就是他本来之前是对神经网络是有非常非常强的信念的。他的信念... 他坚定的认为人是可以通过这个机器是可以通过模仿人的大脑的这种工作方式可以来从数据中来学习。(抱歉我喝点水)

所以他认为神经网络就可以模仿人的大脑，可以从数据中去习得大量的规则、自己去习得大量的规律，能够更好地处理这种复杂性的问题。这是他非常非常坚定的信念。但是甚至他觉得有些任务这个机器其实比人会做得更好，有些任务机器已经远远超过了人类本身的智能。

但是在 2023 年，辛顿和他的学生，最典型的一个学生... 我们会下堂课会讲到，也是刚才我讲的那三个人就参加比赛的三个人中间的一个伊利亚，就是那个学生，他 OpenAI 的创始人，OpenAI 的 GPT 也是他一手创建的。不过他们这些人就辛顿这一派，他们成为了 AI 的保守派。他们认为当前的 AI 智能 AI 这个智能开始变得越来越危险。他们认为本来以前他们觉得这个事还早着呢，可能得 30 年 50 年这种危险才值得去考虑，但是现在他不这么想，他觉得可能现在它就已经在演变成一个新的智能了。

所以你会发现新的在去采访他的时候，他经常会安慰自己说，他会有对自己的工作有点后悔，有点后悔。他觉得他是... 他怎么安慰自己呢？他说即使我不这么做，也会有人这么做的。以这个借口来安慰自己说，其实我之前做的那些工作还是能接受的。所以说什么呢？所以其实新的他是对他之前对人工智能这个非常重大的贡献是有些后悔的。

那么为什么新顿在 2023 年发生了一个非常 180 度的一个转变呢？因为他其实看到了 AI 对我们当今的一个时代的一些威胁。比如我们第一个他认为的一个威胁就是虚幻真实的威胁，虚幻真实。他认为什么呢？他认为互联网他以后会充斥... 因为他这种长文组模型他能够生成大量的内容，那么这种图片模型他能生成大量的图片。那么生成大量的图片之后，那么生成大量的图片之后，那么是不是我们普通人，我们一个 AI 在生存的一个人，他其实就不太知道哪些是真实的了呢？

其实在当今时代大家可以想一想，我们是如何判断哪些事情是真的，哪些事情是假的呢？当然不仅仅是逻辑上能说得通，还有一个重要的工作就是交叉验证，就是我们从这个地方获得的信息，我们可以从其他地方、从网络上可以交叉验证一下来判断。从这个地方获得的信息我们可以从其他地方、从网络上可以交叉验证一下来判断我们现在所获得的信息是真的。

但是如果大家想一想，如果互联网上 99% 的内容都是由 AI 生成的，那么交叉验证这项工作的意义也就失去了。大家注意，AI 生成的内容它可不是胡乱变的，它也是符合逻辑的，而且是更符合人类的这种表达方式所生成的内容。它可不是胡乱变的，它也是符合逻辑的，而且是更符合人类的这种表达方式所生成的。

所以当 AI 所生成的历史，当 AI 所生成的经书，当 AI 所生成的古典都无法辨别真伪的时候，那的确可能会对人类的文明产生冲击。所以即使 AI 不具备那么高级的智能，只要它具备能够生成、能够生成这种合乎逻辑的、更符合人类表达方式的内容，那么本身就是对人类文明的一种威胁。因为当互联网上充斥 99% 的 AI 生成的假的内容的时候，你很难再去辨别哪些是真的、哪些才是假的，因为你交叉验证失去了意义。所以这是西诺所认为的 AI 所带来的一个很大的一个威胁。

第二个威胁就是当然这是一个老生常态的一个威胁，就是对就业的威胁，就是对就业的一个威胁。就是很多人也会这么认为，AI 将会最终颠覆就业市场。这个其实你甭管是哪个技术出来的话，它都会这么威胁。

当然还有一个威胁也是新的他自己比较当心的，他觉得有一天自主武器会对人类构成威胁。为什么呢？因为他发现 AI 系统它不仅能够自己生成代码，它还能够自己运行代码。如果一个 AI 系统能够自己生成代码，它还能够自己运行代码，如果一个 AI 系统能够自己生成代码还能运行代码，那么这种杀手机器就有可能成为现实。

所以你会发现辛顿他的思考当然会遭到很多人的反驳，但是这种思考也是他自己合乎逻辑的一个推理。那么他本身是怎么解的这个问题呢？他觉得你看他有这个这个 AI 时代上的很多假内容，AI 时代又... 他的技术呢又又需要很多的把关，那该怎么去解决这个问题呢？他认为应该引入全球、全球化的监管。但是呢他... 他认为这个方式又不太靠谱。因为呢... 因为这个... 他之所以引入全球监管这种方式呢，是想仿照原子弹、核武器的方式的。但是 AN 武器和核武器很不一样，核武器你是知道哪些国家在造的，但是 AN 武器你是不知道哪个国家、哪个人在造的，可能科学家躲在哪个地方就可以造出来了。

所以他最后其实是呼吁世界上的其他科学家在这种控制技术方面进行合作、进行相关的监管。所以星盾在 2023 年就从谷歌辞职了，从谷歌就离开谷歌了。那么他离开谷歌干嘛呢？他专门就干这件事，专门就呼吁科学家去警惕 AI 的风险。包括 OpenAI 的创始人伊利亚，伊利亚就是他的新的那个学生，他和新的是一派的，他们都是 AI 保守主义。所以你会发现在那个去年这个发生的那个 OpenAI 的发生的那次很大的一个逼宫的那个事件，其实也是一个 AI 保守主义这派想法的一个具体的一个体现。所以这是新的本身的当前的他所处的一个对这个 AI 本身的一个具体的体现。所以这是星盾本身的当前的他所处的一个对 AI 本身的一个理解，一个他自己的想法。

那么我们给大家的理解是什么呢？其实 AI 时代已经开启了，甭管你自己在不在这个时代里边，甭管你自己愿不愿意参与，它已经来了。所以我们的态度是什么？与其你自己去担心它，不如你去拥抱它、你去参与它。所以我们会在第三讲... 今天是第一讲，下一讲我们会着重讲 OpenAI 公司以及大模型当前的发展。第三讲我们会着重讲作为一个求职者，作为求职者的个体，你在 AI 时代中你自己该如何参与。所以这是我们的态度，与其担心，不如参与。

好，谢谢大家。这是我们今天讲的 AI 时代的整个的历史的脉络。