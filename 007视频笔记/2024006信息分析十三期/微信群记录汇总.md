## Week01微信群记录

2024-01-21

狗霸收藏的老阳知识星球灌水内容汇总。

阳志平的主题

2022/4/16 22:27

\# 教学笔记在真实世界，你碰到的信息分析问题，往往具备两个特点：

1、关键词是模糊的，甚至是错误的，因此，你需要定义更清晰的关键词，找到更准确的关键词。

2、问题是似是而非的，甚至是故意误导的。因此，你需要对问题进行更清晰的定义。利用自己能找到的信息质量最高的信息网络，从而快速求解问题。

多年前，在认知写作学课的第一次作业，我故意设计了一个有点「坏」的作业，考察同学是否意识到写作的第一课：将任何接触到的写作题目，都变为自己擅长的写作方向。而非老老实实按照写作题目去写。这是成年人写作不同于应试写作的第一步。

同样，这一期信息分析几乎所有每周小作业也是这么设计的。需要你自己更精确地界定搜索关键词、定义信息分析问题、界定信息报告方向。不同同学的作业提交结果不一样，都是许可的。因为跟你使用的关键词、定义的问题有关系。

阳志平的主题

2022/4/16 22:35

\# 教学笔记摸透常用信息源的秉性。

常用信息源一般包括搜索引擎、数据库、专业网站、占据信息中介节点位置的人等等。不同信息源有自己的秉性。有的热情似火；有的高冷傲娇。你不要与任何一个信息源打交道，都用一套老方法。一般来说，摸透一个信息源的秉性，最快速的方法有三：

1) 读官方的说明文档，也就是「关于我们」、「使用帮助」那里。阅读这部分时，尤其要找到该信息源已经包括了哪些领域的信息，各自数据集大小是多少，也就是信息网络的边界。

2）使用你熟悉的领域验证。比如，在一个陌生的新的学术搜索引擎，你不了解该搜索引擎的秉性，那么不妨先用你最熟悉的学科

来测试。

3) 最快速度找到高级搜索、专业功能等选项。通过这些专家才使用的高级选项，大体上能看出这个信息源的侧重点。

当然，还有一些高级方法。比如，看看信息源支持的协议。MARC 协议就是最常用的一种，如果支持最新版，显然这个信息源更先进一些。

阳志平的主题

2022/4/16 22:50

\# 教学笔记搜索出来的结果太多了，看 20% 即可。

找出来的信息量过大，使用搜索表达式或高级搜索设置，不断缩减信息量。但求全与求准会产生矛盾。因此，也不要太刻意。最佳的方法是快速扫描其中的 20% 信息。

比如，今天下午演示时，国家图书馆的图书书目检索系统，我们以「情报分析」为检索关键词，限定语种为「汉语」, 检索出 76 条书目信息。那么，你取 20% 就是 15 本书，就可以代表整个情报分析领域的重要书籍了。你既可以按照出版年代排序，找到最源头、最新的一本书；也可以将书目按照引用次数整理，找到引用最高的一本书；还可以按照作者整理，找到在该领域出版图书最多的作者。

同样，在谷歌搜索引擎中，搜索出来的结果 100 页。那么，20% 的就是 20 页。你换用不同条件，快速看。最终得出的信息质量往往会不错。

阳志平的主题

2022/4/16 22:51

\# 教学笔记信息分析五问。在任何关键领域的信息分析工作，一上来可以问自己五个问

题：

1、我要分析的信息处在哪个信息网络中？这个信息网络有多大？是正态分布还是幂律分布？

2、我要分析的信息的时空变量规律如何？

3、全局认识：我如何建立一个更具备整体性的认识？找到别人不知道的，更高阶、更

具备整体性的知识？

4、交叉验证：如何兼听则明？

5、有趣度：如何找到小众而高价值的信息？

阳志平的主题

2022/4/16 22:10

\# 教学笔记理解信息网络的边界的重要性。

几乎人类所有信息，都是处在一个更大的信息网络之中。一篇论文处在共被引网络之中；一个公司处在股权投资网络之中；一个人处在人际网络之中。人类常常容易将信息网络看作是无穷大的，因为人类大脑不善于处理过大的数值。超过你熟悉的数值区间，你常常就将其看作是一样的事物。比如，我们人类大脑感知时间，一般是三个月是一个临界值。超过三个月，无论是一年，还是三年，还是十年，还是三十年，对我们的大脑来说，处理信息的方式几乎一致。

但，一年、三年、十年、三十年有区别吗？显然，区别很大。

韭菜与套利者的信息分析能力的区别，常常不是在处理三个月的信息，而是在处理超过三个月以上的信息。以学术信息分析举例。

我们在日常生活中，常常只能接触到分析 10 篇、100 篇论文、下载 10 篇、100 篇论文这种场景。但是，一旦将你的信息分析目标提高到：分析 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文，

那么，你马上发现自己之前习得的信息分析流程、框架，漏洞百出。你之前掌握的信息分析技巧，仅适用于处理 100 篇论文。一旦超过 100 篇论文，对你来说，完全抓瞎了，只能采取笨方法。

如果你掌握了一个既可以适用于分析 100 篇论文，还可以分析 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文的通用信息分析框架、流程，显然，你的信息分析能力会大大不同。同样的时间内，你的同行只能看 10 篇论文，你能看 1000 篇论文。那么，你自然拥有更多灵感、更多创造力、更多素材。

那么，这个通用信息分析框架、流程是什么呢？先说框架。这就是我提出的：时空变量的信息分析框架。

1、时间：这 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文，

1) 按照时间周期：最源头的是什么？最新的是什么？

2) 按照某年 / 某月：哪一年是这个领域发论文的高峰期？

2、空间：这 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文，

1) 按照地域：哪些国家？哪些城市？哪些机构？

2) 按照空间隐喻：这些哪些是最重要的本体是什么？

3、变量：这 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文，

1） 按照包含关系：谁是最关键的论文？提出了什么概念？这些概念从属于谁？它们又包括了什么子概念？

2) 按照相关与因果关系：这些论文涉及的变量，谁是关键变量？它们又影响了哪些因变量？

再说通用的信息分析流程。

再说通用的信息分析流程。

1、信息获取：如何快速下载成功 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文？

2、信息整理：如何在本地存储 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文？并且能快速抓取 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文的元数据？如何对这些论文进行分类？

3、信息加工：如何从本地存储的 1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文？论文中快速提炼出知识或认知？

4、信息报告：如何将提炼出来的知识或认知，报告给大家？哪种报告方式，更符合人类大脑信息加工规律？

以上，这就是高效打通任何一个信息领域的硬核技能。

阳志平的主题

2022/4/16 22:17

\# 教学笔记快速估算任意一个信息网络的边界。

人们常常没有意识到，一个再大的信息网络也是有边界的。一旦你明白，一个数据集有多大，比如，微博每天发表 8000 万条左右；抖音每天发表 6000 万条左右；微信公众号每天发表近 200 万篇文章；B 站每天发表 20 万条左右。

一个看似无穷大的数值变成一个有边界的数值区间了，是不是才谈得上下一步的信息获取、信息整理、信息加工与信息报告？

多数时候，你并没有太多时间成本、经济成本去获取到一个信息网络的边界。此时此刻，你要使用快速估算技巧。放弃追求完美的心态。一个相对模糊的数值区间，也比没有数值好。

在快速估算时，精确的数字远远不如估算正确的量级重要。比如，你研究的领域，每年新增论文数量究竟是多少？我相信绝大多数人，从来没核实过这方面的数字。

1 万篇论文、3 万篇论文、10 万篇论文、30 万篇论文是不同的量级。决定了你在不同领域的套利空间、信息获取方式等等。

---

Q-himi：全局认识的边界是什么意思啊？通过清单怎么获得？怎样的清单？

A-狗霸：

简单理解边界是信息网络的边界，就是你所要寻找的信息在什么网络中，这个网络多大。

上面的笔记最后两张都是关于信息网络边界的，可参考。

清单，接着看视频，后面都有讲解。

包括这一讲有一个实践策略的视频，是更实际的操作讲解。

可以像侦探一样学信分，前面尽可能找线索，有好奇的地方像这样提出来问题就很好，然后随着课程的深入一点点破案。

---

Q-Allen：

很同意这一条，其实类比日常工作当中 sizing problem，就了解一个信息边界可以快速确定需要抽样的范围以及投入的经历

比如说，如果某个学科论文或者之类的数量是一万，那么可能看完 20% 的 10% 就可以了，就大概知道什么时候应该 quite 或者 make a pause。

其实不论是清单还是其他，都是一个建立好的有效样本集合，意思是这个样本里的东西大概率是可以先仔细看过一遍的，或者相比整个 whole population 来说可以节省时间。

这样推演，其实就可以看有什么已经建立好的清单或者干脆自己建立一个清单。

一个比较有趣的玩法是用 python 或者其他爬虫工具设置 twitter 的关注列表自动推送，这样对某个话题的 sourcing 其实也是个清单。

感觉不用拘泥于到底用的啥术语，感觉更重要的是背后的逻辑，我觉得是抽样和筛选。

---

Q-鱼干：

信息分析就是从未知到已知的过程，你可以变换关键词搜索一下。行动获取信息，比如，GitHub 的帮助文档里是否有信息，awesomelist 官方列表是否有信息？

批量查看 awesomelist，你就构建了对 awesomelist 的认识。

---

2024-01-26

Q-Allen：

问问大家，那个 zotero 的模板大家一般是怎么用的呢，就到现在还是有点不太习惯，不知道特定的网页应该放哪儿。

就相比以前用项目式管理 zotero ，现在有点无从下手。

比如说吧，有一本书关于神经科学是我正在学习的内容，我是放在 my library 还是 my learn 呢，这中间其实有不少 overlap，而且所有的都是 collection 而不是 filter，就 obsidian 的 collection 是排他性的，就我其实不太清楚碰到这种冲突的情况应该如何处理。

然后那个 study room 是啥意思呢。

或者按我的理解，my library 应该是一个 saved search 的入口，而不是按照 collection 的形式呈现，它的目的应该是用 metadata 来筛选特定的数据。

但导入 zotero 以后就变成了 collection，所以想来确定一下是不是我前面想的那个逻辑还是说有其他的逻辑，或者是导入的时候出错了。

A - 曦晴：zotero 一个条目可以放在多个文件夹。条目是唯一的，文件夹可以当成另一种形式的标签。

所以说，需要定期整理 zotero ，然后选定多个文件夹来放条目。

或者收录的时候就把元数据或者条目弄清楚。

阳志平

2021/3/4 20:23 北京

Zotero 几个目录的说明: 1) O.Daily: 保存每日阅读，随手记；2) A.MyNote: 保存写的读书笔记、写作灵感；3) B.MyCreate: 个人的作品。按照作品类型分类。然后依据作品属性，分为正在进行的项目、归档的项目、灵感三大类。4) C.MyLearn: 个人的学习系统：保存别人的作品，分成认知科学、阅读、写作、思维、文化、人生发展、儿童发展、软件开发、商业管理几大类。保证自己在每一个大类上与时俱近。其中，认知科学、阅读、写作、思维是自己最强的四大领域。文化主要涉及新道学序列，人生发展主要是指开智相关、儿童发展主要是指爱贝睿相关。软件开发主要涉及一些开源软件与专业软件。5) D.MyLibrary: 个人藏书。包括纸质书与电子书。以及个人开设的各类书单。还有爱贝睿文库、开智文库出版的图书、即将出版的图书。6) E.MyLife: 个人生活。健康、育儿、旅游、美食、趣味、朋友等等。

Q-鱼干：

看阳老师的这个记录。其实是这个逻辑。

@长三角大区-Allen 感兴趣可以用 zotero 作为关键词检索安人书院。

2024-01-27

Q-Allen：

翻完知识星球关于 zoteer 的介绍

刚好把收货分享在这里

1、根据杨老师的思路魔改自己的系统。

把 zotero 作为别人内容或者自己已经完成内容的归档。这个包括日常读的文章、podcast、书 etc

关于自己的部分，包括做完的项目，这又进一步包括了工作上的项目或者全屏兴趣的项目，比如对某个特定主题的研究等等，可以理解成不同的信息分析报告

然后正在进行中的项目或者大部分笔记还是放在 obsidian ，依托 obsidian 和 zotero 的插件同步信息和引用，这样就做到有据可查，又结合 obsidian 更自由的文件管理和 dashboard 功能，结合 dataview 在效率和定制化上面比 zotero 更好。

另外 obsidian 本身就是一堆 markdown 文档和 js 脚本，迁移起来也方便，而且至少现在软件也算开元。

本来想用 tiddly wiki 但目前 tiddly 还是个 html 文件，虽然运行了快二十年也一直有很好的社区支持，但关键是和外部的格式互通还是没有 zotero 或者 obsidian 那么方便。

2、关于信息污染。

这也是为什么把知识管理工具和写作工具分离开的原因

就相当于区分了两个场景，一个拿来创作一个拿来归档和整理，进入这两个系统的时候带有的 mindset 也不一样

本身就知道 obsidian 的东西是迭代的，也更好方便增删，但等到一定的时候就放到 zotero 归档，之后如果想起来还有新的重要的值得归档的更新再用 changelog 来增补。

另外拓展一点杨老师在知识星球聊双链笔记时候的话题

就关于人类的认知结构是时间和场景记忆加上模糊搜索

一个很现实的问题，如果用时间戳来作为笔记的唯一编码，然后依靠全文检索来唤起记忆，那怎么定义搜索关键词呢

一个特定的关键词肯定不能检索到所有可能存在的笔记，或者使用的关键词和当时输入的不太一样

那是不是意味着其实这种遗忘是不可避免的，或者说其实不需要担心，因为随着进一步联想和搜索的展开，其实需要的信息肯定会自然呈现。

另一个心得是就算有很多笔记被反复记录过，其实也不用担心重复，就这种反而是某个节点被加强记忆的很好证明，就表示在大脑中被提取了更多次。

Q - 鱼干：用私人大模型来做这个显然快很多。

Q-Allen：这个确实，gpt 有个插件结合 obsidian 也能做到一点点，就是提取笔记库，然后根据模糊的搜索或者问题智能给出最相关的笔记建议。

这篇杨老师的旧文感觉是对上周讲的信息边界抽样的很好的演示

这里面感觉说到了不少好内容，包括清单、基本单位等等

https://www.yangzhiping.com/psy/meta-learning.html

Q - 鱼干：

搜搜这篇 @长三角大区 - Allen 构建优雅的知识创造系统。

现在暂时跳过这个话题讨论吧，咱们是信息分析。

