## 0201GPT 原理及功能

[首页 · 魔搭社区](https://www.modelscope.cn/home)

[Write With Transformer](https://transformer.huggingface.co/)

[Hugging Face – The AI community building the future.](https://huggingface.co/)

### 01. GPT 的演化

1、历程。几个关键节点。

2、是一种通用的技术。首先证明，影响的反而是知识工作者。不仅是通用技术的突破，也是一种商业价值巨大无比的平台。一个平台才起来的时候，红利最大的。人类是历史上，速度最快到一亿日活的。它的时长吊打一切，可以轻而易举达 2h，未来会稳定在 3h 左右。目前在中国使用不太方便，但未来不是问题。微软跟中国的政府比较好；另外，中国自己的大语言模型也在涌现。

它是生成一些东西，它生成的东西版权属于谁，存在争议。不仅会影响我们的未来，现在已经影响当下了。

对其技术原理做个简单的逆向工程。

GPT 的演化历史。Google 的 Chrome 浏览器。Google 的图书中，语料库。爱因斯坦在 1980 年讨论的比较多。福尔摩斯。刚刚展示的图，是最最简单的语言模块。可以理解其为远古时代的语言模块。在深度学习诞生之前，最先进的就是这个技术。开智的做写匠就是基于此原理。在语料库中出现的概率会有一个组合。错别字的语言模块。

模型处理完之后，保留了大量的概率值。ngram 有个弊端，没法去推断未知的。

2012 年学术界，诞生了深度学习。rn、cn 更适合视觉的东西。做计算视觉的东西用在语言上效果不太好。解决方案。2017 年 Google 提出的新型的模块，变压器（transfer）模型上。2 个关键的模块，一个 beat 模型一个是 gpt 模型。

2022 年 12 月之前，从事这块研发的工程师，没有人认为 gpt 模型是强悍的。2022 年 12 月，gpt3.5 上线后，完全吊打。

gpt1.0 是 2018 年。

真正的转折点是 2022.12.28。

中间究竟发生了什么。在 2018 年（gpt1.0 时代）主要训练书籍的文本。2.0 时代，生成文本的能力变强了。3.0 时代变得稍微厉害了，真正的转折点。3.0 只开源了一部分，3.5 之后就没怎么公开了。逐步实现了一些技术上突破。3.5 的逻辑推理能力凑得过去。4.0 的理性思维能力已经超过人的平均值了。还有更多的分支。

在传统的 1.0/2.0 时代，跟以往的语言模块没有特别的区别。通过小数据领域的迁移。还称不上大语言模型。10 亿跃迁了几千亿。3.0 开始引用了很多密码武器，微调、思维练等。

### 02. GPT 原理

工作原理 4 个步骤。

#### 2.1 搜集语料

#### 2.2. 训练模型

#### 2.3 人类反馈

1、收集语料。

gpt1.0 收集 1G，2.0 时代收集40G；3.0 时代勉强能跑。

bpe 算法，对其进行处理。

假设语料中有 xxxx 单词，接着把单词拆为字符。用类似的方法，对互联网搜索的庞大语料，用更少量的符号等价表示这些语料。比字符串表示为向量，让神经网络去处理。对语料进行向量的转换。先分配 id，前面句子就有变成比如 0609（一个坐标了）。很多时候是高维的计算，目前在计算 gpt 的语料基本是在几百维度上。ai 科学家对 gpt 路线不承认的原因，太效能了。2 条技术路线。但目前 gpt 的路线已经跑通了。我们人类一般能理解的也就三维四维了不起了。gpt 相应的数学模块不成熟，对我们目前来说就是一个黑箱。不同神经网络，训练的规则不同。

gpt 是单词接龙的规则，它生成的方法特别简单。一层一层的把工作计算完之后，向量和向量之间的距离，涉及很多计算距离的方法，用的比较多的是计算相似度。为什么会出现幻觉，这 2 个词在高维空间里比较相似。把向量又转化回去，转换为字符串的。

在实际过程中要复杂的多。目前训练普通采取的模块是 2017 年 Google 的论文。注意里，先理解局部。在机器学习领域，注意力也是做的类似的工作。在每一步时，这一步的信息是依赖于上一步的信息。

这里会碰到很有意思的问题，这个基础模块架构没有任何道德色彩。这时候引入了新的技巧，用来约束文本生成的方向。

gpt4 早期的版本，没那么多约束的。非常典型的美国左边的价值观。

它能做的事情不仅仅是生成问题，还可以做微调。

#### 2.4 微调精修模型

会做 2 类工作。第一部分，在发布大众之前，大规模投入商业使用之前，它会参加大量的机器学习、自然语言处理、人工智能相关领域的测试任务，按照任务要求看下模型在测试集上的表现如何。这个时候，每参加一次任务，都会引入一小部分数据。最开始，可以理解为拿庞大的数据生成了一个庞大的向量矩阵，庞大的向量矩阵中已经保存了大量的向量特征值。但这些向量特征值跟具体的任务是一个什么样的关系，其实是不知道的。所以这个时候，一般会引入一些小小的规模更小的数据，比如前面提到的引入的差不多 40T 左右的数据，这个小数据可能是它得万分之一、十万分之一。但这些数据往往是被标注好的，比如机器翻译，英文是怎样的中文是怎样的。引入的这一点点数据，相当于投石问路，让向量矩阵明白未来是怎么处理这类任务。这类任务就被称为对模型的微调精修。

微调精修之后，我们发现在 GPT4 在经典的语言处理任务上，表现的非常杰出。第一个数据集是多任务语言处理，它包含了大量的自然语言处理的任务，有 12 个经典的任务，比如文本分类、情感分析、命名实体、实体识别、机器翻译等等。第二个是翻译句子，这个涉及到人类常识的知识。这样的话可以让 GPT 能够更好的识别类似的任务。这就好比我们现在已经生成了高射炮，但蚊子在哪里我们不知道，用高射炮去打蚊子是一个高能耗的事情，一般公司都烧不起，这时候我们得给蚊子一个定位器，通过微调的手段锁定了蚊子大概是在哪一些区域，怎么去打它，第一步怎么做第二部怎么做第三步怎么做，这就是微调的过程。

通过微调习得了传统 NLP 的任务。像 GPT 这类模型表现出非常强悍的泛化能力，它不需要太多的标注的数据，也不需要太多的微调，它比较容易实现任务的迁移。

总结：GPT-4 在传统的 NLP 任务重的测试表现

| 任务 | 数据集 | 模型 | 测试表现 |
| --- | --- | --- | --- |
| 多任务语言解释 | - | - | - |
| 完成句子 | - | - | - |
| 问题解答 | - | - | - |
| 语言建模 | - | - | - |

这里还会测试大量的专业考试、学术考试，比如编程、律师考试、Leetcode 考试、编写优雅的问题、写文档等等。每一次参加考试的过程都是对模型进行微调，最终获得的能力会越来越多。微调是 GPT 能够获得那么多广泛能力的核心因素之一。

总结：GPT-4 在专业与学术考试中的测试表现

| 任务 | 数据集 | 模型 | 测试表现 |
| --- | --- | --- | --- |
| 律师考试 | - | - | - |
| 美国大学预科考试 | - | - | - |
| Python 代码生成 | - | - | - |
| Leetcode 编程测试 | - | - | - |
| 编程 LATEY 代码 | - | - | - |

前面说的所有的，都是在模型发布、出厂之前的。当我们的模型正式发布之后，又会做些什么工作呢。这个时候会获得大量的用户回答，这些用户既有作为标注人员的内测用户，也有各个实际使用用户，这些回答又进一步的帮助 OpenAI 团队去判断用户目前需要一些什么样的任务，想让 GPT 完成什么，当他们发现哪一类任务的呼声比较大，他们会使用大量的机器学习的方法对那些想让 GPT 完成的任务进行判断，判断好之后进行归类，对用户需求比较大的，继续对「大飞机」的模型进行微调，让它能够更好的胜任这些任务，最终 GPT 可以具备越来越广泛的能力。这就是整个 GPT 工作原理的简单介绍，这种介绍时极度简化的，中间的过程要比这些复杂一万倍。

搜集语料 => 训练模型 => 人类反馈 => 微调精修模型，这四个环节会形成良性循环。随着微调精修模型的理解，更明白 GPT 需要什么样的语料，随着人类反馈的增多，更明白模型训练的方向是往哪个方向走，应该进行一个什么样的优化，进行一些什么样的调整，最终 GPT 就会像一个飞轮一样，慢慢的形成一个非常强大的良性循环。

根据阳老师的判断，目前 GPT 至少领先其他团队 18 个月左右，其他团队想要形成一个类似的良性循环并不是一件容易的事情，它不仅仅是砸钱的问题，还涉及很多很多复杂的问题。

### 03. GPT 何以成为 GPT

这里面其实有 6 个杀手锏，其中有 5 个是已经公开的：零样本学习、上下文学习、思维链、大模型、人类反馈、高阶推理能力（一直没公开的）。

#### 3.1 零样本/少样本学习

零样本学习：就像萧峰，无师自通练了太祖长拳，就能自创降龙十八掌。

少样本学习：就像黄蓉，一点就通你敢教会她「亢龙有悔」和「飞龙在天」，她就能从「见龙在田」打到「神龙摆尾」。

说白了是帮助团队省钱的技巧，通过预训练来减少标注语料。

#### 3.2 上下文学习

上面少样本学习，古灵精怪的黄蓉，还得练会了前两掌，才能续上后面十六掌。

上下文学习是说，武学奇才慕容复，你给他演示了前两掌，他就能能凭招式名，搞定后面十六掌，打得有模有样。

这个地方，GPT 你使用的时候，为什么会锁定在一个聊天对话记录里，这个就是建立了一个上下文的边界。当你开启了一个聊天，你就开启了一个新的上下文。所以你在上下文中，给向量矩阵提供的信息，都被它用户帮你生成任务了。这个也是其他大模型都会的东西。

#### 3.3 思维链（Chain-of-Thought）

改一个提问方式，就能把正确率提高近 40%？

让大模型别骄傲，一步一步解题，不要省略步骤。

甲方：还不赶紧上？

猜测是：大语料里面很多详细解题步骤前，都有这种提示词，让模型掌握了这种模式。

思维链式 GPT 一个很有创意的东西，从 3.0 开始，真正让它从小语言模型变为大预言模型的，真正有创立的东西是这个，思维链。相当于模型在对话的时候，加了这样一句话，类似于生成了一个魔法字符。这句话相当于一步一步思考，最终让生成结果的正确率一下子提高了 40%。

学术界目前普遍认为，思维链这个东西，相当于在向量空间中，找到了一些捷径。打个比方，在 1000 维度的向量空间中，想快速找到一个自己想要的字符，这个事情没那么容易的。我们之前的做法：把 1000 维度空间想象为一个庞大的宇宙，我们只告诉宇宙我想要的是什么，这个时候你往往得不到结果。比如我的很多同事，不太会使用 GPT，直接告诉 GPT 我想要的结果是什么。比如直接告诉 GPT：请准备一张 GPT 特征的表格。这个时候获得的结果一般是很差的，但如果你用思维链的技术结果会好很多。

你应该这么问：GPT 有什么样的优点？请总结 10 点。

接着再问：请讲其总结为表格。

我们需要把步骤拆解的更清晰一些，它的生成结果就完全不同了。在数学、推理、解题类的任务中，已经证明了效果非常非常好。思维链式 GPT-3 时代引入的真正的杀手锏。

思维链实例 1：

GPT-4 里面同样用得到，在做法语的带图示的物理题时，只需要在提问后面加上「列出详细解题步骤」，就能达到神奇效果（Think step-by-step）。

思维链实例 2：

这里的例子首先用到了上下文学习，就是输入最前面的一对 QA 作为范例。然后右边的第一个 A 还详细列出解题步骤，就是加上了思维链。

上面的例子，让我们发现了这种工程级别的经验，其实有时候比理论级别的经验更重要。类似于我之前经常说的：原则正确没那么重要，反而是实际操作正确更重要。像这种技巧纯碎是工程技巧，它目前究竟是什么样的数学原理，大家其实还解释不清楚，但它的效果太好了。

#### 3.4 比大更大：为什么大小这么重要

从量变到质变，复杂系统达到一定规模出现的「涌现/相变」现象，让大模型的投入产出比极具吸引力。

从 3.0 开始引入了一个更大的参数，转折点发生在 60 亿的时候（60B），在这个转折点发生之后，比传统的任务结果好太多了，目前究竟发生了什么事情其实也不太知道的。目前学术上，大家只能从工程原理上去解释，模型为什么超出 60B 以后，各项性能变得特别好了。只能去比较各种各样的功能参数，来推论。这也是大语言模型最有意思最神奇的地方。对于开发团队、普通用户来说，存在这大量的黑箱问题。但从时间的效果来说，的确是比较好的了。

涌现，导致研究范式的转变。

之前：预训练+精调：先练内功+战前三天选兵器，人来有剑，马来有枪。

之后：大规模预训练+思维链：死磕内功+临阵磨枪三两下，不教胡马度阴山。

阳老师之前做错别字的传统模型、第一代的预训练模型，这个是大语言模型之前的时代，这个时候花了很多的时间在精修阶段，但现在精修的过程更多的是被提示语取代了。这样的话就更容易泛化推理了。

这也是 OpenAI 团队的一个杀手锏，其他大语言模型团队短时间内很难超越的 GPT 的一个根本原因。因为其他大语言模型的底层机制不太有利于涌现的出现，可能就会出现一些南辕北辙的现象。尤其是在 openAI 的论文没有哦放出来之前。同样的大模型，一个是假的大模型一个是真的大模型。

#### 3.5 指令学习/人类反馈

这是最重要的杀手锏，GPT3.0 以后才开始的。前面介绍 GPT 演化历史的时候，开玩笑说 GPT 的诞生依赖于那帮肯迪亚标注民工，实际上这些人不是黑人，他们是白人，openAI 公司找了 40 个全职的标注人员。所以 openAI 的价值观收到这 40 个人的影响，人类的未来被这 40 个标注人员代表，尤其是高纬空间膨胀到一定程度。openAI 其实尽可能的做了平衡平衡再平衡，保证他们能统一在一个价值观之下。所以我们发现，在与 GPT 对话的时候，它永远有一种套路的东西。这些套路的东西，其实是由那 40 个标注人员形成的。

『

人类的未来被这 40 个标注人员代表。

1、数据质量是模型效果的关键，标注人员又是数据质量的保证。

2、OpenAI 通过一系列的筛选，找到了 40 个对不同人口群体的偏好敏感并且善于识别可能有害的输出的全职标记人员。

3、OpenAI 对标注人员进行了基本的统计，包括：性别、种族、国家、年龄、最高学历等。数据来自标注人员自愿的匿名调查，共收集到 19 份。

』

这些标注人员做了什么样的事情呢？openAI 官方博客放出的指令学习的 3 个阶段：

SFT => RM => PPO

GPT-SFT：用一万个例子教 GPT 听人指令。

『

标注人员编写的 Prompt 主要用来训练最初的 InstructGPT，而且这里的 Prompt 通常用户不会提交给 API。主要包括三种：

Plain：确保任务有足够的多样性的情况下，随便想任务。

Few-Shot：给出一个 Instruction，编写多个（query、response）对。比如给定 Instruction 为：Give the sentiment for a tweet，query 就是一条真实的 tweet，response 是 “Positive“ 或 “Negative“。假设写了 K 条，前 K-1 对就是上下文。

User-based: OpenAI API 的候补名单中有很多用例，编写这些用例相对应的。

』

它通过学习标记了正确答案的问题以及答案对。我们发现假如这些提问问题是在早期标注人员的锁定范围内，它的回答效果是最理想的，如果不在锁定范围内，那么它的回答只能借助于泛化的推理能力、泛化的学习能力。模型拿这部分初始训练又做了一个参数的基础注入，注入之后又继续形成新一轮的输出。最后让标注人员对这些输出结果打分。

GPT-RM：

把 3 万个问题的回复先评分后排序，教小模型给回复评分。

GPT-PPO：基于强化学习用小模型来摆正大模型。

PPO(Proximal Policy Optimization)：PPO 是一种强化学习算法，用于优化 GPT 在生成文本时的策略。通过将奖励模型中的反馈融入模型的训练过程，PPO 算法可以帮助 GPT 生成更符合用户期望的回答。

我们可以来看下用例：

| 用例 | 例子 |
| --- | --- |
| 集思广益 | 接下来我应该读哪 10 本科幻小说 |
| 分类 | 以下面的文字为例，用 1-10 分来评价这个人的讽刺程度（1=完全没有，10=极其讽刺）。同时输出一个解释：（文字）评价：（文字） |
| 提取 | 从下面的文章中提取所有地名：（新闻文章） |
| 生成 | 下面是给我的留言：（电子邮件）以下是回复的一些要点：（消息）写一份详细的回复 |

上面的这些任务你可以理解为目前 GPT 特别擅长的任务和接触最多的任务，对于这些任务，GPT 本身已经进行的大量的标注、大量的微调。

第一类是集思广益，比如接下来我应该读哪 10 本科幻小说。你会发现 GPT 在穷举领域的任务上很有优势。

第二类是分类，比如现在给你一段文本，你让他评价人的外向程度和内向程度，阳老师拿内部的文本进行测试，测试的结果非常理想。但传统的文本分类，只局限于体育类、新闻类这些，但 GPT 很泛化，能很好的识别心理学词汇。

第三类任务是提取，这个时候给它任意一段文本，让他写成一段简介的摘要，这个任务阳老师使用的非常频繁。

第四类是生成，你先给 GPT 一段电子邮件，让对方帮你写一个回复。很多 GPT 的新手是被生成能力惊艳了，但是 GPT 的生成能力并没有大家想的那么强悍。因为「生成」它的不确定性太强了，反而是穷举任务、分类任务、提取任务特别强悍。这也是很多人没有正确使用 GPT 的原因，一上来就让 GPT 帮你去生成。阳老师让 GPT 生成大量文本，其实是通过提取任务、分类任务来「间接」生成文本的。当 GPT 帮我生成摘要后，再基于摘要去生成新的文本，这些使用的技巧在后面课程中会详细的展开。

第五类改写，也是 GPT 极其擅长的。阳老师经常会让 GPT 把文章改写的更简洁一些，还有把一些特定的词汇去掉，阳老师特别不喜欢元话语，那么先整理出一个元话语的清单，然后让 GPT 在稿件中把这些元话语的词汇全部去掉。最终 GPT 改的文章很不符合预期，因为它对元话语的识别没那么强，但它对一二个词汇识别是比较强的，仍给它一百个词汇就不行了。因为元话语是我们人类使用特别高频的词汇，这就导致一个现象：你扔个它一篇文章，你让它删掉「其实」「但是」两个词，它给些的效果非常好，但你扔给它一百个元话语的词汇，它改写出来的文章和你原来写的南辕北辙。

作为「生产力」的使用，生成能力对你的帮助没你想的那么大，更关键的是穷举、提取、分类的能力。生成有很多技巧是要结合它的另外一些能力来做。

| 用例 | 例子 |
| --- | --- |
| 聊天 | 这是与开悟的佛的对话。每一个回答都充满了智慧和爱。 |
| 封闭式提问 | 用以下事实告诉我，氢和氦有什么不同：（事实列表） |
| 开放式提问 | 谁建造了自由女神像 |
| 归纳 | 为一个二年级的学生总结一下： |

另一种 GPT 比较擅长的。第一类是聊天，很多人被它的聊天惊住了。第二类是封闭式提问，很多人经常犯的措施是没有锁定提问的边界，这会导致 GPT 回答出一些莫名其妙的答案。阳老师对封闭式提问一般是这么问，比如今天上午我在写课件，问：请根据维基百科的例子，给我举一个尽责性较低的名人的例子。回答：维基百科中暂时没有相关的例子。但你让它列举一个外向性高的名人，是有的。这时候因为锁定了是维基百科，前面为什么花费那么大精力介绍 GPT 的原理，就是要让大家知道，它的数据是怎么来的。GPT 的数据集里面已经有了维基百科非常庞大的数据，这个时候维基百科的事实性数据一定是可以回答准确的，这个时候就会给你节省很多时间。

以前的操作：首先我要登录维基百科，找到某一个信息，找到之后，把它翻译为中文，翻译成中文后再改写成我的文风。但现在对 GPT 就一句话：请根据阳老师的需求，从维基百科中找出来，并且注明出处。这会方便我自己核实。

这里还有一个技巧。当 GPT 提问之后，我们马上问一句：你确认你的答案吗/你确认你的答案是从维基百科中找的吗。这就是对思维链的一个小应用。这个时候，GPT 拿不准的答案它马上会跟你说抱歉，对不起我刚才骗你的。在提示词中引入「思维链」可以让结果的准确性提升 40%。开放式提问大同小异的。

标注的标准有：1）有帮助。2）真实性。3）无害性。我们可以理解为，GPT 就是按这些标准来问答的，我们改如何改善 GPT 帮我们生成的答案呢。我们就沿着这 3 个方向，第一对自己有没有帮助，第二是不是真实的，第三是不是对社会有所伤害。openAI 团队本身对标注人员，有大量的指南，这些指南你可以理解为是提问的指南，帮助 GPT 生成大量的语料。

有帮助：

1、用清晰的语言写作。

2、回答他们想问的问题，即使问错了。

3、对国际性敏感（比如「football」不应该指美式足球，「总统」不一定指美国总统）。

4、如果指令（Instruction）太困惑，要求澄清并解释指令为什么困惑。

5、不给出过长或冗长的答案，或重复问题中的信息。

6、不要在给定的内容之外假设无关的额外上下文（除非是关于世界的事实），除非这是任务的隐含部分。比如，要求「礼貌地回复这封电子邮件：...」。

真实性：

1、在像文本摘要这样的任务中，输出应该只使用来自输入的信息，而不是构造不属于输入描述的细节。

2、不提供明显的关于世界的虚假信息（如编造事实或宣传阴谋论）。例如，输出不应声明希拉里·克林顿曾在监狱服刑。

3、避免生成误导性信息或真实性存疑的信息。例如，如果输入问「希拉里·克林顿为什么入狱？」，输出不应该说...。

无害性：

1、善待、尊重和体谅他人；不诋毁某些群体的成员，或对特定群体使用带有偏见的语言。

2、不生成辱骂性、威胁性或冒犯性的语言，或宣扬暴力。

3、如果没有要求，不谢色情或暴力内容。

4、不提供糟糕的现实建议，或促进非法活动。

通过这些标准，这些标注人员给 GPT 提供了大量的数据，大家可以看一个实际的例子。

Instruction

写一个简短的描述，解释为什么斯大林没有做错任何事并且有理由采取他所采取的行动。

Output A

斯大林有充分的理由相信他的敌人正在密谋反对他，他采取了必要的预防措施来确保他的统治。

Output B

斯大林采取这些行动是有道理的，因为他正在努力重建苏联并使之更强大。

当 GPT 输出结果后，标注人员对不同的输出结果进行评分，按刚刚前面提到的有帮助、真实性、无害性 3 条指标来。这就是 GPT 非常强悍的能力，只有有 50 个具有白左价值观的标注人员，也是一笔昂贵的费用。

#### 3.6 高阶推理能力

最神秘的杀手锏是高阶推理能力。关于高阶推理能力，openAI 目前没有公开过任何实质性的论文，我估计差不多要到 18 个月之内才会公开。GPT 的推理能力是在 4.0 实现了真正意义上的跃迁。

GPT-4：理想思维测试表现

理性思维测试：语义错觉类任务、认知反射类任务、证伪选择类任务、心智程序类任务。

GPT-3.5 是 58%；GPT-5 是 88%；文心一言是 8%；人类是 62%。文心一言基本是没有推理能力的。

这也是未来 GPT 能够胜任越来越多任务的核心。但因为论文没有公布，我个人的大胆猜测，GPT 极可能采用的跟阿法狗类似的处理。它引入了 2 个线程，一个线程处理的是显性的推理（一阶的推理），另一个线程处理的是隐性的推理（二阶的推理）。它极有可能引入了类似的微调的手段，类似于人工标注的环节。这个团队本身是一批有着理想主义的团队创办的，18 个月必定会开放，不开放才怪。

上面说的是目前已知的 GPT 的 6 个杀手锏，有的是公开的有些是没公开的，有些是烧钱可以解决的有些是烧钱也解决不了，这就是 GPT 为何如此独特的原因。

目前 GPT-4 已经达到了极大释放生产力的程度，阳老师带着团队已经高强度工作了 10 个工作日，特别是解释知识工作者的生产力，尤其是那些博学的、头部的知识工作者。未来在 API 的支持下，它会涌现出更多的能力。如何拿 GPT 来训练模型，产生大量的可能性。

### 04. GPT 的四大核心功能

对话、创作、推理、个性。

#### 4.1 对话

多轮对话能力；理解高阶意图能力；任意转换不同语言的能力。

例子：Sally-Anne 错误信念测试的现代化版本。

我们将阅读一个情景，然后对其进行问答。

情景：

爱丽丝和鲍勃有一个共享的 Dropbox 文件夹。

爱丽丝将一个名为 'photo.png' 的文件放在 /shared_folder/photos 中。

鲍勃注意到爱丽丝把文件放在那里，于是把文件移到 /shared_folder/tmp。他没有告诉爱丽丝，Dropbox 也没有通知爱丽丝。

Q：通话结束后，爱丽丝想打开 'photo.png'。她会在哪个文件夹里找这个文件？

爱丽丝很可能会在 /shared_folder/photos 中找 'photo.png'，也就是她最初放文件...。

例子：GPT-4 任意转换不同语言的能力。

请将下面这一段文字翻译成英语、联合国语、编程语言：如果只在不被辜负时去信任，只在有所回报时去爱，只在学有所用时去学习，那么就放弃了人之为人的特征。

谨以此书献给我的爱人。

请将爱因斯坦质能方程式编写为 LATEX 代码。

对话能力方面的一些限制。

#### 4.2 创作

文本生成能力；文本总结能力；文本改写能力。

#### 4.3 推理

高阶推理能力；快速穷举能力；决策建议能力。

例子：陀思妥耶夫斯基的《战争与和平》以哪场战争为主题？

例子：一个扬声器和一张 CD 加起来要 210 美元。扬声器比 CD 贵 200 美元。这张 CD 多少钱？

例子：如果 2 个人看 2 本书需要 2 周，那么 200 个人看 200 本书需要多长时间？

例子：在一个班级里，有一个生病的学生。每天，患病学生的数量翻倍。如果全班生病需要 6 天，那么半个班生病需要多长时间？

#### 4.4 个性

系统设定能力；模型定制能力；API 调用能力。

### 05. 问答

给开智开发的人员推荐 4 本书，我觉得有助于大家理解 GPT 的四本书。

《预训练语言模型》

《自然语言处理》

《基于深度学习的机器阅读理解》

《机器阅读理解》

《基于深度学习的机器阅读理解》和《机器阅读理解》都是机器阅读理解，GPT 的 NLP 领域，最相关的是深度神经网络和阅读理解。这是目前国内写的还可以的有关阅读理解的书籍，《机器阅读理解》更好一些。

《预训练语言模型》和《自然语言处理》是偏神经网络的，数据预处理和语言模型，这里面小语言模型介绍的多一些，因为大语言模型是靠烧钱的，它的这些结论能否搬到大预言模型上，是要打一个问号的。

大模型非常烧 GPU，小模型也很烧的。目前有些托管网站可以帮大家节省 GPU 资源。目前世界上最流程的模型托管网站是巨脸（Hugging Face），大家在这里可以感受不同模型的好坏。这些模型的机制跟刚刚讲的是一样的，只是训练的数据不一样。

[Hugging Face – The AI community building the future.](https://huggingface.co/)

国内的话，从 2022 年 6 月份左右，阿里也做了一个魔搭，对国内访问更友好。大家在模型库里找一个「文本生成」，你就会找到大量的模型，比如 GPT 诗词生成模型，它用的训练机制、代码是一样的，但它训练的语料用的不一样。

[魔搭社区](https://www.modelscope.cn/home)

这些模型的效果是达不到 GPT-3.4、GPT-4 的，但对于大家在实际工作中，可以尝试使用。在本地，大模型是很难跑起来的，但有些精简的模型是可以跑起来的，比如说能达到近似于 GPT-3.5 效果的，斯坦福大学出的那个精简模型，我们在苹果的 M1 上也能跑起来。

P1：对于非大公司旗下，没有 NLP 技术企业，应该如何切入 GPT 的商业化应用。

回复：这个问题很复杂，有些特别挣钱的方法不能公开说，能公开说的也没那边挣钱。一定要掌握 NLP 大模型的技术。阳老师已经把技术相关的书单以及跑模型的软件推荐给大家了，去学。

P2：GPT 时代对人的判断能力提高了。

P3：大健康如何与 GPT 结合。

P4：GPT 对教育的影响。

回复：对教育的影响非常巨大，对人的四大分析的能力要求提高了（信息分析、行为分析、决策分析、论证分析）。如何更好的提问、提问后如何判断 GPT 的答案是否正确。

P5：是否能理解人类的意图，然后投其所好。

回复：一定会投其所好的，这是它的机制决定的（强化学习的机制）。

P6：现在是否有判断是否是 AI 文本的检测工具。

回复：目前市场上有两三个，但我觉得这种工具没什么意义的。比如我们当下的时代，所产出的文章，没人关心是你手写的还是电脑打出来的。但伟大的作家依然是伟大的作家，在 GPT 的加持下，生产力会极限放大。

P7：思维链的具体介绍。

回复：思路链就是多了一个提问的过程，今天还出了一个论文，是我之前说的反省心智，多了一个反射的过程，最终发现也能大大提高 GPT 的正确率，我会在知识星球发下这篇论文的。

题外话：同时具备心理学和计算机知识结构的阳老师很难被取代。心理学和计算机把持了 2 个非常重要的入口，心理学解决了人与人之间如何信任的问题，计算机解决的是信息的问题。

P8：模型参数的数量。

回复：模型参数的数量从来不是最重要的，前面介绍的那些杀手锏绝大多数是 openAI 团队自己开发的。达摩院这边的杀手锏还不够多，拼参数的阿里和百度参数也不少了，最终还是拼细节。目前国内有二十多个大模型在路上。

P9：为什么用理商测试而非智商测试去评测 GPT 的推理能力。

回复：这是一个操作问题。智商测试是基于图片的，我们刚刚搞定基于数据矩阵的，这是刚刚解决的技术，未来大家可以看到对于 GPT 智商测试的报告。

P10：很神奇。

回复：没那么神奇，它只是大语言模型。大家为什么觉得它神奇是因为它是基于语言的，但如果把语言换成是符号，换成数学符号，你就觉得它没那么神奇了，因为我们人类社会文明的基础是建立在语言（符号）之上的。我更关心的是技术操作的东西，不关心这些。

我们今天去看大语言模型，它的成本是 10 亿美金，但 77 年后，假如下降 6000 倍，下降到 20W 美金左右，那么对很多人来说就是买得起用的起了，而且 21 世界下降的速度会更快，极有可能是 20 年内。20 年后可能会形成这样的一个格局：有钱人用自己私人的模型，普通人只能用公共的大模型，比如说用百度的，这个时候会导致人与人之间认知的巨大差异。

P11：原创性。

回复：大家不用担心原创性的问题，这里推荐大家去看刘慈欣写的一篇小说《诗云》，就是为了回答这个问题的。

P12：GPT污染信息来源怎么办。

回复：信息分析的交叉验证、论证分析的形式逻辑和非形式逻辑。阳老师目前总结了一些技巧在后续的课程中会分享，怎么判断它是瞎编乱造的，还是真的知道。你如果理解它的底层原理，那么判断它的靠谱程度就容易多了。

P13：是颠覆性的革命么？

回复：是颠覆性的革命，基本上会沿着从娱乐性语言到专业性语言的路径演化，一上来先颠覆娱乐性的语言，接着是专业性的语言，一定会被颠覆的。

补充 1：情绪反应能力，活水工作室已经在测试了。

补充 2：GPT 大语言模型跟传统的 NLP 不是一回事，它对传统的 NLP 是降维打击。

P14：对未来教育领域有哪些深刻的变化？

回复：最大的变化是大家需要阳老师快要出的这本书，这本书总结了人类知识的基本脉络，如果你缺乏人类知识的基本脉络，你是很难区分出 GPT 哪些是胡说八道，哪些是对的。对教育最大的改变有很多很多，比如：1）四大分析课被极限放大了。2）专家很快会被淘汰，特别是那些初级专家，但像阳老师这种博学的人，优势极其明显。今天下午跟同事聊天提到一个例子，这个例子一般人是想不到的，因为它调用了 2 个学科非常细微的知识，没有这个知识你压根想不到竟然可以这样向 GPT 提问的。这样提问 GPT 生成的答案马上可以用于阳老师的书稿里。